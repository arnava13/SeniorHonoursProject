2024-04-04 14:42:00.084578: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-04-04 14:42:00.084625: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-04-04 14:42:00.085865: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-04-04 14:42:01.177522: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-04-04 14:42:03.733922: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2024-04-04 15:41:20.028471: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 4406400000 exceeds 10% of free system memory.
2024-04-04 15:41:23.348752: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 4406400000 exceeds 10% of free system memory.
using 1D layers and 4 channels
/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:98: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.
loc = add_variable_fn(
/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:108: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.
untransformed_scale = add_variable_fn(
Expected output dimension after layer: conv1d_flipout : 65
Expected output dimension after layer: conv1d_flipout_1 : 30
Expected output dimension after layer: conv1d_flipout_2 : 29
2024-04-04 15:52:05.322828: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 4406400000 exceeds 10% of free system memory.
2024-04-04 15:52:13.788717: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 4406400000 exceeds 10% of free system memory.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1712245944.604675   31488 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
W0000 00:00:1712245958.384949   31488 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update
W0000 00:00:1712245976.297825   31490 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update
Directory models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_ not created
-------- Parameters:
bayesian True
test_mode False
n_test_idx 2
seed 1312
fine_tune False
one_vs_all False
c_0 ['lcdm']
c_1 ['True', 'dgp', 'ds', 'fR', 'rand--save_ckpt', 'wcdm']
dataset_balanced False
include_last False
log_path models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5__log.txt
restore False
fname fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_
model_name custom
my_path None
DIR data/train
TEST_DIR
models_dir models/
save_ckpt True
out_path_overwrite False
curves_folder data/curve_files_sys/theory_error
save_processed_spectra False
cache_dir False
im_depth 500
im_width 1
im_channels 4
swap_axes True
sort_labels True
norm_data_name /planck_ee2.txt
normalization stdcosmo
sample_pace 1
k_max 2.5
k_min 0.06
i_max None
i_min None
add_noise True
n_noisy_samples 10
add_shot False
add_sys True
add_cosvar True
sigma_sys None
sys_scaled None
sys_factor None
sys_max None
sigma_curves 0.05
sigma_curves_default 0.05
rescale_curves uniform
z_bins [0, 1, 2, 3]
n_dense 1
filters [8, 16, 32]
kernel_sizes [10, 5, 2]
strides [2, 2, 1]
pool_sizes [2, 2, 0]
strides_pooling [2, 1, 0]
add_FT_dense False
trainable False
unfreeze False
lr 0.01
drop 0.5
n_epochs 100
val_size 0.15
test_size 0.0
batch_size 3000
patience 20
GPU True
TPU False
decay 0.95
BatchNorm True
padding valid
shuffle True
------------ CREATING DATA GENERATORS ------------
labels : ['dgp', 'ds', 'fr', 'lcdm', 'rand', 'wcdm']
Labels encoding:
{'dgp': 0, 'ds': 1, 'fr': 2, 'lcdm': 3, 'rand': 4, 'wcdm': 5}
n_labels : 6
dgp - 20000 training examples
ds - 20000 training examples
fr - 20000 training examples
lcdm - 20000 training examples
rand - 20000 training examples
wcdm - 20000 training examples
N. of data files: 20000
get_all_indexes labels dict: {'dgp': 0, 'ds': 1, 'fr': 2, 'lcdm': 3, 'rand': 4, 'wcdm': 5}
create_generators n_labels: 6
create_generators n_labels_eff: 6
create_generators len_c1: 1
Check for no duplicates in test: (0=ok):
0.0
Check for no duplicates in val: (0=ok):
0
N of indexes in training set: 17000
N of indexes in validation set: 3000
N of indexes in test set: 0
Check - total per class: 20000
--create_generators, train indexes
batch_size: 3000
- Cut sample
bs: 3000
N_labels: 6
N_noise: 10
len_c1: 1
Train index length: 17000
--create_generators, validation indexes
- Cut sample
bs: 3000
N_labels: 6
N_noise: 10
len_c1: 1
Val index length: 3000
len(train_index_1), batch_size, n_labels_eff, n_noisy_samples = 17000, 3000, 6, 10
--DataSet Train
DataSet Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 2.5
Corresponding i_max is 399
Closest k to k_max is 2.504942
Specified k_min is 0.06
Corresponding i_min is 129
Closest k to k_min is 0.05964185
New data dim: (270, 1)
Final i_max used is 399
Final i_min used is 129
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 6
N. n_classes in output: 6
LABELS: ['dgp', 'ds', 'fr', 'lcdm', 'rand', 'wcdm']
list_IDs length: 17000
n_indexes (n of file IDs read for each batch): 50
batch size: 3000
n_batches : 340
For each batch we read 50 file IDs
For each file ID we have 6 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 3000 training examples
Input batch size: 3000
N of batches to cover all file IDs: 340
len(fname_list), batch_size, n_noisy_samples, n_batches: 102000, 3000, 10, 340
--DataSet Validation
DataSet Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 2.5
Corresponding i_max is 399
Closest k to k_max is 2.504942
Specified k_min is 0.06
Corresponding i_min is 129
Closest k to k_min is 0.05964185
New data dim: (270, 1)
Final i_max used is 399
Final i_min used is 129
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 6
N. n_classes in output: 6
LABELS: ['dgp', 'ds', 'fr', 'lcdm', 'rand', 'wcdm']
list_IDs length: 3000
n_indexes (n of file IDs read for each batch): 50
batch size: 3000
n_batches : 60
For each batch we read 50 file IDs
For each file ID we have 6 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 3000 training examples
Input batch size: 3000
N of batches to cover all file IDs: 60
len(fname_list), batch_size, n_noisy_samples, n_batches: 18000, 3000, 10, 60
------------ DONE ------------
------------ BUILDING MODEL ------------
Input shape (270, 4)
Model: "model"
_________________________________________________________________
Layer (type)                Output Shape              Param #
=================================================================
input_1 (InputLayer)        [(None, 270, 4)]          0
conv1d_flipout (Conv1DFlip  (None, 131, 8)            648
out)
max_pooling1d (MaxPooling1  (None, 65, 8)             0
D)
batch_normalization (Batch  (None, 65, 8)             32
Normalization)
conv1d_flipout_1 (Conv1DFl  (None, 31, 16)            1296
ipout)
max_pooling1d_1 (MaxPoolin  (None, 30, 16)            0
g1D)
batch_normalization_1 (Bat  (None, 30, 16)            64
chNormalization)
conv1d_flipout_2 (Conv1DFl  (None, 29, 32)            2080
ipout)
batch_normalization_2 (Bat  (None, 29, 32)            128
chNormalization)
global_average_pooling1d (  (None, 32)                0
GlobalAveragePooling1D)
dense_flipout (DenseFlipou  (None, 32)                2080
t)
batch_normalization_3 (Bat  (None, 32)                128
chNormalization)
dense_flipout_1 (DenseFlip  (None, 6)                 390
out)
=================================================================
Total params: 6846 (26.74 KB)
Trainable params: 6670 (26.05 KB)
Non-trainable params: 176 (704.00 Byte)
_________________________________________________________________
None
Found GPU at: /device:GPU:0
------------ TRAINING ------------
Features shape: (3000, 270, 4)
Labels shape: (3000, 6)
Initializing checkpoint from scratch.
Epoch 0
Validation loss decreased. Saved checkpoint for step 1: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-1
Time:  44.07s, ---- Loss: 1.0022, Acc.: 0.5112, Val. Loss: 1.6962, Val. Acc.: 0.3890
Epoch 1
Validation loss decreased. Saved checkpoint for step 2: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-2
Time:  4.25s, ---- Loss: 0.8615, Acc.: 0.6342, Val. Loss: 0.9823, Val. Acc.: 0.6326
Epoch 2
Validation loss decreased. Saved checkpoint for step 3: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-3
Time:  4.23s, ---- Loss: 0.8128, Acc.: 0.6638, Val. Loss: 0.9567, Val. Acc.: 0.6456
Epoch 3
Validation loss decreased. Saved checkpoint for step 4: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-4
Time:  4.28s, ---- Loss: 0.7886, Acc.: 0.6779, Val. Loss: 0.9035, Val. Acc.: 0.6631
Epoch 4
Validation loss decreased. Saved checkpoint for step 5: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-5
Time:  4.26s, ---- Loss: 0.7500, Acc.: 0.6901, Val. Loss: 0.8826, Val. Acc.: 0.6713
Epoch 5
Validation loss decreased. Saved checkpoint for step 6: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-6
Time:  4.26s, ---- Loss: 0.7286, Acc.: 0.7025, Val. Loss: 0.8250, Val. Acc.: 0.6919
Epoch 6
Loss did not decrease. Count = 1
Time:  4.14s, ---- Loss: 0.7141, Acc.: 0.7098, Val. Loss: 0.8410, Val. Acc.: 0.6848
Epoch 7
Validation loss decreased. Saved checkpoint for step 8: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-7
Time:  4.22s, ---- Loss: 0.7043, Acc.: 0.7142, Val. Loss: 0.8027, Val. Acc.: 0.6992
Epoch 8
Loss did not decrease. Count = 1
Time:  4.13s, ---- Loss: 0.6987, Acc.: 0.7178, Val. Loss: 0.8345, Val. Acc.: 0.6837
Epoch 9
Loss did not decrease. Count = 2
Time:  4.12s, ---- Loss: 0.6817, Acc.: 0.7210, Val. Loss: 0.8074, Val. Acc.: 0.6987
Epoch 10
Loss did not decrease. Count = 3
Time:  4.10s, ---- Loss: 0.6769, Acc.: 0.7236, Val. Loss: 0.8179, Val. Acc.: 0.6974
Epoch 11
Loss did not decrease. Count = 4
Time:  4.13s, ---- Loss: 0.6724, Acc.: 0.7264, Val. Loss: 0.8178, Val. Acc.: 0.6971
Epoch 12
Validation loss decreased. Saved checkpoint for step 13: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-8
Time:  4.23s, ---- Loss: 0.6637, Acc.: 0.7284, Val. Loss: 0.7470, Val. Acc.: 0.7221
Epoch 13
Validation loss decreased. Saved checkpoint for step 14: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-9
Time:  4.24s, ---- Loss: 0.6628, Acc.: 0.7311, Val. Loss: 0.7321, Val. Acc.: 0.7262
Epoch 14
Validation loss decreased. Saved checkpoint for step 15: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-10
Time:  4.27s, ---- Loss: 0.6602, Acc.: 0.7337, Val. Loss: 0.7293, Val. Acc.: 0.7280
Epoch 15
Validation loss decreased. Saved checkpoint for step 16: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-11
Time:  4.21s, ---- Loss: 0.6501, Acc.: 0.7360, Val. Loss: 0.7250, Val. Acc.: 0.7297
Epoch 16
Loss did not decrease. Count = 1
Time:  4.13s, ---- Loss: 0.6401, Acc.: 0.7375, Val. Loss: 0.7261, Val. Acc.: 0.7295
Epoch 17
Loss did not decrease. Count = 2
Time:  4.10s, ---- Loss: 0.6398, Acc.: 0.7390, Val. Loss: 0.7315, Val. Acc.: 0.7289
Epoch 18
Validation loss decreased. Saved checkpoint for step 19: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-12
Time:  4.23s, ---- Loss: 0.6343, Acc.: 0.7403, Val. Loss: 0.7140, Val. Acc.: 0.7344
Epoch 19
Loss did not decrease. Count = 1
Time:  4.13s, ---- Loss: 0.6311, Acc.: 0.7412, Val. Loss: 0.7210, Val. Acc.: 0.7325
Epoch 20
Loss did not decrease. Count = 2
Time:  4.12s, ---- Loss: 0.6263, Acc.: 0.7424, Val. Loss: 0.7252, Val. Acc.: 0.7303
Epoch 21
Validation loss decreased. Saved checkpoint for step 22: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-13
Time:  4.23s, ---- Loss: 0.6270, Acc.: 0.7429, Val. Loss: 0.7110, Val. Acc.: 0.7359
Epoch 22
Loss did not decrease. Count = 1
Time:  4.15s, ---- Loss: 0.6263, Acc.: 0.7437, Val. Loss: 0.7180, Val. Acc.: 0.7330
Epoch 23
Loss did not decrease. Count = 2
Time:  4.13s, ---- Loss: 0.6246, Acc.: 0.7444, Val. Loss: 0.7146, Val. Acc.: 0.7335
Epoch 24
Validation loss decreased. Saved checkpoint for step 25: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-14
Time:  4.24s, ---- Loss: 0.6243, Acc.: 0.7450, Val. Loss: 0.7021, Val. Acc.: 0.7380
Epoch 25
Validation loss decreased. Saved checkpoint for step 26: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-15
Time:  4.24s, ---- Loss: 0.6200, Acc.: 0.7454, Val. Loss: 0.6987, Val. Acc.: 0.7390
Epoch 26
Validation loss decreased. Saved checkpoint for step 27: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-16
Time:  4.19s, ---- Loss: 0.6191, Acc.: 0.7458, Val. Loss: 0.6954, Val. Acc.: 0.7407
Epoch 27
Loss did not decrease. Count = 1
Time:  4.14s, ---- Loss: 0.6165, Acc.: 0.7468, Val. Loss: 0.7028, Val. Acc.: 0.7369
Epoch 28
Loss did not decrease. Count = 2
Time:  4.09s, ---- Loss: 0.6162, Acc.: 0.7470, Val. Loss: 0.6990, Val. Acc.: 0.7384
Epoch 29
Validation loss decreased. Saved checkpoint for step 30: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-17
Time:  4.23s, ---- Loss: 0.6154, Acc.: 0.7476, Val. Loss: 0.6947, Val. Acc.: 0.7402
Epoch 30
Validation loss decreased. Saved checkpoint for step 31: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-18
Time:  4.24s, ---- Loss: 0.6125, Acc.: 0.7477, Val. Loss: 0.6910, Val. Acc.: 0.7416
Epoch 31
Validation loss decreased. Saved checkpoint for step 32: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-19
Time:  4.26s, ---- Loss: 0.6132, Acc.: 0.7481, Val. Loss: 0.6894, Val. Acc.: 0.7427
Epoch 32
Validation loss decreased. Saved checkpoint for step 33: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-20
Time:  4.26s, ---- Loss: 0.6124, Acc.: 0.7485, Val. Loss: 0.6862, Val. Acc.: 0.7435
Epoch 33
Validation loss decreased. Saved checkpoint for step 34: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-21
Time:  4.27s, ---- Loss: 0.6146, Acc.: 0.7491, Val. Loss: 0.6828, Val. Acc.: 0.7460
Epoch 34
Loss did not decrease. Count = 1
Time:  4.12s, ---- Loss: 0.6102, Acc.: 0.7493, Val. Loss: 0.6834, Val. Acc.: 0.7443
Epoch 35
Validation loss decreased. Saved checkpoint for step 36: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-22
Time:  4.29s, ---- Loss: 0.6101, Acc.: 0.7497, Val. Loss: 0.6827, Val. Acc.: 0.7452
Epoch 36
Validation loss decreased. Saved checkpoint for step 37: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-23
Time:  4.23s, ---- Loss: 0.6127, Acc.: 0.7498, Val. Loss: 0.6796, Val. Acc.: 0.7462
Epoch 37
Loss did not decrease. Count = 1
Time:  4.10s, ---- Loss: 0.6110, Acc.: 0.7503, Val. Loss: 0.6797, Val. Acc.: 0.7465
Epoch 38
Validation loss decreased. Saved checkpoint for step 39: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-24
Time:  4.26s, ---- Loss: 0.6104, Acc.: 0.7506, Val. Loss: 0.6776, Val. Acc.: 0.7477
Epoch 39
Loss did not decrease. Count = 1
Time:  4.11s, ---- Loss: 0.6112, Acc.: 0.7507, Val. Loss: 0.6777, Val. Acc.: 0.7472
Epoch 40
Validation loss decreased. Saved checkpoint for step 41: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-25
Time:  4.24s, ---- Loss: 0.6110, Acc.: 0.7513, Val. Loss: 0.6761, Val. Acc.: 0.7478
Epoch 41
Loss did not decrease. Count = 1
Time:  4.13s, ---- Loss: 0.6123, Acc.: 0.7513, Val. Loss: 0.6763, Val. Acc.: 0.7474
Epoch 42
Validation loss decreased. Saved checkpoint for step 43: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-26
Time:  4.22s, ---- Loss: 0.6082, Acc.: 0.7516, Val. Loss: 0.6750, Val. Acc.: 0.7482
Epoch 43
Loss did not decrease. Count = 1
Time:  4.10s, ---- Loss: 0.6072, Acc.: 0.7518, Val. Loss: 0.6753, Val. Acc.: 0.7486
Epoch 44
Loss did not decrease. Count = 2
Time:  4.09s, ---- Loss: 0.6060, Acc.: 0.7517, Val. Loss: 0.6759, Val. Acc.: 0.7481
Epoch 45
Validation loss decreased. Saved checkpoint for step 46: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-27
Time:  4.24s, ---- Loss: 0.6044, Acc.: 0.7521, Val. Loss: 0.6737, Val. Acc.: 0.7492
Epoch 46
Validation loss decreased. Saved checkpoint for step 47: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-28
Time:  4.28s, ---- Loss: 0.6035, Acc.: 0.7524, Val. Loss: 0.6724, Val. Acc.: 0.7499
Epoch 47
Loss did not decrease. Count = 1
Time:  4.12s, ---- Loss: 0.6015, Acc.: 0.7525, Val. Loss: 0.6724, Val. Acc.: 0.7498
Epoch 48
Validation loss decreased. Saved checkpoint for step 49: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-29
Time:  4.25s, ---- Loss: 0.6052, Acc.: 0.7525, Val. Loss: 0.6713, Val. Acc.: 0.7503
Epoch 49
Validation loss decreased. Saved checkpoint for step 50: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-30
Time:  4.29s, ---- Loss: 0.6065, Acc.: 0.7528, Val. Loss: 0.6708, Val. Acc.: 0.7507
Epoch 50
Validation loss decreased. Saved checkpoint for step 51: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-31
Time:  4.24s, ---- Loss: 0.6030, Acc.: 0.7530, Val. Loss: 0.6708, Val. Acc.: 0.7503
Epoch 51
Loss did not decrease. Count = 1
Time:  4.13s, ---- Loss: 0.6054, Acc.: 0.7533, Val. Loss: 0.6714, Val. Acc.: 0.7505
Epoch 52
Validation loss decreased. Saved checkpoint for step 53: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-32
Time:  4.25s, ---- Loss: 0.6028, Acc.: 0.7532, Val. Loss: 0.6707, Val. Acc.: 0.7503
Epoch 53
Validation loss decreased. Saved checkpoint for step 54: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-33
Time:  4.23s, ---- Loss: 0.6041, Acc.: 0.7533, Val. Loss: 0.6706, Val. Acc.: 0.7503
Epoch 54
Validation loss decreased. Saved checkpoint for step 55: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-34
Time:  4.29s, ---- Loss: 0.6039, Acc.: 0.7537, Val. Loss: 0.6703, Val. Acc.: 0.7511
Epoch 55
Validation loss decreased. Saved checkpoint for step 56: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-35
Time:  4.25s, ---- Loss: 0.6045, Acc.: 0.7537, Val. Loss: 0.6694, Val. Acc.: 0.7515
Epoch 56
Validation loss decreased. Saved checkpoint for step 57: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-36
Time:  4.26s, ---- Loss: 0.6046, Acc.: 0.7539, Val. Loss: 0.6688, Val. Acc.: 0.7515
Epoch 57
Loss did not decrease. Count = 1
Time:  4.14s, ---- Loss: 0.6036, Acc.: 0.7538, Val. Loss: 0.6693, Val. Acc.: 0.7511
Epoch 58
Validation loss decreased. Saved checkpoint for step 59: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-37
Time:  4.27s, ---- Loss: 0.6011, Acc.: 0.7541, Val. Loss: 0.6687, Val. Acc.: 0.7512
Epoch 59
Validation loss decreased. Saved checkpoint for step 60: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-38
Time:  4.28s, ---- Loss: 0.6035, Acc.: 0.7541, Val. Loss: 0.6686, Val. Acc.: 0.7513
Epoch 60
Validation loss decreased. Saved checkpoint for step 61: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-39
Time:  4.26s, ---- Loss: 0.6025, Acc.: 0.7540, Val. Loss: 0.6679, Val. Acc.: 0.7520
Epoch 61
Loss did not decrease. Count = 1
Time:  4.13s, ---- Loss: 0.6031, Acc.: 0.7541, Val. Loss: 0.6679, Val. Acc.: 0.7516
Epoch 62
Validation loss decreased. Saved checkpoint for step 63: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-40
Time:  4.26s, ---- Loss: 0.6035, Acc.: 0.7543, Val. Loss: 0.6674, Val. Acc.: 0.7519
Epoch 63
Loss did not decrease. Count = 1
Time:  4.25s, ---- Loss: 0.6034, Acc.: 0.7542, Val. Loss: 0.6681, Val. Acc.: 0.7516
Epoch 64
Validation loss decreased. Saved checkpoint for step 65: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-41
Time:  4.53s, ---- Loss: 0.6029, Acc.: 0.7542, Val. Loss: 0.6673, Val. Acc.: 0.7519
Epoch 65
Validation loss decreased. Saved checkpoint for step 66: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-42
Time:  4.58s, ---- Loss: 0.6028, Acc.: 0.7545, Val. Loss: 0.6673, Val. Acc.: 0.7514
Epoch 66
Validation loss decreased. Saved checkpoint for step 67: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-43
Time:  4.57s, ---- Loss: 0.6047, Acc.: 0.7544, Val. Loss: 0.6668, Val. Acc.: 0.7519
Epoch 67
Loss did not decrease. Count = 1
Time:  4.27s, ---- Loss: 0.6027, Acc.: 0.7546, Val. Loss: 0.6669, Val. Acc.: 0.7520
Epoch 68
Loss did not decrease. Count = 2
Time:  4.28s, ---- Loss: 0.6039, Acc.: 0.7546, Val. Loss: 0.6675, Val. Acc.: 0.7521
Epoch 69
Validation loss decreased. Saved checkpoint for step 70: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-44
Time:  4.39s, ---- Loss: 0.6040, Acc.: 0.7547, Val. Loss: 0.6668, Val. Acc.: 0.7522
Epoch 70
Validation loss decreased. Saved checkpoint for step 71: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-45
Time:  4.42s, ---- Loss: 0.6024, Acc.: 0.7549, Val. Loss: 0.6665, Val. Acc.: 0.7524
Epoch 71
Loss did not decrease. Count = 1
Time:  4.24s, ---- Loss: 0.6031, Acc.: 0.7546, Val. Loss: 0.6666, Val. Acc.: 0.7520
Epoch 72
Loss did not decrease. Count = 2
Time:  4.24s, ---- Loss: 0.6031, Acc.: 0.7550, Val. Loss: 0.6665, Val. Acc.: 0.7526
Epoch 73
Validation loss decreased. Saved checkpoint for step 74: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-46
Time:  4.42s, ---- Loss: 0.6030, Acc.: 0.7551, Val. Loss: 0.6663, Val. Acc.: 0.7521
Epoch 74
Loss did not decrease. Count = 1
Time:  4.27s, ---- Loss: 0.6038, Acc.: 0.7549, Val. Loss: 0.6664, Val. Acc.: 0.7526
Epoch 75
Loss did not decrease. Count = 2
Time:  4.27s, ---- Loss: 0.6015, Acc.: 0.7552, Val. Loss: 0.6670, Val. Acc.: 0.7517
Epoch 76
Loss did not decrease. Count = 3
Time:  4.25s, ---- Loss: 0.6009, Acc.: 0.7550, Val. Loss: 0.6672, Val. Acc.: 0.7523
Epoch 77
Validation loss decreased. Saved checkpoint for step 78: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-47
Time:  4.38s, ---- Loss: 0.6032, Acc.: 0.7549, Val. Loss: 0.6662, Val. Acc.: 0.7521
Epoch 78
Validation loss decreased. Saved checkpoint for step 79: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-48
Time:  4.46s, ---- Loss: 0.6033, Acc.: 0.7552, Val. Loss: 0.6662, Val. Acc.: 0.7521
Epoch 79
Validation loss decreased. Saved checkpoint for step 80: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-49
Time:  4.37s, ---- Loss: 0.6031, Acc.: 0.7552, Val. Loss: 0.6659, Val. Acc.: 0.7522
Epoch 80
Validation loss decreased. Saved checkpoint for step 81: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-50
Time:  4.34s, ---- Loss: 0.6018, Acc.: 0.7551, Val. Loss: 0.6658, Val. Acc.: 0.7527
Epoch 81
Validation loss decreased. Saved checkpoint for step 82: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-51
Time:  4.37s, ---- Loss: 0.6004, Acc.: 0.7552, Val. Loss: 0.6656, Val. Acc.: 0.7527
Epoch 82
Loss did not decrease. Count = 1
Time:  4.27s, ---- Loss: 0.6010, Acc.: 0.7553, Val. Loss: 0.6660, Val. Acc.: 0.7526
Epoch 83
Loss did not decrease. Count = 2
Time:  4.23s, ---- Loss: 0.6015, Acc.: 0.7551, Val. Loss: 0.6659, Val. Acc.: 0.7527
Epoch 84
Validation loss decreased. Saved checkpoint for step 85: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-52
Time:  4.35s, ---- Loss: 0.6020, Acc.: 0.7553, Val. Loss: 0.6654, Val. Acc.: 0.7528
Epoch 85
Validation loss decreased. Saved checkpoint for step 86: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-53
Time:  4.38s, ---- Loss: 0.6018, Acc.: 0.7552, Val. Loss: 0.6654, Val. Acc.: 0.7532
Epoch 86
Validation loss decreased. Saved checkpoint for step 87: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-54
Time:  4.40s, ---- Loss: 0.6045, Acc.: 0.7552, Val. Loss: 0.6652, Val. Acc.: 0.7530
Epoch 87
Validation loss decreased. Saved checkpoint for step 88: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-55
Time:  4.37s, ---- Loss: 0.6006, Acc.: 0.7554, Val. Loss: 0.6651, Val. Acc.: 0.7523
Epoch 88
Loss did not decrease. Count = 1
Time:  4.18s, ---- Loss: 0.6023, Acc.: 0.7553, Val. Loss: 0.6655, Val. Acc.: 0.7526
Epoch 89
Loss did not decrease. Count = 2
Time:  4.44s, ---- Loss: 0.6026, Acc.: 0.7555, Val. Loss: 0.6653, Val. Acc.: 0.7527
Epoch 90
Validation loss decreased. Saved checkpoint for step 91: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-56
Time:  4.56s, ---- Loss: 0.6020, Acc.: 0.7557, Val. Loss: 0.6651, Val. Acc.: 0.7524
Epoch 91
Loss did not decrease. Count = 1
Time:  4.38s, ---- Loss: 0.6033, Acc.: 0.7554, Val. Loss: 0.6653, Val. Acc.: 0.7521
Epoch 92
Validation loss decreased. Saved checkpoint for step 93: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-57
Time:  4.39s, ---- Loss: 0.6011, Acc.: 0.7556, Val. Loss: 0.6651, Val. Acc.: 0.7526
Epoch 93
Loss did not decrease. Count = 1
Time:  4.24s, ---- Loss: 0.6044, Acc.: 0.7556, Val. Loss: 0.6651, Val. Acc.: 0.7531
Epoch 94
Validation loss decreased. Saved checkpoint for step 95: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-58
Time:  4.41s, ---- Loss: 0.6041, Acc.: 0.7555, Val. Loss: 0.6650, Val. Acc.: 0.7529
Epoch 95
Loss did not decrease. Count = 1
Time:  4.26s, ---- Loss: 0.6013, Acc.: 0.7556, Val. Loss: 0.6652, Val. Acc.: 0.7533
Epoch 96
Validation loss decreased. Saved checkpoint for step 97: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-59
Time:  4.40s, ---- Loss: 0.6014, Acc.: 0.7558, Val. Loss: 0.6649, Val. Acc.: 0.7527
Epoch 97
Validation loss decreased. Saved checkpoint for step 98: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-60
Time:  4.38s, ---- Loss: 0.5999, Acc.: 0.7555, Val. Loss: 0.6648, Val. Acc.: 0.7527
Epoch 98
Validation loss decreased. Saved checkpoint for step 99: models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-61
Time:  4.40s, ---- Loss: 0.6013, Acc.: 0.7557, Val. Loss: 0.6648, Val. Acc.: 0.7534
Epoch 99
Loss did not decrease. Count = 1
Time:  4.26s, ---- Loss: 0.6023, Acc.: 0.7556, Val. Loss: 0.6649, Val. Acc.: 0.7529
Saving at models/fivelabel_20k_EE2_LCDM-randoms_kmin-0.06_kmax-2.5_/hist.png
Done in 4676.29s

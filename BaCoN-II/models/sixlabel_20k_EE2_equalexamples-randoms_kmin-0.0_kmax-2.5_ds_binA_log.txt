2024-04-07 00:18:10.619630: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-04-07 00:18:10.619672: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-04-07 00:18:10.621515: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-04-07 00:18:11.621797: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-04-07 00:18:13.991689: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
using 1D layers and 4 channels
/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:98: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.
loc = add_variable_fn(
/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:108: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.
untransformed_scale = add_variable_fn(
Expected output dimension after layer: conv1d_flipout : 97
Expected output dimension after layer: conv1d_flipout_1 : 46
Expected output dimension after layer: conv1d_flipout_2 : 45
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1712450072.277568    9315 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Creating directory models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA
-------- Parameters:
bayesian True
test_mode False
n_test_idx 2
seed 1312
fine_tune False
one_vs_all False
c_0 ['lcdm']
c_1 ['True', 'dgp', 'ds', 'fR', 'rand--save_ckpt', 'wcdm']
dataset_balanced False
include_last False
log_path models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA_log.txt
restore False
fname sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA
model_name custom
my_path None
DIR data/train
TEST_DIR data/test/
models_dir models/
save_ckpt True
out_path_overwrite False
curves_folder data/curve_files_sys/theory_error
save_processed_spectra False
cache_dir False
im_depth 500
im_width 1
im_channels 4
swap_axes True
sort_labels True
norm_data_name /planck_ee2.txt
normalization stdcosmo
sample_pace 1
k_max 2.5
k_min 0.0
i_max None
i_min None
add_noise True
n_noisy_samples 10
add_shot False
add_sys True
add_cosvar True
sigma_sys None
sys_scaled None
sys_factor None
sys_max None
sigma_curves 0.05
sigma_curves_default 0.05
rescale_curves uniform
z_bins [0, 1, 2, 3]
n_dense 1
filters [8, 16, 32]
kernel_sizes [10, 5, 2]
strides [2, 2, 1]
pool_sizes [2, 2, 0]
strides_pooling [2, 1, 0]
add_FT_dense False
trainable False
unfreeze False
lr 0.01
drop 0.5
n_epochs 100
val_size 0.15
test_size 0.0
batch_size 3000
patience 20
GPU True
TPU False
decay 0.95
BatchNorm True
padding valid
shuffle True
------------ CREATING DATA GENERATORS ------------
labels : ['dgp', 'ds_binA', 'fr', 'lcdm', 'rand', 'wcdm']
Labels encoding:
{'dgp': 0, 'ds_binA': 1, 'fr': 2, 'lcdm': 3, 'rand': 4, 'wcdm': 5}
n_labels : 6
dgp - 5000 training examples
ds_binA - 5000 training examples
fr - 5000 training examples
lcdm - 5000 training examples
rand - 5000 training examples
wcdm - 5000 training examples
N. of data files: 5000
get_all_indexes labels dict: {'dgp': 0, 'ds_binA': 1, 'fr': 2, 'lcdm': 3, 'rand': 4, 'wcdm': 5}
create_generators n_labels: 6
create_generators n_labels_eff: 6
create_generators len_c1: 1
Check for no duplicates in test: (0=ok):
0.0
Check for no duplicates in val: (0=ok):
0
N of indexes in training set: 4250
N of indexes in validation set: 750
N of indexes in test set: 0
Check - total per class: 5000
--create_generators, train indexes
batch_size: 3000
- Cut sample
bs: 3000
N_labels: 6
N_noise: 10
len_c1: 1
Train index length: 4250
--create_generators, validation indexes
- Cut sample
bs: 3000
N_labels: 6
N_noise: 10
len_c1: 1
Val index length: 750
len(train_index_1), batch_size, n_labels_eff, n_noisy_samples = 4250, 3000, 6, 10
--DataSet Train
DataSet Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 2.5
Corresponding i_max is 399
Closest k to k_max is 2.504942
Specified k_min is 0.0
Corresponding i_min is 0
Closest k to k_min is 0.01
New data dim: (399, 1)
Final i_max used is 399
Final i_min used is 0
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 6
N. n_classes in output: 6
LABELS: ['dgp', 'ds_binA', 'fr', 'lcdm', 'rand', 'wcdm']
list_IDs length: 4250
n_indexes (n of file IDs read for each batch): 50
batch size: 3000
n_batches : 85
For each batch we read 50 file IDs
For each file ID we have 6 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 3000 training examples
Input batch size: 3000
N of batches to cover all file IDs: 85
len(fname_list), batch_size, n_noisy_samples, n_batches: 25500, 3000, 10, 85
--DataSet Validation
DataSet Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 2.5
Corresponding i_max is 399
Closest k to k_max is 2.504942
Specified k_min is 0.0
Corresponding i_min is 0
Closest k to k_min is 0.01
New data dim: (399, 1)
Final i_max used is 399
Final i_min used is 0
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 6
N. n_classes in output: 6
LABELS: ['dgp', 'ds_binA', 'fr', 'lcdm', 'rand', 'wcdm']
list_IDs length: 750
n_indexes (n of file IDs read for each batch): 50
batch size: 3000
n_batches : 15
For each batch we read 50 file IDs
For each file ID we have 6 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 3000 training examples
Input batch size: 3000
N of batches to cover all file IDs: 15
len(fname_list), batch_size, n_noisy_samples, n_batches: 4500, 3000, 10, 15
------------ DONE ------------
------------ BUILDING MODEL ------------
Input shape (399, 4)
Model: "model"
_________________________________________________________________
Layer (type)                Output Shape              Param #
=================================================================
input_1 (InputLayer)        [(None, 399, 4)]          0
conv1d_flipout (Conv1DFlip  (None, 195, 8)            648
out)
max_pooling1d (MaxPooling1  (None, 97, 8)             0
D)
batch_normalization (Batch  (None, 97, 8)             32
Normalization)
conv1d_flipout_1 (Conv1DFl  (None, 47, 16)            1296
ipout)
max_pooling1d_1 (MaxPoolin  (None, 46, 16)            0
g1D)
batch_normalization_1 (Bat  (None, 46, 16)            64
chNormalization)
conv1d_flipout_2 (Conv1DFl  (None, 45, 32)            2080
ipout)
batch_normalization_2 (Bat  (None, 45, 32)            128
chNormalization)
global_average_pooling1d (  (None, 32)                0
GlobalAveragePooling1D)
dense_flipout (DenseFlipou  (None, 32)                2080
t)
batch_normalization_3 (Bat  (None, 32)                128
chNormalization)
dense_flipout_1 (DenseFlip  (None, 6)                 390
out)
=================================================================
Total params: 6846 (26.74 KB)
Trainable params: 6670 (26.05 KB)
Non-trainable params: 176 (704.00 Byte)
_________________________________________________________________
None
Found GPU at: /device:GPU:0
------------ TRAINING ------------
Features shape: (3000, 399, 4)
Labels shape: (3000, 6)
Initializing checkpoint from scratch.
Epoch 0
Validation loss decreased. Saved checkpoint for step 1: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-1
Time:  34.98s, ---- Loss: 1.1431, Acc.: 0.4493, Val. Loss: 2.0364, Val. Acc.: 0.3063
Epoch 1
Loss did not decrease. Count = 1
Time:  0.95s, ---- Loss: 0.9869, Acc.: 0.5714, Val. Loss: 2.3255, Val. Acc.: 0.2864
Epoch 2
Loss did not decrease. Count = 2
Time:  0.95s, ---- Loss: 0.9144, Acc.: 0.6258, Val. Loss: 2.4403, Val. Acc.: 0.2552
Epoch 3
Loss did not decrease. Count = 3
Time:  0.94s, ---- Loss: 0.8383, Acc.: 0.6570, Val. Loss: 2.0463, Val. Acc.: 0.3649
Epoch 4
Validation loss decreased. Saved checkpoint for step 5: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-2
Time:  1.07s, ---- Loss: 0.8148, Acc.: 0.6731, Val. Loss: 1.5365, Val. Acc.: 0.4775
Epoch 5
Validation loss decreased. Saved checkpoint for step 6: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-3
Time:  1.07s, ---- Loss: 0.7746, Acc.: 0.6858, Val. Loss: 1.2757, Val. Acc.: 0.5545
Epoch 6
Validation loss decreased. Saved checkpoint for step 7: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-4
Time:  1.06s, ---- Loss: 0.7573, Acc.: 0.6955, Val. Loss: 1.0625, Val. Acc.: 0.6374
Epoch 7
Validation loss decreased. Saved checkpoint for step 8: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-5
Time:  1.07s, ---- Loss: 0.7376, Acc.: 0.7028, Val. Loss: 0.9677, Val. Acc.: 0.6817
Epoch 8
Validation loss decreased. Saved checkpoint for step 9: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-6
Time:  1.09s, ---- Loss: 0.7245, Acc.: 0.7077, Val. Loss: 0.9375, Val. Acc.: 0.6948
Epoch 9
Validation loss decreased. Saved checkpoint for step 10: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-7
Time:  1.06s, ---- Loss: 0.7175, Acc.: 0.7131, Val. Loss: 0.9292, Val. Acc.: 0.7002
Epoch 10
Loss did not decrease. Count = 1
Time:  0.93s, ---- Loss: 0.7044, Acc.: 0.7155, Val. Loss: 0.9303, Val. Acc.: 0.7003
Epoch 11
Validation loss decreased. Saved checkpoint for step 12: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-8
Time:  1.06s, ---- Loss: 0.6946, Acc.: 0.7193, Val. Loss: 0.9110, Val. Acc.: 0.7081
Epoch 12
Loss did not decrease. Count = 1
Time:  0.94s, ---- Loss: 0.6950, Acc.: 0.7213, Val. Loss: 0.9112, Val. Acc.: 0.7115
Epoch 13
Loss did not decrease. Count = 2
Time:  0.95s, ---- Loss: 0.6903, Acc.: 0.7231, Val. Loss: 0.9259, Val. Acc.: 0.7057
Epoch 14
Loss did not decrease. Count = 3
Time:  0.93s, ---- Loss: 0.6690, Acc.: 0.7261, Val. Loss: 0.9246, Val. Acc.: 0.7061
Epoch 15
Loss did not decrease. Count = 4
Time:  0.94s, ---- Loss: 0.6637, Acc.: 0.7271, Val. Loss: 0.9172, Val. Acc.: 0.7078
Epoch 16
Validation loss decreased. Saved checkpoint for step 17: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-9
Time:  1.06s, ---- Loss: 0.6663, Acc.: 0.7291, Val. Loss: 0.8949, Val. Acc.: 0.7175
Epoch 17
Loss did not decrease. Count = 1
Time:  0.93s, ---- Loss: 0.6576, Acc.: 0.7310, Val. Loss: 0.8969, Val. Acc.: 0.7181
Epoch 18
Validation loss decreased. Saved checkpoint for step 19: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-10
Time:  1.06s, ---- Loss: 0.6490, Acc.: 0.7330, Val. Loss: 0.8860, Val. Acc.: 0.7181
Epoch 19
Loss did not decrease. Count = 1
Time:  0.94s, ---- Loss: 0.6492, Acc.: 0.7344, Val. Loss: 0.8896, Val. Acc.: 0.7174
Epoch 20
Loss did not decrease. Count = 2
Time:  0.96s, ---- Loss: 0.6436, Acc.: 0.7348, Val. Loss: 0.8949, Val. Acc.: 0.7159
Epoch 21
Validation loss decreased. Saved checkpoint for step 22: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-11
Time:  1.06s, ---- Loss: 0.6391, Acc.: 0.7356, Val. Loss: 0.8756, Val. Acc.: 0.7236
Epoch 22
Loss did not decrease. Count = 1
Time:  0.93s, ---- Loss: 0.6353, Acc.: 0.7376, Val. Loss: 0.8779, Val. Acc.: 0.7213
Epoch 23
Loss did not decrease. Count = 2
Time:  0.93s, ---- Loss: 0.6287, Acc.: 0.7382, Val. Loss: 0.8780, Val. Acc.: 0.7210
Epoch 24
Validation loss decreased. Saved checkpoint for step 25: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-12
Time:  1.06s, ---- Loss: 0.6306, Acc.: 0.7389, Val. Loss: 0.8697, Val. Acc.: 0.7261
Epoch 25
Validation loss decreased. Saved checkpoint for step 26: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-13
Time:  1.05s, ---- Loss: 0.6308, Acc.: 0.7404, Val. Loss: 0.8678, Val. Acc.: 0.7265
Epoch 26
Loss did not decrease. Count = 1
Time:  0.94s, ---- Loss: 0.6276, Acc.: 0.7412, Val. Loss: 0.8716, Val. Acc.: 0.7263
Epoch 27
Loss did not decrease. Count = 2
Time:  0.94s, ---- Loss: 0.6191, Acc.: 0.7412, Val. Loss: 0.8742, Val. Acc.: 0.7248
Epoch 28
Loss did not decrease. Count = 3
Time:  0.93s, ---- Loss: 0.6188, Acc.: 0.7420, Val. Loss: 0.8789, Val. Acc.: 0.7215
Epoch 29
Loss did not decrease. Count = 4
Time:  0.93s, ---- Loss: 0.6153, Acc.: 0.7425, Val. Loss: 0.8773, Val. Acc.: 0.7253
Epoch 30
Loss did not decrease. Count = 5
Time:  0.93s, ---- Loss: 0.6172, Acc.: 0.7430, Val. Loss: 0.8715, Val. Acc.: 0.7261
Epoch 31
Loss did not decrease. Count = 6
Time:  0.96s, ---- Loss: 0.6138, Acc.: 0.7441, Val. Loss: 0.8715, Val. Acc.: 0.7278
Epoch 32
Validation loss decreased. Saved checkpoint for step 33: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-14
Time:  1.07s, ---- Loss: 0.6166, Acc.: 0.7453, Val. Loss: 0.8670, Val. Acc.: 0.7284
Epoch 33
Validation loss decreased. Saved checkpoint for step 34: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-15
Time:  1.06s, ---- Loss: 0.6096, Acc.: 0.7452, Val. Loss: 0.8598, Val. Acc.: 0.7304
Epoch 34
Loss did not decrease. Count = 1
Time:  0.93s, ---- Loss: 0.6104, Acc.: 0.7458, Val. Loss: 0.8611, Val. Acc.: 0.7325
Epoch 35
Validation loss decreased. Saved checkpoint for step 36: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-16
Time:  1.05s, ---- Loss: 0.6123, Acc.: 0.7460, Val. Loss: 0.8579, Val. Acc.: 0.7330
Epoch 36
Validation loss decreased. Saved checkpoint for step 37: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-17
Time:  1.07s, ---- Loss: 0.6095, Acc.: 0.7466, Val. Loss: 0.8561, Val. Acc.: 0.7343
Epoch 37
Loss did not decrease. Count = 1
Time:  0.94s, ---- Loss: 0.6015, Acc.: 0.7469, Val. Loss: 0.8582, Val. Acc.: 0.7340
Epoch 38
Loss did not decrease. Count = 2
Time:  0.94s, ---- Loss: 0.6065, Acc.: 0.7476, Val. Loss: 0.8599, Val. Acc.: 0.7334
Epoch 39
Validation loss decreased. Saved checkpoint for step 40: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-18
Time:  1.05s, ---- Loss: 0.6001, Acc.: 0.7483, Val. Loss: 0.8502, Val. Acc.: 0.7365
Epoch 40
Loss did not decrease. Count = 1
Time:  0.94s, ---- Loss: 0.5998, Acc.: 0.7490, Val. Loss: 0.8511, Val. Acc.: 0.7361
Epoch 41
Validation loss decreased. Saved checkpoint for step 42: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-19
Time:  1.06s, ---- Loss: 0.5960, Acc.: 0.7494, Val. Loss: 0.8501, Val. Acc.: 0.7352
Epoch 42
Validation loss decreased. Saved checkpoint for step 43: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-20
Time:  1.09s, ---- Loss: 0.5999, Acc.: 0.7493, Val. Loss: 0.8482, Val. Acc.: 0.7383
Epoch 43
Validation loss decreased. Saved checkpoint for step 44: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-21
Time:  1.07s, ---- Loss: 0.6035, Acc.: 0.7501, Val. Loss: 0.8435, Val. Acc.: 0.7393
Epoch 44
Loss did not decrease. Count = 1
Time:  0.93s, ---- Loss: 0.5924, Acc.: 0.7499, Val. Loss: 0.8451, Val. Acc.: 0.7383
Epoch 45
Loss did not decrease. Count = 2
Time:  0.93s, ---- Loss: 0.6029, Acc.: 0.7504, Val. Loss: 0.8487, Val. Acc.: 0.7395
Epoch 46
Loss did not decrease. Count = 3
Time:  0.93s, ---- Loss: 0.6002, Acc.: 0.7511, Val. Loss: 0.8514, Val. Acc.: 0.7368
Epoch 47
Validation loss decreased. Saved checkpoint for step 48: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-22
Time:  1.05s, ---- Loss: 0.5918, Acc.: 0.7512, Val. Loss: 0.8427, Val. Acc.: 0.7399
Epoch 48
Validation loss decreased. Saved checkpoint for step 49: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-23
Time:  1.05s, ---- Loss: 0.5995, Acc.: 0.7521, Val. Loss: 0.8424, Val. Acc.: 0.7413
Epoch 49
Validation loss decreased. Saved checkpoint for step 50: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-24
Time:  1.05s, ---- Loss: 0.5927, Acc.: 0.7519, Val. Loss: 0.8419, Val. Acc.: 0.7423
Epoch 50
Validation loss decreased. Saved checkpoint for step 51: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-25
Time:  1.05s, ---- Loss: 0.5922, Acc.: 0.7523, Val. Loss: 0.8392, Val. Acc.: 0.7431
Epoch 51
Loss did not decrease. Count = 1
Time:  0.93s, ---- Loss: 0.5905, Acc.: 0.7531, Val. Loss: 0.8412, Val. Acc.: 0.7400
Epoch 52
Validation loss decreased. Saved checkpoint for step 53: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-26
Time:  1.06s, ---- Loss: 0.5930, Acc.: 0.7530, Val. Loss: 0.8373, Val. Acc.: 0.7421
Epoch 53
Loss did not decrease. Count = 1
Time:  0.94s, ---- Loss: 0.5871, Acc.: 0.7534, Val. Loss: 0.8419, Val. Acc.: 0.7414
Epoch 54
Loss did not decrease. Count = 2
Time:  0.95s, ---- Loss: 0.5922, Acc.: 0.7532, Val. Loss: 0.8397, Val. Acc.: 0.7431
Epoch 55
Loss did not decrease. Count = 3
Time:  0.93s, ---- Loss: 0.5920, Acc.: 0.7535, Val. Loss: 0.8389, Val. Acc.: 0.7417
Epoch 56
Loss did not decrease. Count = 4
Time:  0.94s, ---- Loss: 0.5916, Acc.: 0.7534, Val. Loss: 0.8385, Val. Acc.: 0.7439
Epoch 57
Validation loss decreased. Saved checkpoint for step 58: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-27
Time:  1.06s, ---- Loss: 0.5953, Acc.: 0.7535, Val. Loss: 0.8349, Val. Acc.: 0.7428
Epoch 58
Loss did not decrease. Count = 1
Time:  0.94s, ---- Loss: 0.5928, Acc.: 0.7534, Val. Loss: 0.8364, Val. Acc.: 0.7442
Epoch 59
Loss did not decrease. Count = 2
Time:  0.93s, ---- Loss: 0.5911, Acc.: 0.7547, Val. Loss: 0.8356, Val. Acc.: 0.7445
Epoch 60
Loss did not decrease. Count = 3
Time:  0.94s, ---- Loss: 0.5894, Acc.: 0.7546, Val. Loss: 0.8356, Val. Acc.: 0.7458
Epoch 61
Validation loss decreased. Saved checkpoint for step 62: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-28
Time:  1.05s, ---- Loss: 0.5857, Acc.: 0.7550, Val. Loss: 0.8330, Val. Acc.: 0.7445
Epoch 62
Loss did not decrease. Count = 1
Time:  0.95s, ---- Loss: 0.5927, Acc.: 0.7550, Val. Loss: 0.8347, Val. Acc.: 0.7455
Epoch 63
Validation loss decreased. Saved checkpoint for step 64: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-29
Time:  1.05s, ---- Loss: 0.5881, Acc.: 0.7552, Val. Loss: 0.8327, Val. Acc.: 0.7466
Epoch 64
Loss did not decrease. Count = 1
Time:  0.93s, ---- Loss: 0.5829, Acc.: 0.7551, Val. Loss: 0.8343, Val. Acc.: 0.7433
Epoch 65
Loss did not decrease. Count = 2
Time:  0.94s, ---- Loss: 0.5828, Acc.: 0.7553, Val. Loss: 0.8349, Val. Acc.: 0.7441
Epoch 66
Loss did not decrease. Count = 3
Time:  0.94s, ---- Loss: 0.5801, Acc.: 0.7547, Val. Loss: 0.8340, Val. Acc.: 0.7459
Epoch 67
Loss did not decrease. Count = 4
Time:  0.93s, ---- Loss: 0.5868, Acc.: 0.7551, Val. Loss: 0.8332, Val. Acc.: 0.7468
Epoch 68
Validation loss decreased. Saved checkpoint for step 69: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-30
Time:  1.05s, ---- Loss: 0.5825, Acc.: 0.7552, Val. Loss: 0.8313, Val. Acc.: 0.7460
Epoch 69
Validation loss decreased. Saved checkpoint for step 70: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-31
Time:  1.06s, ---- Loss: 0.5858, Acc.: 0.7554, Val. Loss: 0.8312, Val. Acc.: 0.7475
Epoch 70
Loss did not decrease. Count = 1
Time:  0.93s, ---- Loss: 0.5871, Acc.: 0.7555, Val. Loss: 0.8340, Val. Acc.: 0.7439
Epoch 71
Loss did not decrease. Count = 2
Time:  0.93s, ---- Loss: 0.5874, Acc.: 0.7562, Val. Loss: 0.8338, Val. Acc.: 0.7457
Epoch 72
Loss did not decrease. Count = 3
Time:  0.93s, ---- Loss: 0.5853, Acc.: 0.7562, Val. Loss: 0.8322, Val. Acc.: 0.7451
Epoch 73
Validation loss decreased. Saved checkpoint for step 74: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-32
Time:  1.06s, ---- Loss: 0.5839, Acc.: 0.7560, Val. Loss: 0.8308, Val. Acc.: 0.7462
Epoch 74
Validation loss decreased. Saved checkpoint for step 75: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-33
Time:  1.07s, ---- Loss: 0.5836, Acc.: 0.7560, Val. Loss: 0.8294, Val. Acc.: 0.7459
Epoch 75
Loss did not decrease. Count = 1
Time:  0.93s, ---- Loss: 0.5834, Acc.: 0.7560, Val. Loss: 0.8318, Val. Acc.: 0.7456
Epoch 76
Loss did not decrease. Count = 2
Time:  0.93s, ---- Loss: 0.5795, Acc.: 0.7554, Val. Loss: 0.8308, Val. Acc.: 0.7469
Epoch 77
Loss did not decrease. Count = 3
Time:  0.95s, ---- Loss: 0.5809, Acc.: 0.7558, Val. Loss: 0.8311, Val. Acc.: 0.7472
Epoch 78
Loss did not decrease. Count = 4
Time:  0.94s, ---- Loss: 0.5791, Acc.: 0.7563, Val. Loss: 0.8314, Val. Acc.: 0.7457
Epoch 79
Loss did not decrease. Count = 5
Time:  0.92s, ---- Loss: 0.5816, Acc.: 0.7568, Val. Loss: 0.8308, Val. Acc.: 0.7471
Epoch 80
Loss did not decrease. Count = 6
Time:  0.93s, ---- Loss: 0.5834, Acc.: 0.7564, Val. Loss: 0.8305, Val. Acc.: 0.7474
Epoch 81
Loss did not decrease. Count = 7
Time:  0.95s, ---- Loss: 0.5774, Acc.: 0.7566, Val. Loss: 0.8297, Val. Acc.: 0.7480
Epoch 82
Loss did not decrease. Count = 8
Time:  0.94s, ---- Loss: 0.5796, Acc.: 0.7569, Val. Loss: 0.8316, Val. Acc.: 0.7465
Epoch 83
Loss did not decrease. Count = 9
Time:  0.94s, ---- Loss: 0.5808, Acc.: 0.7562, Val. Loss: 0.8303, Val. Acc.: 0.7460
Epoch 84
Loss did not decrease. Count = 10
Time:  0.94s, ---- Loss: 0.5860, Acc.: 0.7573, Val. Loss: 0.8314, Val. Acc.: 0.7458
Epoch 85
Loss did not decrease. Count = 11
Time:  0.94s, ---- Loss: 0.5811, Acc.: 0.7563, Val. Loss: 0.8310, Val. Acc.: 0.7464
Epoch 86
Loss did not decrease. Count = 12
Time:  0.93s, ---- Loss: 0.5839, Acc.: 0.7570, Val. Loss: 0.8296, Val. Acc.: 0.7463
Epoch 87
Validation loss decreased. Saved checkpoint for step 88: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-34
Time:  1.05s, ---- Loss: 0.5790, Acc.: 0.7564, Val. Loss: 0.8292, Val. Acc.: 0.7472
Epoch 88
Loss did not decrease. Count = 1
Time:  0.94s, ---- Loss: 0.5825, Acc.: 0.7567, Val. Loss: 0.8296, Val. Acc.: 0.7481
Epoch 89
Loss did not decrease. Count = 2
Time:  0.96s, ---- Loss: 0.5775, Acc.: 0.7571, Val. Loss: 0.8302, Val. Acc.: 0.7461
Epoch 90
Loss did not decrease. Count = 3
Time:  0.94s, ---- Loss: 0.5790, Acc.: 0.7568, Val. Loss: 0.8304, Val. Acc.: 0.7467
Epoch 91
Loss did not decrease. Count = 4
Time:  0.93s, ---- Loss: 0.5866, Acc.: 0.7566, Val. Loss: 0.8303, Val. Acc.: 0.7469
Epoch 92
Loss did not decrease. Count = 5
Time:  0.93s, ---- Loss: 0.5862, Acc.: 0.7572, Val. Loss: 0.8294, Val. Acc.: 0.7470
Epoch 93
Loss did not decrease. Count = 6
Time:  0.93s, ---- Loss: 0.5781, Acc.: 0.7574, Val. Loss: 0.8298, Val. Acc.: 0.7483
Epoch 94
Loss did not decrease. Count = 7
Time:  0.93s, ---- Loss: 0.5774, Acc.: 0.7568, Val. Loss: 0.8292, Val. Acc.: 0.7471
Epoch 95
Loss did not decrease. Count = 8
Time:  0.93s, ---- Loss: 0.5784, Acc.: 0.7570, Val. Loss: 0.8302, Val. Acc.: 0.7465
Epoch 96
Loss did not decrease. Count = 9
Time:  0.94s, ---- Loss: 0.5791, Acc.: 0.7573, Val. Loss: 0.8293, Val. Acc.: 0.7467
Epoch 97
Loss did not decrease. Count = 10
Time:  0.94s, ---- Loss: 0.5850, Acc.: 0.7571, Val. Loss: 0.8315, Val. Acc.: 0.7464
Epoch 98
Loss did not decrease. Count = 11
Time:  0.94s, ---- Loss: 0.5807, Acc.: 0.7577, Val. Loss: 0.8295, Val. Acc.: 0.7488
Epoch 99
Loss did not decrease. Count = 12
Time:  0.93s, ---- Loss: 0.5795, Acc.: 0.7576, Val. Loss: 0.8294, Val. Acc.: 0.7480
Saving at models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/hist.png
Done in 1104.89s

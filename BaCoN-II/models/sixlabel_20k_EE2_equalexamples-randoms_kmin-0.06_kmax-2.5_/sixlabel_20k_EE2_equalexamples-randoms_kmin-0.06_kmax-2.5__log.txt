
 -------- Parameters:
bayesian True
test_mode False
n_test_idx 2
seed 1312
fine_tune False
one_vs_all False
c_0 ['lcdm']
c_1 ['True', 'dgp', 'ds', 'fR', 'rand--save_ckpt', 'wcdm']
dataset_balanced False
include_last False
log_path models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5__log.txt
restore False
fname sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_
model_name custom
my_path None
DIR data/train
TEST_DIR data/test
models_dir models/
save_ckpt True
out_path_overwrite False
curves_folder data/curve_files_sys/theory_error
save_processed_spectra False
cache_dir False
im_depth 500
im_width 1
im_channels 4
swap_axes True
sort_labels True
norm_data_name /planck_ee2.txt
normalization stdcosmo
sample_pace 1
k_max 2.5
k_min 0.06
i_max None
i_min None
add_noise True
n_noisy_samples 10
add_shot False
add_sys True
add_cosvar True
sigma_sys None
sys_scaled None
sys_factor None
sys_max None
sigma_curves 0.05
sigma_curves_default 0.05
rescale_curves uniform
z_bins [0, 1, 2, 3]
n_dense 1
filters [8, 16, 32]
kernel_sizes [10, 5, 2]
strides [2, 2, 1]
pool_sizes [2, 2, 0]
strides_pooling [2, 1, 0]
add_FT_dense False
trainable False
unfreeze False
lr 0.01
drop 0.5
n_epochs 100
val_size 0.15
test_size 0.0
batch_size 12000
patience 20
GPU True
TPU False
decay 0.95
BatchNorm True
padding valid
shuffle True

------------ CREATING DATA GENERATORS ------------
labels : ['dgp', 'ds', 'fr', 'lcdm', 'rand', 'wcdm']
Labels encoding: 
{'dgp': 0, 'ds': 1, 'fr': 2, 'lcdm': 3, 'rand': 4, 'wcdm': 5}
n_labels : 6
dgp - 20000 training examples
ds - 20000 training examples
fr - 20000 training examples
lcdm - 20000 training examples
rand - 20000 training examples
wcdm - 20000 training examples

N. of data files: 20000
get_all_indexes labels dict: {'dgp': 0, 'ds': 1, 'fr': 2, 'lcdm': 3, 'rand': 4, 'wcdm': 5}
create_generators n_labels: 6
create_generators n_labels_eff: 6
create_generators len_c1: 1
Check for no duplicates in test: (0=ok):
0.0
Check for no duplicates in val: (0=ok):
0
N of indexes in training set: 17000
N of indexes in validation set: 3000
N of indexes in test set: 0
Check - total per class: 20000
--create_generators, train indexes
batch_size: 12000
- Cut sample
bs: 12000
N_labels: 6
N_noise: 10
len_c1: 1
Train index length: 17000
--create_generators, validation indexes
- Cut sample
bs: 12000
N_labels: 6
N_noise: 10
len_c1: 1
Val index length: 3000
len(train_index_1), batch_size, n_labels_eff, n_noisy_samples = 17000, 12000, 6, 10

--DataSet Train
DataSet Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 2.5
Corresponding i_max is 399
Closest k to k_max is 2.504942
Specified k_min is 0.06
Corresponding i_min is 129
Closest k to k_min is 0.05964185
New data dim: (270, 1)
Final i_max used is 399
Final i_min used is 129
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 6
N. n_classes in output: 6
LABELS: ['dgp', 'ds', 'fr', 'lcdm', 'rand', 'wcdm']
list_IDs length: 17000
n_indexes (n of file IDs read for each batch): 200
batch size: 12000
n_batches : 85
For each batch we read 200 file IDs
For each file ID we have 6 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 12000 training examples
Input batch size: 12000
N of batches to cover all file IDs: 85
len(fname_list), batch_size, n_noisy_samples, n_batches: 102000, 12000, 10, 85

--DataSet Validation
DataSet Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 2.5
Corresponding i_max is 399
Closest k to k_max is 2.504942
Specified k_min is 0.06
Corresponding i_min is 129
Closest k to k_min is 0.05964185
New data dim: (270, 1)
Final i_max used is 399
Final i_min used is 129
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 6
N. n_classes in output: 6
LABELS: ['dgp', 'ds', 'fr', 'lcdm', 'rand', 'wcdm']
list_IDs length: 3000
n_indexes (n of file IDs read for each batch): 200
batch size: 12000
n_batches : 15
For each batch we read 200 file IDs
For each file ID we have 6 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 12000 training examples
Input batch size: 12000
N of batches to cover all file IDs: 15
len(fname_list), batch_size, n_noisy_samples, n_batches: 18000, 12000, 10, 15
------------ DONE ------------

------------ BUILDING MODEL ------------
Input shape (270, 4)
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 270, 4)]          0         
                                                                 
 conv1d_flipout (Conv1DFlip  (None, 131, 8)            648       
 out)                                                            
                                                                 
 max_pooling1d (MaxPooling1  (None, 65, 8)             0         
 D)                                                              
                                                                 
 batch_normalization (Batch  (None, 65, 8)             32        
 Normalization)                                                  
                                                                 
 conv1d_flipout_1 (Conv1DFl  (None, 31, 16)            1296      
 ipout)                                                          
                                                                 
 max_pooling1d_1 (MaxPoolin  (None, 30, 16)            0         
 g1D)                                                            
                                                                 
 batch_normalization_1 (Bat  (None, 30, 16)            64        
 chNormalization)                                                
                                                                 
 conv1d_flipout_2 (Conv1DFl  (None, 29, 32)            2080      
 ipout)                                                          
                                                                 
 batch_normalization_2 (Bat  (None, 29, 32)            128       
 chNormalization)                                                
                                                                 
 global_average_pooling1d (  (None, 32)                0         
 GlobalAveragePooling1D)                                         
                                                                 
 dense_flipout (DenseFlipou  (None, 32)                2080      
 t)                                                              
                                                                 
 batch_normalization_3 (Bat  (None, 32)                128       
 chNormalization)                                                
                                                                 
 dense_flipout_1 (DenseFlip  (None, 6)                 390       
 out)                                                            
                                                                 
=================================================================
Total params: 6846 (26.74 KB)
Trainable params: 6670 (26.05 KB)
Non-trainable params: 176 (704.00 Byte)
_________________________________________________________________
None
Found GPU at: /device:GPU:0
------------ TRAINING ------------

Features shape: (12000, 270, 4)
Labels shape: (12000, 6)
Initializing checkpoint from scratch.
Epoch 0
Validation loss decreased. Saved checkpoint for step 1: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-1
Time:  43.02s, ---- Loss: 1.2309, Acc.: 0.4217, Val. Loss: 1.8066, Val. Acc.: 0.2362

Epoch 1
Validation loss decreased. Saved checkpoint for step 2: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-2
Time:  2.11s, ---- Loss: 1.1035, Acc.: 0.5356, Val. Loss: 1.6354, Val. Acc.: 0.3450

Epoch 2
Loss did not decrease. Count = 1
Time:  1.97s, ---- Loss: 0.9934, Acc.: 0.5826, Val. Loss: 1.8194, Val. Acc.: 0.3416

Epoch 3
Loss did not decrease. Count = 2
Time:  1.99s, ---- Loss: 0.9253, Acc.: 0.6232, Val. Loss: 1.8263, Val. Acc.: 0.3623

Epoch 4
Validation loss decreased. Saved checkpoint for step 5: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-3
Time:  2.11s, ---- Loss: 0.8895, Acc.: 0.6406, Val. Loss: 1.5296, Val. Acc.: 0.4453

Epoch 5
Validation loss decreased. Saved checkpoint for step 6: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-4
Time:  2.12s, ---- Loss: 0.8677, Acc.: 0.6514, Val. Loss: 1.3671, Val. Acc.: 0.4903

Epoch 6
Validation loss decreased. Saved checkpoint for step 7: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-5
Time:  2.09s, ---- Loss: 0.8503, Acc.: 0.6591, Val. Loss: 1.1747, Val. Acc.: 0.5446

Epoch 7
Validation loss decreased. Saved checkpoint for step 8: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-6
Time:  2.10s, ---- Loss: 0.8288, Acc.: 0.6660, Val. Loss: 1.0287, Val. Acc.: 0.6011

Epoch 8
Validation loss decreased. Saved checkpoint for step 9: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-7
Time:  2.09s, ---- Loss: 0.8257, Acc.: 0.6709, Val. Loss: 0.9363, Val. Acc.: 0.6425

Epoch 9
Validation loss decreased. Saved checkpoint for step 10: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-8
Time:  2.12s, ---- Loss: 0.8152, Acc.: 0.6753, Val. Loss: 0.8992, Val. Acc.: 0.6621

Epoch 10
Validation loss decreased. Saved checkpoint for step 11: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-9
Time:  2.09s, ---- Loss: 0.8045, Acc.: 0.6794, Val. Loss: 0.8918, Val. Acc.: 0.6655

Epoch 11
Validation loss decreased. Saved checkpoint for step 12: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-10
Time:  2.09s, ---- Loss: 0.7940, Acc.: 0.6825, Val. Loss: 0.8837, Val. Acc.: 0.6676

Epoch 12
Loss did not decrease. Count = 1
Time:  1.97s, ---- Loss: 0.7829, Acc.: 0.6864, Val. Loss: 0.9146, Val. Acc.: 0.6523

Epoch 13
Loss did not decrease. Count = 2
Time:  1.96s, ---- Loss: 0.7766, Acc.: 0.6891, Val. Loss: 0.9149, Val. Acc.: 0.6509

Epoch 14
Loss did not decrease. Count = 3
Time:  1.98s, ---- Loss: 0.7687, Acc.: 0.6926, Val. Loss: 0.9116, Val. Acc.: 0.6536

Epoch 15
Loss did not decrease. Count = 4
Time:  1.99s, ---- Loss: 0.7579, Acc.: 0.6966, Val. Loss: 0.9836, Val. Acc.: 0.6379

Epoch 16
Loss did not decrease. Count = 5
Time:  1.97s, ---- Loss: 0.7409, Acc.: 0.7009, Val. Loss: 1.0798, Val. Acc.: 0.6067

Epoch 17
Loss did not decrease. Count = 6
Time:  1.98s, ---- Loss: 0.7326, Acc.: 0.7049, Val. Loss: 1.0549, Val. Acc.: 0.6138

Epoch 18
Loss did not decrease. Count = 7
Time:  1.96s, ---- Loss: 0.7292, Acc.: 0.7081, Val. Loss: 0.9819, Val. Acc.: 0.6355

Epoch 19
Loss did not decrease. Count = 8
Time:  1.97s, ---- Loss: 0.7219, Acc.: 0.7103, Val. Loss: 0.9141, Val. Acc.: 0.6570

Epoch 20
Validation loss decreased. Saved checkpoint for step 21: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-11
Time:  2.11s, ---- Loss: 0.7228, Acc.: 0.7126, Val. Loss: 0.8693, Val. Acc.: 0.6734

Epoch 21
Validation loss decreased. Saved checkpoint for step 22: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-12
Time:  2.10s, ---- Loss: 0.7148, Acc.: 0.7139, Val. Loss: 0.8326, Val. Acc.: 0.6883

Epoch 22
Validation loss decreased. Saved checkpoint for step 23: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-13
Time:  2.10s, ---- Loss: 0.7104, Acc.: 0.7153, Val. Loss: 0.8254, Val. Acc.: 0.6895

Epoch 23
Validation loss decreased. Saved checkpoint for step 24: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-14
Time:  2.09s, ---- Loss: 0.7099, Acc.: 0.7168, Val. Loss: 0.8018, Val. Acc.: 0.6984

Epoch 24
Validation loss decreased. Saved checkpoint for step 25: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-15
Time:  2.10s, ---- Loss: 0.7058, Acc.: 0.7182, Val. Loss: 0.7891, Val. Acc.: 0.7053

Epoch 25
Validation loss decreased. Saved checkpoint for step 26: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-16
Time:  2.09s, ---- Loss: 0.6962, Acc.: 0.7194, Val. Loss: 0.7770, Val. Acc.: 0.7107

Epoch 26
Validation loss decreased. Saved checkpoint for step 27: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-17
Time:  2.11s, ---- Loss: 0.6971, Acc.: 0.7210, Val. Loss: 0.7740, Val. Acc.: 0.7120

Epoch 27
Validation loss decreased. Saved checkpoint for step 28: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-18
Time:  2.09s, ---- Loss: 0.6957, Acc.: 0.7213, Val. Loss: 0.7699, Val. Acc.: 0.7144

Epoch 28
Validation loss decreased. Saved checkpoint for step 29: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-19
Time:  2.08s, ---- Loss: 0.6891, Acc.: 0.7222, Val. Loss: 0.7643, Val. Acc.: 0.7176

Epoch 29
Validation loss decreased. Saved checkpoint for step 30: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-20
Time:  2.08s, ---- Loss: 0.6893, Acc.: 0.7233, Val. Loss: 0.7599, Val. Acc.: 0.7178

Epoch 30
Validation loss decreased. Saved checkpoint for step 31: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-21
Time:  2.09s, ---- Loss: 0.6819, Acc.: 0.7236, Val. Loss: 0.7592, Val. Acc.: 0.7187

Epoch 31
Validation loss decreased. Saved checkpoint for step 32: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-22
Time:  2.10s, ---- Loss: 0.6820, Acc.: 0.7246, Val. Loss: 0.7528, Val. Acc.: 0.7211

Epoch 32
Validation loss decreased. Saved checkpoint for step 33: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-23
Time:  2.08s, ---- Loss: 0.6804, Acc.: 0.7254, Val. Loss: 0.7524, Val. Acc.: 0.7216

Epoch 33
Validation loss decreased. Saved checkpoint for step 34: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-24
Time:  2.11s, ---- Loss: 0.6798, Acc.: 0.7256, Val. Loss: 0.7500, Val. Acc.: 0.7214

Epoch 34
Validation loss decreased. Saved checkpoint for step 35: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-25
Time:  2.09s, ---- Loss: 0.6776, Acc.: 0.7266, Val. Loss: 0.7478, Val. Acc.: 0.7228

Epoch 35
Validation loss decreased. Saved checkpoint for step 36: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-26
Time:  2.08s, ---- Loss: 0.6737, Acc.: 0.7269, Val. Loss: 0.7452, Val. Acc.: 0.7249

Epoch 36
Validation loss decreased. Saved checkpoint for step 37: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-27
Time:  2.10s, ---- Loss: 0.6742, Acc.: 0.7273, Val. Loss: 0.7432, Val. Acc.: 0.7242

Epoch 37
Validation loss decreased. Saved checkpoint for step 38: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-28
Time:  2.10s, ---- Loss: 0.6738, Acc.: 0.7278, Val. Loss: 0.7426, Val. Acc.: 0.7253

Epoch 38
Validation loss decreased. Saved checkpoint for step 39: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-29
Time:  2.08s, ---- Loss: 0.6725, Acc.: 0.7285, Val. Loss: 0.7407, Val. Acc.: 0.7258

Epoch 39
Validation loss decreased. Saved checkpoint for step 40: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-30
Time:  2.08s, ---- Loss: 0.6712, Acc.: 0.7288, Val. Loss: 0.7384, Val. Acc.: 0.7260

Epoch 40
Validation loss decreased. Saved checkpoint for step 41: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-31
Time:  2.09s, ---- Loss: 0.6693, Acc.: 0.7291, Val. Loss: 0.7384, Val. Acc.: 0.7265

Epoch 41
Validation loss decreased. Saved checkpoint for step 42: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-32
Time:  2.08s, ---- Loss: 0.6671, Acc.: 0.7298, Val. Loss: 0.7367, Val. Acc.: 0.7276

Epoch 42
Validation loss decreased. Saved checkpoint for step 43: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-33
Time:  2.13s, ---- Loss: 0.6712, Acc.: 0.7299, Val. Loss: 0.7360, Val. Acc.: 0.7270

Epoch 43
Validation loss decreased. Saved checkpoint for step 44: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-34
Time:  2.10s, ---- Loss: 0.6669, Acc.: 0.7300, Val. Loss: 0.7355, Val. Acc.: 0.7276

Epoch 44
Validation loss decreased. Saved checkpoint for step 45: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-35
Time:  2.09s, ---- Loss: 0.6669, Acc.: 0.7303, Val. Loss: 0.7346, Val. Acc.: 0.7277

Epoch 45
Validation loss decreased. Saved checkpoint for step 46: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-36
Time:  2.09s, ---- Loss: 0.6669, Acc.: 0.7309, Val. Loss: 0.7335, Val. Acc.: 0.7285

Epoch 46
Validation loss decreased. Saved checkpoint for step 47: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-37
Time:  2.11s, ---- Loss: 0.6643, Acc.: 0.7311, Val. Loss: 0.7324, Val. Acc.: 0.7296

Epoch 47
Validation loss decreased. Saved checkpoint for step 48: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-38
Time:  2.12s, ---- Loss: 0.6640, Acc.: 0.7314, Val. Loss: 0.7321, Val. Acc.: 0.7296

Epoch 48
Validation loss decreased. Saved checkpoint for step 49: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-39
Time:  2.12s, ---- Loss: 0.6643, Acc.: 0.7320, Val. Loss: 0.7307, Val. Acc.: 0.7303

Epoch 49
Validation loss decreased. Saved checkpoint for step 50: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-40
Time:  2.14s, ---- Loss: 0.6611, Acc.: 0.7320, Val. Loss: 0.7305, Val. Acc.: 0.7300

Epoch 50
Validation loss decreased. Saved checkpoint for step 51: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-41
Time:  2.15s, ---- Loss: 0.6614, Acc.: 0.7323, Val. Loss: 0.7286, Val. Acc.: 0.7306

Epoch 51
Loss did not decrease. Count = 1
Time:  2.00s, ---- Loss: 0.6618, Acc.: 0.7325, Val. Loss: 0.7296, Val. Acc.: 0.7309

Epoch 52
Loss did not decrease. Count = 2
Time:  1.96s, ---- Loss: 0.6585, Acc.: 0.7329, Val. Loss: 0.7290, Val. Acc.: 0.7311

Epoch 53
Loss did not decrease. Count = 3
Time:  1.99s, ---- Loss: 0.6582, Acc.: 0.7329, Val. Loss: 0.7290, Val. Acc.: 0.7309

Epoch 54
Validation loss decreased. Saved checkpoint for step 55: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-42
Time:  2.09s, ---- Loss: 0.6594, Acc.: 0.7333, Val. Loss: 0.7281, Val. Acc.: 0.7311

Epoch 55
Validation loss decreased. Saved checkpoint for step 56: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-43
Time:  2.09s, ---- Loss: 0.6584, Acc.: 0.7331, Val. Loss: 0.7278, Val. Acc.: 0.7309

Epoch 56
Validation loss decreased. Saved checkpoint for step 57: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-44
Time:  2.10s, ---- Loss: 0.6608, Acc.: 0.7336, Val. Loss: 0.7269, Val. Acc.: 0.7310

Epoch 57
Validation loss decreased. Saved checkpoint for step 58: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-45
Time:  2.10s, ---- Loss: 0.6590, Acc.: 0.7337, Val. Loss: 0.7263, Val. Acc.: 0.7315

Epoch 58
Validation loss decreased. Saved checkpoint for step 59: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-46
Time:  2.11s, ---- Loss: 0.6576, Acc.: 0.7337, Val. Loss: 0.7259, Val. Acc.: 0.7318

Epoch 59
Loss did not decrease. Count = 1
Time:  1.98s, ---- Loss: 0.6567, Acc.: 0.7340, Val. Loss: 0.7272, Val. Acc.: 0.7317

Epoch 60
Loss did not decrease. Count = 2
Time:  1.97s, ---- Loss: 0.6557, Acc.: 0.7343, Val. Loss: 0.7259, Val. Acc.: 0.7315

Epoch 61
Validation loss decreased. Saved checkpoint for step 62: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-47
Time:  2.07s, ---- Loss: 0.6566, Acc.: 0.7342, Val. Loss: 0.7253, Val. Acc.: 0.7317

Epoch 62
Validation loss decreased. Saved checkpoint for step 63: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-48
Time:  2.10s, ---- Loss: 0.6528, Acc.: 0.7345, Val. Loss: 0.7247, Val. Acc.: 0.7320

Epoch 63
Validation loss decreased. Saved checkpoint for step 64: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-49
Time:  2.08s, ---- Loss: 0.6556, Acc.: 0.7349, Val. Loss: 0.7238, Val. Acc.: 0.7326

Epoch 64
Loss did not decrease. Count = 1
Time:  1.98s, ---- Loss: 0.6568, Acc.: 0.7348, Val. Loss: 0.7242, Val. Acc.: 0.7320

Epoch 65
Loss did not decrease. Count = 2
Time:  1.98s, ---- Loss: 0.6549, Acc.: 0.7353, Val. Loss: 0.7240, Val. Acc.: 0.7319

Epoch 66
Validation loss decreased. Saved checkpoint for step 67: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-50
Time:  2.09s, ---- Loss: 0.6544, Acc.: 0.7347, Val. Loss: 0.7231, Val. Acc.: 0.7331

Epoch 67
Validation loss decreased. Saved checkpoint for step 68: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-51
Time:  2.09s, ---- Loss: 0.6536, Acc.: 0.7352, Val. Loss: 0.7225, Val. Acc.: 0.7326

Epoch 68
Validation loss decreased. Saved checkpoint for step 69: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-52
Time:  2.10s, ---- Loss: 0.6519, Acc.: 0.7355, Val. Loss: 0.7223, Val. Acc.: 0.7332

Epoch 69
Validation loss decreased. Saved checkpoint for step 70: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-53
Time:  2.10s, ---- Loss: 0.6522, Acc.: 0.7352, Val. Loss: 0.7223, Val. Acc.: 0.7334

Epoch 70
Validation loss decreased. Saved checkpoint for step 71: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-54
Time:  2.10s, ---- Loss: 0.6531, Acc.: 0.7355, Val. Loss: 0.7217, Val. Acc.: 0.7339

Epoch 71
Validation loss decreased. Saved checkpoint for step 72: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-55
Time:  2.08s, ---- Loss: 0.6528, Acc.: 0.7354, Val. Loss: 0.7217, Val. Acc.: 0.7329

Epoch 72
Validation loss decreased. Saved checkpoint for step 73: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-56
Time:  2.08s, ---- Loss: 0.6511, Acc.: 0.7356, Val. Loss: 0.7213, Val. Acc.: 0.7338

Epoch 73
Loss did not decrease. Count = 1
Time:  1.97s, ---- Loss: 0.6529, Acc.: 0.7357, Val. Loss: 0.7214, Val. Acc.: 0.7331

Epoch 74
Validation loss decreased. Saved checkpoint for step 75: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-57
Time:  2.09s, ---- Loss: 0.6495, Acc.: 0.7356, Val. Loss: 0.7210, Val. Acc.: 0.7343

Epoch 75
Validation loss decreased. Saved checkpoint for step 76: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-58
Time:  2.11s, ---- Loss: 0.6509, Acc.: 0.7351, Val. Loss: 0.7206, Val. Acc.: 0.7340

Epoch 76
Loss did not decrease. Count = 1
Time:  1.98s, ---- Loss: 0.6505, Acc.: 0.7358, Val. Loss: 0.7213, Val. Acc.: 0.7334

Epoch 77
Loss did not decrease. Count = 2
Time:  1.97s, ---- Loss: 0.6520, Acc.: 0.7360, Val. Loss: 0.7208, Val. Acc.: 0.7338

Epoch 78
Validation loss decreased. Saved checkpoint for step 79: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-59
Time:  2.10s, ---- Loss: 0.6514, Acc.: 0.7362, Val. Loss: 0.7205, Val. Acc.: 0.7347

Epoch 79
Validation loss decreased. Saved checkpoint for step 80: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-60
Time:  2.09s, ---- Loss: 0.6497, Acc.: 0.7361, Val. Loss: 0.7197, Val. Acc.: 0.7349

Epoch 80
Loss did not decrease. Count = 1
Time:  1.99s, ---- Loss: 0.6507, Acc.: 0.7362, Val. Loss: 0.7201, Val. Acc.: 0.7343

Epoch 81
Loss did not decrease. Count = 2
Time:  2.00s, ---- Loss: 0.6509, Acc.: 0.7362, Val. Loss: 0.7200, Val. Acc.: 0.7341

Epoch 82
Loss did not decrease. Count = 3
Time:  1.97s, ---- Loss: 0.6509, Acc.: 0.7362, Val. Loss: 0.7198, Val. Acc.: 0.7347

Epoch 83
Validation loss decreased. Saved checkpoint for step 84: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-61
Time:  2.11s, ---- Loss: 0.6485, Acc.: 0.7363, Val. Loss: 0.7193, Val. Acc.: 0.7344

Epoch 84
Loss did not decrease. Count = 1
Time:  1.98s, ---- Loss: 0.6489, Acc.: 0.7366, Val. Loss: 0.7197, Val. Acc.: 0.7340

Epoch 85
Validation loss decreased. Saved checkpoint for step 86: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-62
Time:  2.10s, ---- Loss: 0.6488, Acc.: 0.7363, Val. Loss: 0.7189, Val. Acc.: 0.7350

Epoch 86
Loss did not decrease. Count = 1
Time:  1.99s, ---- Loss: 0.6489, Acc.: 0.7364, Val. Loss: 0.7196, Val. Acc.: 0.7346

Epoch 87
Loss did not decrease. Count = 2
Time:  2.01s, ---- Loss: 0.6480, Acc.: 0.7364, Val. Loss: 0.7194, Val. Acc.: 0.7341

Epoch 88
Loss did not decrease. Count = 3
Time:  1.98s, ---- Loss: 0.6504, Acc.: 0.7365, Val. Loss: 0.7192, Val. Acc.: 0.7350

Epoch 89
Validation loss decreased. Saved checkpoint for step 90: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-63
Time:  2.09s, ---- Loss: 0.6505, Acc.: 0.7364, Val. Loss: 0.7186, Val. Acc.: 0.7354

Epoch 90
Loss did not decrease. Count = 1
Time:  1.97s, ---- Loss: 0.6499, Acc.: 0.7368, Val. Loss: 0.7190, Val. Acc.: 0.7349

Epoch 91
Loss did not decrease. Count = 2
Time:  1.98s, ---- Loss: 0.6480, Acc.: 0.7366, Val. Loss: 0.7188, Val. Acc.: 0.7349

Epoch 92
Loss did not decrease. Count = 3
Time:  1.98s, ---- Loss: 0.6486, Acc.: 0.7369, Val. Loss: 0.7190, Val. Acc.: 0.7345

Epoch 93
Validation loss decreased. Saved checkpoint for step 94: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-64
Time:  2.11s, ---- Loss: 0.6476, Acc.: 0.7366, Val. Loss: 0.7184, Val. Acc.: 0.7352

Epoch 94
Loss did not decrease. Count = 1
Time:  1.97s, ---- Loss: 0.6485, Acc.: 0.7368, Val. Loss: 0.7185, Val. Acc.: 0.7347

Epoch 95
Loss did not decrease. Count = 2
Time:  1.95s, ---- Loss: 0.6477, Acc.: 0.7371, Val. Loss: 0.7185, Val. Acc.: 0.7345

Epoch 96
Validation loss decreased. Saved checkpoint for step 97: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-65
Time:  2.09s, ---- Loss: 0.6491, Acc.: 0.7367, Val. Loss: 0.7183, Val. Acc.: 0.7354

Epoch 97
Loss did not decrease. Count = 1
Time:  1.97s, ---- Loss: 0.6480, Acc.: 0.7369, Val. Loss: 0.7188, Val. Acc.: 0.7353

Epoch 98
Validation loss decreased. Saved checkpoint for step 99: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/tf_ckpts/ckpt-66
Time:  2.10s, ---- Loss: 0.6470, Acc.: 0.7368, Val. Loss: 0.7182, Val. Acc.: 0.7351

Epoch 99
Loss did not decrease. Count = 1
Time:  1.97s, ---- Loss: 0.6486, Acc.: 0.7371, Val. Loss: 0.7182, Val. Acc.: 0.7353

Saving at models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.06_kmax-2.5_/hist.png
Done in 4153.17s

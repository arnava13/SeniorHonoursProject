
 -------- Parameters:
bayesian True
test_mode False
n_test_idx 2
seed 1312
fine_tune False
one_vs_all False
c_0 ['lcdm']
c_1 ['True', 'dgp', 'ds', 'fR', 'rand--save_ckpt', 'wcdm']
dataset_balanced False
include_last False
log_path models/test_log.txt
restore False
fname test
model_name custom
my_path None
DIR data/minimal
TEST_DIR data/test_data/
models_dir models/
save_ckpt True
out_path_overwrite False
curves_folder data/curve_files_sys/theory_error
save_processed_spectra True
im_depth 500
im_width 1
im_channels 4
swap_axes True
sort_labels True
norm_data_name /planck_ee2.txt
normalization stdcosmo
sample_pace 4
k_max 5.0
k_min 0.8508632
i_max None
i_min None
add_noise True
n_noisy_samples 10
add_shot False
add_sys True
add_cosvar True
sigma_sys None
sys_scaled None
sys_factor None
sys_max None
sigma_curves 0.05
sigma_curves_default 0.05
rescale_curves uniform
z_bins [0, 1, 2, 3]
n_dense 1
filters [8, 16, 32]
kernel_sizes [10, 5, 2]
strides [2, 2, 1]
pool_sizes [2, 2, 0]
strides_pooling [2, 1, 0]
add_FT_dense False
trainable False
unfreeze False
lr 0.01
drop 0.5
n_epochs 1
val_size 0.15
test_size 0.0
batch_size 60
patience 50
GPU True
TPU False
decay 0.95
BatchNorm True
padding same
shuffle False

------------ CREATING DATASETS ------------
labels : ['dgp', 'ds_binA', 'fr', 'lcdm', 'rand', 'wcdm']
Labels encoding: 
{'dgp': 0, 'ds_binA': 1, 'fr': 2, 'lcdm': 3, 'rand': 4, 'wcdm': 5}
n_labels : 6
dgp - 20 training examples
ds_binA - 20 training examples
fr - 20 training examples
lcdm - 20 training examples
rand - 20 training examples
wcdm - 20 training examples
get_all_indexes labels dict: {'dgp': 0, 'ds_binA': 1, 'fr': 2, 'lcdm': 3, 'rand': 4, 'wcdm': 5}
create_generators n_labels: 6
create_generators n_labels_eff: 6
create_generators len_c1: 1
Check for no duplicates in test: (0=ok):
0.0
Check for no duplicates in val: (0=ok):
0
N of files in training set: 6N of files in training set: 6N of files in training set: 6N of files in training set: 6N of files in training set: 6N of files in training set: 6N of files in training set: 6N of files in training set: 6N of files in training set: 6N of files in training set: 6N of files in training set: 6N of files in training set: 6N of files in training set: 6N of files in training set: 6N of files in training set: 6N of files in training set: 6N of files in training set: 6
N of files in validation set: 6N of files in validation set: 6N of files in validation set: 6

Check - total per class: 20
--create_generators, train indexes
batch_size: 60
- Cut sample
bs: 60
N_labels: 6
N_noise: 10
len_c1: 1
Train index length: 17
--create_generators, validation indexes
- Cut sample
bs: 60
N_labels: 6
N_noise: 10
len_c1: 1
Val index length: 3
len(train_index_1), batch_size, n_labels_eff, n_noisy_samples = 17, 60, 6, 10

--DataSet Train
DataSet Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 5.0
Corresponding i_max is 112
Closest k to k_max is 4.936132
Specified k_min is 0.8508632
Corresponding i_min is 80
Closest k to k_min is 0.8391656
New data dim: (32, 1)
Final i_max used is 112
Final i_min used is 80
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 6
N. n_classes in output: 6
LABELS: ['dgp', 'ds_binA', 'fr', 'lcdm', 'rand', 'wcdm']
list_IDs length: 17
n_indexes (n of file IDs read for each batch): 1
batch size: 60
n_batches : 17
For each batch we read 1 file IDs
For each file ID we have 6 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 60 training examples
Input batch size: 60
N of batches to cover all file IDs: 17
len(fname_list), batch_size, n_noisy_samples, n_batches: 102, 60, 10, 17
Saving processed (noisy and normalised) spectra in models/test/processed_spectra/processed_spectra_zbin0.txt
Saving processed (noisy and normalised) spectra in models/test/processed_spectra/processed_spectra_zbin1.txt
Saving processed (noisy and normalised) spectra in models/test/processed_spectra/processed_spectra_zbin2.txt
Saving processed (noisy and normalised) spectra in models/test/processed_spectra/processed_spectra_zbin3.txt

--DataSet Validation
DataSet Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 5.0
Corresponding i_max is 112
Closest k to k_max is 4.936132
Specified k_min is 0.8508632
Corresponding i_min is 80
Closest k to k_min is 0.8391656
New data dim: (32, 1)
Final i_max used is 112
Final i_min used is 80
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 6
N. n_classes in output: 6
LABELS: ['dgp', 'ds_binA', 'fr', 'lcdm', 'rand', 'wcdm']
list_IDs length: 3
n_indexes (n of file IDs read for each batch): 1
batch size: 60
n_batches : 3
For each batch we read 1 file IDs
For each file ID we have 6 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 60 training examples
Input batch size: 60
N of batches to cover all file IDs: 3
len(fname_list), batch_size, n_noisy_samples, n_batches: 18, 60, 10, 3
------------ DONE ------------

------------ BUILDING MODEL ------------
Input shape (32, 4)
using 1D layers and 4 channels
Expected output dimension of layer conv1d_flipout: 12.0
Expected output dimension of layer max_pooling1d: 6.0
Expected output dimension of layer conv1d_flipout_1: 1.5
Expected output dimension of layer max_pooling1d_1: 0.5
Expected output dimension of layer conv1d_flipout_2: -0.5
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 32, 4)]           0         
                                                                 
 conv1d_flipout (Conv1DFlip  (None, 16, 8)             648       
 out)                                                            
                                                                 
 max_pooling1d (MaxPooling1  (None, 8, 8)              0         
 D)                                                              
                                                                 
 batch_normalization (Batch  (None, 8, 8)              32        
 Normalization)                                                  
                                                                 
 conv1d_flipout_1 (Conv1DFl  (None, 4, 16)             1296      
 ipout)                                                          
                                                                 
 max_pooling1d_1 (MaxPoolin  (None, 4, 16)             0         
 g1D)                                                            
                                                                 
 batch_normalization_1 (Bat  (None, 4, 16)             64        
 chNormalization)                                                
                                                                 
 conv1d_flipout_2 (Conv1DFl  (None, 4, 32)             2080      
 ipout)                                                          
                                                                 
 batch_normalization_2 (Bat  (None, 4, 32)             128       
 chNormalization)                                                
                                                                 
 global_average_pooling1d (  (None, 32)                0         
 GlobalAveragePooling1D)                                         
                                                                 
 dense_flipout (DenseFlipou  (None, 32)                2080      
 t)                                                              
                                                                 
 batch_normalization_3 (Bat  (None, 32)                128       
 chNormalization)                                                
                                                                 
 dense_flipout_1 (DenseFlip  (None, 6)                 390       
 out)                                                            
                                                                 


 -------- Parameters:
bayesian True
test_mode False
n_test_idx 2
seed 1312
fine_tune False
one_vs_all False
c_0 ['lcdm']
c_1 ['dgp', 'ds', 'fR', 'wcdm']
dataset_balanced False
include_last False
log_path models/model_dark_scattering_train_ds_ee2_100_log.txt
restore False
fname model_dark_scattering_train_ds_ee2_100
model_name custom
my_path None
DIR data/ds_ee2_train_1k
TEST_DIR data/test_data/
models_dir models/
save_ckpt True
out_path_overwrite False
curves_folder data/curve_files_sys/theory_error
save_processed_spectra False
im_depth 500
im_width 1
im_channels 4
swap_axes True
sort_labels True
norm_data_name /planck_ee2.txt
normalization stdcosmo
sample_pace 4
k_max 2.5
i_max None
add_noise True
n_noisy_samples 10
add_shot False
add_sys True
add_cosvar True
sigma_sys None
sys_scaled None
sys_factor None
sys_max None
sigma_curves 0.05
sigma_curves_default 0.05
rescale_curves uniform
z_bins [0, 1, 2, 3]
n_dense 1
filters [8, 16, 32]
kernel_sizes [10, 5, 2]
strides [2, 2, 1]
pool_sizes [2, 2, 0]
strides_pooling [2, 1, 0]
add_FT_dense False
trainable False
unfreeze False
lr 0.01
drop 0.5
n_epochs 50
val_size 0.15
test_size 0.0
batch_size 2500
patience 50
GPU True
decay 0.95
BatchNorm True

------------ CREATING DATA GENERATORS ------------
labels : ['dgp', 'ds', 'fr', 'lcdm', 'wcdm']
Labels encoding: 
{'dgp': 0, 'ds': 1, 'fr': 2, 'lcdm': 3, 'wcdm': 4}
n_labels : 5
dgp - 1000 training examples
ds - 1000 training examples
fr - 1000 training examples
lcdm - 1000 training examples
wcdm - 1000 training examples

N. of data files: 1000
get_all_indexes labels dict: {'dgp': 0, 'ds': 1, 'fr': 2, 'lcdm': 3, 'wcdm': 4}
create_generators n_labels: 5
create_generators n_labels_eff: 5
create_generators len_c1: 1
Check for no duplicates in test: (0=ok):
0.0
Check for no duplicates in val: (0=ok):
0
N of files in training set: 850
N of files in validation set: 150
N of files in test set: 0
Check - total: 1000
--create_generators, train indexes
batch_size: 2500
- Cut sample
bs: 2500
N_labels: 5
N_noise: 10
len_c1: 1
Train index length: 850
--create_generators, validation indexes
- Cut sample
bs: 2500
N_labels: 5
N_noise: 10
len_c1: 1
Val index length: 150
len(train_index_1), batch_size, n_labels_eff, n_noisy_samples = 850, 2500, 5, 10

--DataGenerator Train
Data Generator Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 2.5
Corresponding i_max is 100
Closest k to k_max is 2.539859
New data dim: (100, 1)
Final i_max used is 100
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 5
N. n_classes in output: 5
LABELS: ['dgp', 'ds', 'fr', 'lcdm', 'wcdm']
list_IDs length: 850
n_indexes (n of file IDs read for each batch): 50
batch size: 2500
n_batches : 17
For each batch we read 50 file IDs
For each file ID we have 5 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 2500 training examples
Input batch size: 2500
N of batches to cover all file IDs: 17

--DataGenerator Validation
Data Generator Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 2.5
Corresponding i_max is 100
Closest k to k_max is 2.539859
New data dim: (100, 1)
Final i_max used is 100
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 5
N. n_classes in output: 5
LABELS: ['dgp', 'ds', 'fr', 'lcdm', 'wcdm']
list_IDs length: 150
n_indexes (n of file IDs read for each batch): 50
batch size: 2500
n_batches : 3
For each batch we read 50 file IDs
For each file ID we have 5 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 2500 training examples
Input batch size: 2500
N of batches to cover all file IDs: 3
------------ DONE ------------

------------ BUILDING MODEL ------------
Input shape (100, 4)
using 1D layers and 4 channels
Expected output dimension of layer conv1d_flipout: 46.0
Expected output dimension of layer max_pooling1d: 23.0
Expected output dimension of layer conv1d_flipout_1: 10.0
Expected output dimension of layer max_pooling1d_1: 9.0
Expected output dimension of layer conv1d_flipout_2: 8.0
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 100, 4)]          0         
                                                                 
 conv1d_flipout (Conv1DFlip  (None, 46, 8)             648       
 out)                                                            
                                                                 
 max_pooling1d (MaxPooling1  (None, 23, 8)             0         
 D)                                                              
                                                                 
 batch_normalization (Batch  (None, 23, 8)             32        
 Normalization)                                                  
                                                                 
 conv1d_flipout_1 (Conv1DFl  (None, 10, 16)            1296      
 ipout)                                                          
                                                                 
 max_pooling1d_1 (MaxPoolin  (None, 9, 16)             0         
 g1D)                                                            
                                                                 
 batch_normalization_1 (Bat  (None, 9, 16)             64        
 chNormalization)                                                
                                                                 
 conv1d_flipout_2 (Conv1DFl  (None, 8, 32)             2080      
 ipout)                                                          
                                                                 
 batch_normalization_2 (Bat  (None, 8, 32)             128       
 chNormalization)                                                
                                                                 
 global_average_pooling1d (  (None, 32)                0         
 GlobalAveragePooling1D)                                         
                                                                 
 dense_flipout (DenseFlipou  (None, 32)                2080      
 t)                                                              
                                                                 
 batch_normalization_3 (Bat  (None, 32)                128       
 chNormalization)                                                
                                                                 
 dense_flipout_1 (DenseFlip  (None, 5)                 325       
 out)                                                            
                                                                 
=================================================================
Total params: 6781 (26.49 KB)
Trainable params: 6605 (25.80 KB)
Non-trainable params: 176 (704.00 Byte)
_________________________________________________________________
None
Found GPU at: /device:GPU:0
------------ TRAINING ------------

Features shape: (2500, 100, 4)
Labels shape: (2500, 5)
Initializing checkpoint from scratch.
Epoch 0
Validation loss decreased. Saved checkpoint for step 1: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-1
Time:  77.56s, ---- Loss: 1.5632, Acc.: 0.3292, Val. Loss: 2.6609, Val. Acc.: 0.2241

Epoch 1
Loss did not decrease. Count = 1
Time:  68.48s, ---- Loss: 1.3565, Acc.: 0.4638, Val. Loss: 2.8674, Val. Acc.: 0.2015

Epoch 2
Loss did not decrease. Count = 2
Time:  68.38s, ---- Loss: 1.2285, Acc.: 0.5350, Val. Loss: 3.4083, Val. Acc.: 0.2663

Epoch 3
Loss did not decrease. Count = 3
Time:  68.53s, ---- Loss: 1.1661, Acc.: 0.5580, Val. Loss: 3.7362, Val. Acc.: 0.2735

Epoch 4
Loss did not decrease. Count = 4
Time:  68.63s, ---- Loss: 1.1756, Acc.: 0.5693, Val. Loss: 3.6498, Val. Acc.: 0.2715

Epoch 5
Loss did not decrease. Count = 5
Time:  68.60s, ---- Loss: 1.1746, Acc.: 0.5782, Val. Loss: 3.4928, Val. Acc.: 0.2715

Epoch 6
Loss did not decrease. Count = 6
Time:  68.63s, ---- Loss: 1.1551, Acc.: 0.5816, Val. Loss: 3.3605, Val. Acc.: 0.2795

Epoch 7
Loss did not decrease. Count = 7
Time:  68.68s, ---- Loss: 1.1294, Acc.: 0.5875, Val. Loss: 3.2512, Val. Acc.: 0.2825

Epoch 8
Loss did not decrease. Count = 8
Time:  68.51s, ---- Loss: 1.1100, Acc.: 0.5897, Val. Loss: 3.1301, Val. Acc.: 0.2905

Epoch 9
Loss did not decrease. Count = 9
Time:  68.44s, ---- Loss: 1.0888, Acc.: 0.5959, Val. Loss: 3.0232, Val. Acc.: 0.2937

Epoch 10
Loss did not decrease. Count = 10
Time:  68.25s, ---- Loss: 1.1242, Acc.: 0.5986, Val. Loss: 2.9712, Val. Acc.: 0.2967

Epoch 11
Loss did not decrease. Count = 11
Time:  68.33s, ---- Loss: 1.0883, Acc.: 0.6039, Val. Loss: 2.8377, Val. Acc.: 0.3032

Epoch 12
Loss did not decrease. Count = 12
Time:  68.32s, ---- Loss: 1.0723, Acc.: 0.6057, Val. Loss: 2.7427, Val. Acc.: 0.3095

Epoch 13
Validation loss decreased. Saved checkpoint for step 14: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-2
Time:  68.43s, ---- Loss: 1.0776, Acc.: 0.6100, Val. Loss: 2.6349, Val. Acc.: 0.3280

Epoch 14
Validation loss decreased. Saved checkpoint for step 15: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-3
Time:  68.51s, ---- Loss: 1.0715, Acc.: 0.6130, Val. Loss: 2.5361, Val. Acc.: 0.3477

Epoch 15
Validation loss decreased. Saved checkpoint for step 16: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-4
Time:  68.41s, ---- Loss: 1.0556, Acc.: 0.6117, Val. Loss: 2.4539, Val. Acc.: 0.3652

Epoch 16
Validation loss decreased. Saved checkpoint for step 17: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-5
Time:  68.54s, ---- Loss: 1.0601, Acc.: 0.6177, Val. Loss: 2.3606, Val. Acc.: 0.4072

Epoch 17
Validation loss decreased. Saved checkpoint for step 18: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-6
Time:  68.65s, ---- Loss: 1.0509, Acc.: 0.6196, Val. Loss: 2.2539, Val. Acc.: 0.4355

Epoch 18
Loss did not decrease. Count = 1
Time:  68.51s, ---- Loss: 1.0399, Acc.: 0.6207, Val. Loss: 2.2597, Val. Acc.: 0.4391

Epoch 19
Validation loss decreased. Saved checkpoint for step 20: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-7
Time:  68.57s, ---- Loss: 1.0257, Acc.: 0.6220, Val. Loss: 2.1302, Val. Acc.: 0.4939

Epoch 20
Validation loss decreased. Saved checkpoint for step 21: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-8
Time:  68.64s, ---- Loss: 1.0466, Acc.: 0.6231, Val. Loss: 2.0404, Val. Acc.: 0.5225

Epoch 21
Validation loss decreased. Saved checkpoint for step 22: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-9
Time:  68.56s, ---- Loss: 1.0423, Acc.: 0.6276, Val. Loss: 2.0243, Val. Acc.: 0.5281

Epoch 22
Validation loss decreased. Saved checkpoint for step 23: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-10
Time:  68.58s, ---- Loss: 1.0179, Acc.: 0.6253, Val. Loss: 1.9817, Val. Acc.: 0.5431

Epoch 23
Validation loss decreased. Saved checkpoint for step 24: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-11
Time:  68.72s, ---- Loss: 1.0078, Acc.: 0.6281, Val. Loss: 1.9247, Val. Acc.: 0.5680

Epoch 24
Validation loss decreased. Saved checkpoint for step 25: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-12
Time:  68.68s, ---- Loss: 1.0314, Acc.: 0.6300, Val. Loss: 1.9160, Val. Acc.: 0.5733

Epoch 25
Validation loss decreased. Saved checkpoint for step 26: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-13
Time:  68.82s, ---- Loss: 1.0055, Acc.: 0.6291, Val. Loss: 1.8689, Val. Acc.: 0.5885

Epoch 26
Validation loss decreased. Saved checkpoint for step 27: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-14
Time:  68.60s, ---- Loss: 1.0006, Acc.: 0.6312, Val. Loss: 1.8356, Val. Acc.: 0.6015

Epoch 27
Loss did not decrease. Count = 1
Time:  68.57s, ---- Loss: 0.9874, Acc.: 0.6317, Val. Loss: 1.8413, Val. Acc.: 0.5933

Epoch 28
Validation loss decreased. Saved checkpoint for step 29: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-15
Time:  68.63s, ---- Loss: 0.9905, Acc.: 0.6346, Val. Loss: 1.8286, Val. Acc.: 0.6011

Epoch 29
Validation loss decreased. Saved checkpoint for step 30: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-16
Time:  68.47s, ---- Loss: 0.9833, Acc.: 0.6347, Val. Loss: 1.7972, Val. Acc.: 0.6207

Epoch 30
Validation loss decreased. Saved checkpoint for step 31: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-17
Time:  68.52s, ---- Loss: 0.9762, Acc.: 0.6376, Val. Loss: 1.7935, Val. Acc.: 0.6211

Epoch 31
Validation loss decreased. Saved checkpoint for step 32: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-18
Time:  68.58s, ---- Loss: 1.0002, Acc.: 0.6407, Val. Loss: 1.7728, Val. Acc.: 0.6276

Epoch 32
Loss did not decrease. Count = 1
Time:  68.55s, ---- Loss: 0.9910, Acc.: 0.6438, Val. Loss: 1.7913, Val. Acc.: 0.6231

Epoch 33
Validation loss decreased. Saved checkpoint for step 34: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-19
Time:  68.48s, ---- Loss: 0.9845, Acc.: 0.6432, Val. Loss: 1.7702, Val. Acc.: 0.6224

Epoch 34
Validation loss decreased. Saved checkpoint for step 35: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-20
Time:  68.49s, ---- Loss: 0.9589, Acc.: 0.6392, Val. Loss: 1.7549, Val. Acc.: 0.6304

Epoch 35
Validation loss decreased. Saved checkpoint for step 36: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-21
Time:  68.78s, ---- Loss: 0.9739, Acc.: 0.6423, Val. Loss: 1.7548, Val. Acc.: 0.6297

Epoch 36
Validation loss decreased. Saved checkpoint for step 37: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-22
Time:  68.61s, ---- Loss: 1.0101, Acc.: 0.6473, Val. Loss: 1.7472, Val. Acc.: 0.6356

Epoch 37
Validation loss decreased. Saved checkpoint for step 38: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-23
Time:  68.71s, ---- Loss: 0.9985, Acc.: 0.6441, Val. Loss: 1.7361, Val. Acc.: 0.6368

Epoch 38
Loss did not decrease. Count = 1
Time:  68.50s, ---- Loss: 0.9723, Acc.: 0.6473, Val. Loss: 1.7476, Val. Acc.: 0.6379

Epoch 39
Loss did not decrease. Count = 2
Time:  68.46s, ---- Loss: 0.9694, Acc.: 0.6467, Val. Loss: 1.7363, Val. Acc.: 0.6387

Epoch 40
Loss did not decrease. Count = 3
Time:  68.37s, ---- Loss: 0.9829, Acc.: 0.6469, Val. Loss: 1.7371, Val. Acc.: 0.6367

Epoch 41
Validation loss decreased. Saved checkpoint for step 42: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-24
Time:  68.74s, ---- Loss: 0.9781, Acc.: 0.6466, Val. Loss: 1.7339, Val. Acc.: 0.6336

Epoch 42
Loss did not decrease. Count = 1
Time:  68.36s, ---- Loss: 0.9635, Acc.: 0.6499, Val. Loss: 1.7463, Val. Acc.: 0.6377

Epoch 43
Validation loss decreased. Saved checkpoint for step 44: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-25
Time:  68.69s, ---- Loss: 0.9771, Acc.: 0.6463, Val. Loss: 1.7293, Val. Acc.: 0.6393

Epoch 44
Validation loss decreased. Saved checkpoint for step 45: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-26
Time:  68.48s, ---- Loss: 0.9610, Acc.: 0.6482, Val. Loss: 1.7261, Val. Acc.: 0.6421

Epoch 45
Validation loss decreased. Saved checkpoint for step 46: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-27
Time:  68.63s, ---- Loss: 0.9500, Acc.: 0.6497, Val. Loss: 1.7258, Val. Acc.: 0.6404

Epoch 46
Validation loss decreased. Saved checkpoint for step 47: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-28
Time:  68.66s, ---- Loss: 0.9557, Acc.: 0.6512, Val. Loss: 1.7223, Val. Acc.: 0.6413

Epoch 47
Validation loss decreased. Saved checkpoint for step 48: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-29
Time:  68.56s, ---- Loss: 0.9390, Acc.: 0.6517, Val. Loss: 1.7216, Val. Acc.: 0.6453

Epoch 48
Validation loss decreased. Saved checkpoint for step 49: models/model_dark_scattering_train_ds_ee2_100/tf_ckpts/ckpt-30
Time:  68.71s, ---- Loss: 0.9552, Acc.: 0.6500, Val. Loss: 1.7137, Val. Acc.: 0.6503

Epoch 49
Loss did not decrease. Count = 1
Time:  68.71s, ---- Loss: 0.9403, Acc.: 0.6528, Val. Loss: 1.7210, Val. Acc.: 0.6433

Saving at models/model_dark_scattering_train_ds_ee2_100/hist.png
Done in 3445.38s

2024-04-08 04:55:08.100294: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-04-08 04:55:08.100350: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-04-08 04:55:08.102215: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-04-08 04:55:09.199113: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-04-08 04:55:11.740024: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
using 1D layers and 4 channels
/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:98: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.
loc = add_variable_fn(
/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:108: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.
untransformed_scale = add_variable_fn(
Expected output dimension after layer: conv1d_flipout : 97
Expected output dimension after layer: conv1d_flipout_1 : 46
Expected output dimension after layer: conv1d_flipout_2 : 45
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1712553109.780285    4071 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Creating directory models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB
-------- Parameters:
bayesian True
test_mode False
n_test_idx 2
seed 1312
fine_tune False
one_vs_all False
c_0 ['lcdm']
c_1 ['True', 'dgp', 'ds', 'fR', 'rand--save_ckpt', 'wcdm']
dataset_balanced False
include_last False
log_path models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB_log.txt
restore False
fname sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB
model_name custom
my_path None
DIR data/train
TEST_DIR data/test/
models_dir models/
save_ckpt True
out_path_overwrite False
curves_folder data/curve_files_sys/theory_error
save_processed_spectra False
cache_dir False
im_depth 500
im_width 1
im_channels 4
swap_axes True
sort_labels True
norm_data_name /planck_ee2.txt
normalization stdcosmo
sample_pace 1
k_max 2.5
k_min 0.0
i_max None
i_min None
add_noise True
n_noisy_samples 10
add_shot False
add_sys True
add_cosvar True
sigma_sys None
sys_scaled None
sys_factor None
sys_max None
sigma_curves 0.05
sigma_curves_default 0.05
rescale_curves uniform
z_bins [0, 1, 2, 3]
n_dense 1
filters [8, 16, 32]
kernel_sizes [10, 5, 2]
strides [2, 2, 1]
pool_sizes [2, 2, 0]
strides_pooling [2, 1, 0]
add_FT_dense False
trainable False
unfreeze False
lr 0.01
drop 0.5
n_epochs 100
val_size 0.15
test_size 0.0
batch_size 3000
patience 20
GPU True
TPU False
decay 0.95
BatchNorm True
padding valid
shuffle True
------------ CREATING DATA GENERATORS ------------
labels : ['dgp', 'ds_binB', 'fr', 'lcdm', 'rand', 'wcdm']
Labels encoding:
{'dgp': 0, 'ds_binB': 1, 'fr': 2, 'lcdm': 3, 'rand': 4, 'wcdm': 5}
n_labels : 6
dgp - 5000 training examples
ds_binB - 5000 training examples
fr - 5000 training examples
lcdm - 5000 training examples
rand - 5000 training examples
wcdm - 5000 training examples
N. of data files: 5000
get_all_indexes labels dict: {'dgp': 0, 'ds_binB': 1, 'fr': 2, 'lcdm': 3, 'rand': 4, 'wcdm': 5}
create_generators n_labels: 6
create_generators n_labels_eff: 6
create_generators len_c1: 1
Check for no duplicates in test: (0=ok):
0.0
Check for no duplicates in val: (0=ok):
0
N of indexes in training set: 4250
N of indexes in validation set: 750
N of indexes in test set: 0
Check - total per class: 5000
--create_generators, train indexes
batch_size: 3000
- Cut sample
bs: 3000
N_labels: 6
N_noise: 10
len_c1: 1
Train index length: 4250
--create_generators, validation indexes
- Cut sample
bs: 3000
N_labels: 6
N_noise: 10
len_c1: 1
Val index length: 750
len(train_index_1), batch_size, n_labels_eff, n_noisy_samples = 4250, 3000, 6, 10
--DataSet Train
DataSet Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 2.5
Corresponding i_max is 399
Closest k to k_max is 2.504942
Specified k_min is 0.0
Corresponding i_min is 0
Closest k to k_min is 0.01
New data dim: (399, 1)
Final i_max used is 399
Final i_min used is 0
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 6
N. n_classes in output: 6
LABELS: ['dgp', 'ds_binB', 'fr', 'lcdm', 'rand', 'wcdm']
list_IDs length: 4250
n_indexes (n of file IDs read for each batch): 50
batch size: 3000
n_batches : 85
For each batch we read 50 file IDs
For each file ID we have 6 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 3000 training examples
Input batch size: 3000
N of batches to cover all file IDs: 85
len(fname_list), batch_size, n_noisy_samples, n_batches: 25500, 3000, 10, 85
--DataSet Validation
DataSet Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 2.5
Corresponding i_max is 399
Closest k to k_max is 2.504942
Specified k_min is 0.0
Corresponding i_min is 0
Closest k to k_min is 0.01
New data dim: (399, 1)
Final i_max used is 399
Final i_min used is 0
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 6
N. n_classes in output: 6
LABELS: ['dgp', 'ds_binB', 'fr', 'lcdm', 'rand', 'wcdm']
list_IDs length: 750
n_indexes (n of file IDs read for each batch): 50
batch size: 3000
n_batches : 15
For each batch we read 50 file IDs
For each file ID we have 6 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 3000 training examples
Input batch size: 3000
N of batches to cover all file IDs: 15
len(fname_list), batch_size, n_noisy_samples, n_batches: 4500, 3000, 10, 15
------------ DONE ------------
------------ BUILDING MODEL ------------
Input shape (399, 4)
Model: "model"
_________________________________________________________________
Layer (type)                Output Shape              Param #
=================================================================
input_1 (InputLayer)        [(None, 399, 4)]          0
conv1d_flipout (Conv1DFlip  (None, 195, 8)            648
out)
max_pooling1d (MaxPooling1  (None, 97, 8)             0
D)
batch_normalization (Batch  (None, 97, 8)             32
Normalization)
conv1d_flipout_1 (Conv1DFl  (None, 47, 16)            1296
ipout)
max_pooling1d_1 (MaxPoolin  (None, 46, 16)            0
g1D)
batch_normalization_1 (Bat  (None, 46, 16)            64
chNormalization)
conv1d_flipout_2 (Conv1DFl  (None, 45, 32)            2080
ipout)
batch_normalization_2 (Bat  (None, 45, 32)            128
chNormalization)
global_average_pooling1d (  (None, 32)                0
GlobalAveragePooling1D)
dense_flipout (DenseFlipou  (None, 32)                2080
t)
batch_normalization_3 (Bat  (None, 32)                128
chNormalization)
dense_flipout_1 (DenseFlip  (None, 6)                 390
out)
=================================================================
Total params: 6846 (26.74 KB)
Trainable params: 6670 (26.05 KB)
Non-trainable params: 176 (704.00 Byte)
_________________________________________________________________
None
Found GPU at: /device:GPU:0
------------ TRAINING ------------
Features shape: (3000, 399, 4)
Labels shape: (3000, 6)
Initializing checkpoint from scratch.
Epoch 0
Validation loss decreased. Saved checkpoint for step 1: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-1
Time:  38.13s, ---- Loss: 1.1761, Acc.: 0.4492, Val. Loss: 2.3787, Val. Acc.: 0.1915
Epoch 1
Loss did not decrease. Count = 1
Time:  1.07s, ---- Loss: 0.9818, Acc.: 0.5792, Val. Loss: 2.7080, Val. Acc.: 0.2742
Epoch 2
Validation loss decreased. Saved checkpoint for step 3: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-2
Time:  1.18s, ---- Loss: 0.8634, Acc.: 0.6349, Val. Loss: 1.9472, Val. Acc.: 0.4481
Epoch 3
Validation loss decreased. Saved checkpoint for step 4: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-3
Time:  1.18s, ---- Loss: 0.8257, Acc.: 0.6625, Val. Loss: 1.3983, Val. Acc.: 0.5567
Epoch 4
Validation loss decreased. Saved checkpoint for step 5: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-4
Time:  1.16s, ---- Loss: 0.8142, Acc.: 0.6775, Val. Loss: 1.2448, Val. Acc.: 0.5939
Epoch 5
Validation loss decreased. Saved checkpoint for step 6: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-5
Time:  1.17s, ---- Loss: 0.7902, Acc.: 0.6890, Val. Loss: 1.1918, Val. Acc.: 0.6054
Epoch 6
Validation loss decreased. Saved checkpoint for step 7: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-6
Time:  1.17s, ---- Loss: 0.7392, Acc.: 0.6985, Val. Loss: 1.1610, Val. Acc.: 0.6203
Epoch 7
Validation loss decreased. Saved checkpoint for step 8: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-7
Time:  1.18s, ---- Loss: 0.7284, Acc.: 0.7060, Val. Loss: 1.1139, Val. Acc.: 0.6274
Epoch 8
Loss did not decrease. Count = 1
Time:  1.07s, ---- Loss: 0.7126, Acc.: 0.7114, Val. Loss: 1.1342, Val. Acc.: 0.6250
Epoch 9
Validation loss decreased. Saved checkpoint for step 10: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-8
Time:  1.21s, ---- Loss: 0.6963, Acc.: 0.7162, Val. Loss: 1.1052, Val. Acc.: 0.6380
Epoch 10
Validation loss decreased. Saved checkpoint for step 11: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-9
Time:  1.18s, ---- Loss: 0.6935, Acc.: 0.7215, Val. Loss: 0.9974, Val. Acc.: 0.6827
Epoch 11
Loss did not decrease. Count = 1
Time:  1.06s, ---- Loss: 0.6714, Acc.: 0.7258, Val. Loss: 1.0394, Val. Acc.: 0.6668
Epoch 12
Validation loss decreased. Saved checkpoint for step 13: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-10
Time:  1.19s, ---- Loss: 0.6663, Acc.: 0.7280, Val. Loss: 0.9886, Val. Acc.: 0.6908
Epoch 13
Validation loss decreased. Saved checkpoint for step 14: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-11
Time:  1.18s, ---- Loss: 0.6681, Acc.: 0.7314, Val. Loss: 0.9644, Val. Acc.: 0.6990
Epoch 14
Validation loss decreased. Saved checkpoint for step 15: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-12
Time:  1.19s, ---- Loss: 0.6582, Acc.: 0.7334, Val. Loss: 0.9400, Val. Acc.: 0.7081
Epoch 15
Validation loss decreased. Saved checkpoint for step 16: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-13
Time:  1.17s, ---- Loss: 0.6500, Acc.: 0.7359, Val. Loss: 0.9275, Val. Acc.: 0.7133
Epoch 16
Validation loss decreased. Saved checkpoint for step 17: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-14
Time:  1.18s, ---- Loss: 0.6422, Acc.: 0.7378, Val. Loss: 0.9255, Val. Acc.: 0.7138
Epoch 17
Loss did not decrease. Count = 1
Time:  1.06s, ---- Loss: 0.6424, Acc.: 0.7397, Val. Loss: 0.9300, Val. Acc.: 0.7148
Epoch 18
Loss did not decrease. Count = 2
Time:  1.06s, ---- Loss: 0.6397, Acc.: 0.7420, Val. Loss: 0.9291, Val. Acc.: 0.7161
Epoch 19
Validation loss decreased. Saved checkpoint for step 20: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-15
Time:  1.19s, ---- Loss: 0.6336, Acc.: 0.7423, Val. Loss: 0.8966, Val. Acc.: 0.7254
Epoch 20
Validation loss decreased. Saved checkpoint for step 21: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-16
Time:  1.19s, ---- Loss: 0.6367, Acc.: 0.7446, Val. Loss: 0.8952, Val. Acc.: 0.7264
Epoch 21
Validation loss decreased. Saved checkpoint for step 22: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-17
Time:  1.19s, ---- Loss: 0.6252, Acc.: 0.7454, Val. Loss: 0.8919, Val. Acc.: 0.7286
Epoch 22
Loss did not decrease. Count = 1
Time:  1.05s, ---- Loss: 0.6241, Acc.: 0.7473, Val. Loss: 0.9250, Val. Acc.: 0.7158
Epoch 23
Loss did not decrease. Count = 2
Time:  1.07s, ---- Loss: 0.6203, Acc.: 0.7486, Val. Loss: 0.9300, Val. Acc.: 0.7176
Epoch 24
Loss did not decrease. Count = 3
Time:  1.08s, ---- Loss: 0.6141, Acc.: 0.7501, Val. Loss: 0.9175, Val. Acc.: 0.7204
Epoch 25
Loss did not decrease. Count = 4
Time:  1.06s, ---- Loss: 0.6081, Acc.: 0.7514, Val. Loss: 0.8950, Val. Acc.: 0.7299
Epoch 26
Loss did not decrease. Count = 5
Time:  1.05s, ---- Loss: 0.6116, Acc.: 0.7521, Val. Loss: 0.8971, Val. Acc.: 0.7264
Epoch 27
Validation loss decreased. Saved checkpoint for step 28: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-18
Time:  1.18s, ---- Loss: 0.6056, Acc.: 0.7533, Val. Loss: 0.8626, Val. Acc.: 0.7400
Epoch 28
Validation loss decreased. Saved checkpoint for step 29: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-19
Time:  1.19s, ---- Loss: 0.5975, Acc.: 0.7538, Val. Loss: 0.8619, Val. Acc.: 0.7396
Epoch 29
Loss did not decrease. Count = 1
Time:  1.04s, ---- Loss: 0.6002, Acc.: 0.7546, Val. Loss: 0.8757, Val. Acc.: 0.7340
Epoch 30
Loss did not decrease. Count = 2
Time:  1.04s, ---- Loss: 0.6002, Acc.: 0.7569, Val. Loss: 0.9393, Val. Acc.: 0.7077
Epoch 31
Loss did not decrease. Count = 3
Time:  1.00s, ---- Loss: 0.5967, Acc.: 0.7574, Val. Loss: 0.8829, Val. Acc.: 0.7344
Epoch 32
Validation loss decreased. Saved checkpoint for step 33: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-20
Time:  1.12s, ---- Loss: 0.6048, Acc.: 0.7581, Val. Loss: 0.8496, Val. Acc.: 0.7452
Epoch 33
Validation loss decreased. Saved checkpoint for step 34: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-21
Time:  1.10s, ---- Loss: 0.5970, Acc.: 0.7592, Val. Loss: 0.8461, Val. Acc.: 0.7491
Epoch 34
Loss did not decrease. Count = 1
Time:  0.97s, ---- Loss: 0.5965, Acc.: 0.7596, Val. Loss: 0.8901, Val. Acc.: 0.7336
Epoch 35
Loss did not decrease. Count = 2
Time:  0.98s, ---- Loss: 0.5895, Acc.: 0.7607, Val. Loss: 0.9191, Val. Acc.: 0.7225
Epoch 36
Loss did not decrease. Count = 3
Time:  1.04s, ---- Loss: 0.5899, Acc.: 0.7611, Val. Loss: 0.8687, Val. Acc.: 0.7394
Epoch 37
Loss did not decrease. Count = 4
Time:  1.08s, ---- Loss: 0.5826, Acc.: 0.7619, Val. Loss: 0.8606, Val. Acc.: 0.7428
Epoch 38
Loss did not decrease. Count = 5
Time:  1.07s, ---- Loss: 0.5880, Acc.: 0.7627, Val. Loss: 0.8651, Val. Acc.: 0.7420
Epoch 39
Validation loss decreased. Saved checkpoint for step 40: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-22
Time:  1.24s, ---- Loss: 0.5870, Acc.: 0.7620, Val. Loss: 0.8296, Val. Acc.: 0.7548
Epoch 40
Loss did not decrease. Count = 1
Time:  1.10s, ---- Loss: 0.5833, Acc.: 0.7631, Val. Loss: 0.8408, Val. Acc.: 0.7521
Epoch 41
Loss did not decrease. Count = 2
Time:  1.02s, ---- Loss: 0.5850, Acc.: 0.7640, Val. Loss: 0.8491, Val. Acc.: 0.7484
Epoch 42
Loss did not decrease. Count = 3
Time:  1.04s, ---- Loss: 0.5832, Acc.: 0.7641, Val. Loss: 0.8433, Val. Acc.: 0.7512
Epoch 43
Loss did not decrease. Count = 4
Time:  1.06s, ---- Loss: 0.5833, Acc.: 0.7645, Val. Loss: 0.8359, Val. Acc.: 0.7541
Epoch 44
Loss did not decrease. Count = 5
Time:  1.05s, ---- Loss: 0.5830, Acc.: 0.7655, Val. Loss: 0.8450, Val. Acc.: 0.7496
Epoch 45
Validation loss decreased. Saved checkpoint for step 46: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-23
Time:  1.19s, ---- Loss: 0.5815, Acc.: 0.7650, Val. Loss: 0.8087, Val. Acc.: 0.7635
Epoch 46
Validation loss decreased. Saved checkpoint for step 47: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-24
Time:  1.21s, ---- Loss: 0.5813, Acc.: 0.7663, Val. Loss: 0.8047, Val. Acc.: 0.7656
Epoch 47
Loss did not decrease. Count = 1
Time:  1.06s, ---- Loss: 0.5797, Acc.: 0.7664, Val. Loss: 0.8121, Val. Acc.: 0.7627
Epoch 48
Loss did not decrease. Count = 2
Time:  1.06s, ---- Loss: 0.5746, Acc.: 0.7670, Val. Loss: 0.8114, Val. Acc.: 0.7620
Epoch 49
Loss did not decrease. Count = 3
Time:  1.08s, ---- Loss: 0.5777, Acc.: 0.7671, Val. Loss: 0.8110, Val. Acc.: 0.7626
Epoch 50
Loss did not decrease. Count = 4
Time:  1.06s, ---- Loss: 0.5804, Acc.: 0.7679, Val. Loss: 0.8143, Val. Acc.: 0.7621
Epoch 51
Loss did not decrease. Count = 5
Time:  1.04s, ---- Loss: 0.5797, Acc.: 0.7680, Val. Loss: 0.8159, Val. Acc.: 0.7615
Epoch 52
Loss did not decrease. Count = 6
Time:  1.05s, ---- Loss: 0.5788, Acc.: 0.7680, Val. Loss: 0.8079, Val. Acc.: 0.7650
Epoch 53
Loss did not decrease. Count = 7
Time:  1.05s, ---- Loss: 0.5762, Acc.: 0.7675, Val. Loss: 0.8105, Val. Acc.: 0.7642
Epoch 54
Loss did not decrease. Count = 8
Time:  1.05s, ---- Loss: 0.5754, Acc.: 0.7683, Val. Loss: 0.8100, Val. Acc.: 0.7624
Epoch 55
Loss did not decrease. Count = 9
Time:  1.05s, ---- Loss: 0.5842, Acc.: 0.7681, Val. Loss: 0.8113, Val. Acc.: 0.7641
Epoch 56
Loss did not decrease. Count = 10
Time:  1.04s, ---- Loss: 0.5731, Acc.: 0.7683, Val. Loss: 0.8097, Val. Acc.: 0.7641
Epoch 57
Loss did not decrease. Count = 11
Time:  1.05s, ---- Loss: 0.5796, Acc.: 0.7685, Val. Loss: 0.8067, Val. Acc.: 0.7651
Epoch 58
Loss did not decrease. Count = 12
Time:  1.05s, ---- Loss: 0.5774, Acc.: 0.7691, Val. Loss: 0.8080, Val. Acc.: 0.7652
Epoch 59
Loss did not decrease. Count = 13
Time:  1.06s, ---- Loss: 0.5732, Acc.: 0.7687, Val. Loss: 0.8052, Val. Acc.: 0.7658
Epoch 60
Validation loss decreased. Saved checkpoint for step 61: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-25
Time:  1.20s, ---- Loss: 0.5752, Acc.: 0.7690, Val. Loss: 0.8018, Val. Acc.: 0.7683
Epoch 61
Loss did not decrease. Count = 1
Time:  1.07s, ---- Loss: 0.5742, Acc.: 0.7692, Val. Loss: 0.8039, Val. Acc.: 0.7668
Epoch 62
Loss did not decrease. Count = 2
Time:  1.05s, ---- Loss: 0.5738, Acc.: 0.7693, Val. Loss: 0.8021, Val. Acc.: 0.7662
Epoch 63
Validation loss decreased. Saved checkpoint for step 64: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-26
Time:  1.18s, ---- Loss: 0.5746, Acc.: 0.7698, Val. Loss: 0.7987, Val. Acc.: 0.7681
Epoch 64
Loss did not decrease. Count = 1
Time:  1.04s, ---- Loss: 0.5730, Acc.: 0.7697, Val. Loss: 0.8004, Val. Acc.: 0.7691
Epoch 65
Loss did not decrease. Count = 2
Time:  1.06s, ---- Loss: 0.5723, Acc.: 0.7703, Val. Loss: 0.8000, Val. Acc.: 0.7689
Epoch 66
Loss did not decrease. Count = 3
Time:  1.07s, ---- Loss: 0.5708, Acc.: 0.7703, Val. Loss: 0.7994, Val. Acc.: 0.7696
Epoch 67
Loss did not decrease. Count = 4
Time:  1.05s, ---- Loss: 0.5772, Acc.: 0.7701, Val. Loss: 0.8000, Val. Acc.: 0.7670
Epoch 68
Loss did not decrease. Count = 5
Time:  1.05s, ---- Loss: 0.5720, Acc.: 0.7701, Val. Loss: 0.8004, Val. Acc.: 0.7693
Epoch 69
Loss did not decrease. Count = 6
Time:  1.04s, ---- Loss: 0.5733, Acc.: 0.7705, Val. Loss: 0.7991, Val. Acc.: 0.7694
Epoch 70
Validation loss decreased. Saved checkpoint for step 71: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-27
Time:  1.21s, ---- Loss: 0.5756, Acc.: 0.7700, Val. Loss: 0.7980, Val. Acc.: 0.7701
Epoch 71
Loss did not decrease. Count = 1
Time:  1.07s, ---- Loss: 0.5742, Acc.: 0.7707, Val. Loss: 0.7986, Val. Acc.: 0.7687
Epoch 72
Loss did not decrease. Count = 2
Time:  1.02s, ---- Loss: 0.5764, Acc.: 0.7701, Val. Loss: 0.7989, Val. Acc.: 0.7691
Epoch 73
Loss did not decrease. Count = 3
Time:  1.01s, ---- Loss: 0.5656, Acc.: 0.7706, Val. Loss: 0.8005, Val. Acc.: 0.7680
Epoch 74
Loss did not decrease. Count = 4
Time:  0.99s, ---- Loss: 0.5689, Acc.: 0.7707, Val. Loss: 0.7983, Val. Acc.: 0.7686
Epoch 75
Validation loss decreased. Saved checkpoint for step 76: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-28
Time:  1.13s, ---- Loss: 0.5670, Acc.: 0.7705, Val. Loss: 0.7979, Val. Acc.: 0.7699
Epoch 76
Loss did not decrease. Count = 1
Time:  1.02s, ---- Loss: 0.5713, Acc.: 0.7711, Val. Loss: 0.7984, Val. Acc.: 0.7704
Epoch 77
Loss did not decrease. Count = 2
Time:  1.06s, ---- Loss: 0.5733, Acc.: 0.7713, Val. Loss: 0.7987, Val. Acc.: 0.7691
Epoch 78
Loss did not decrease. Count = 3
Time:  1.07s, ---- Loss: 0.5648, Acc.: 0.7705, Val. Loss: 0.7984, Val. Acc.: 0.7698
Epoch 79
Validation loss decreased. Saved checkpoint for step 80: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-29
Time:  1.20s, ---- Loss: 0.5745, Acc.: 0.7709, Val. Loss: 0.7979, Val. Acc.: 0.7695
Epoch 80
Loss did not decrease. Count = 1
Time:  1.07s, ---- Loss: 0.5715, Acc.: 0.7712, Val. Loss: 0.7985, Val. Acc.: 0.7687
Epoch 81
Validation loss decreased. Saved checkpoint for step 82: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-30
Time:  1.17s, ---- Loss: 0.5715, Acc.: 0.7715, Val. Loss: 0.7972, Val. Acc.: 0.7703
Epoch 82
Loss did not decrease. Count = 1
Time:  1.04s, ---- Loss: 0.5694, Acc.: 0.7710, Val. Loss: 0.7974, Val. Acc.: 0.7681
Epoch 83
Validation loss decreased. Saved checkpoint for step 84: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-31
Time:  1.18s, ---- Loss: 0.5710, Acc.: 0.7718, Val. Loss: 0.7961, Val. Acc.: 0.7697
Epoch 84
Loss did not decrease. Count = 1
Time:  1.04s, ---- Loss: 0.5722, Acc.: 0.7716, Val. Loss: 0.7971, Val. Acc.: 0.7706
Epoch 85
Validation loss decreased. Saved checkpoint for step 86: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-32
Time:  1.18s, ---- Loss: 0.5709, Acc.: 0.7712, Val. Loss: 0.7959, Val. Acc.: 0.7694
Epoch 86
Validation loss decreased. Saved checkpoint for step 87: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-33
Time:  1.16s, ---- Loss: 0.5696, Acc.: 0.7717, Val. Loss: 0.7958, Val. Acc.: 0.7700
Epoch 87
Validation loss decreased. Saved checkpoint for step 88: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/tf_ckpts/ckpt-34
Time:  1.16s, ---- Loss: 0.5662, Acc.: 0.7718, Val. Loss: 0.7943, Val. Acc.: 0.7706
Epoch 88
Loss did not decrease. Count = 1
Time:  1.05s, ---- Loss: 0.5705, Acc.: 0.7716, Val. Loss: 0.7957, Val. Acc.: 0.7704
Epoch 89
Loss did not decrease. Count = 2
Time:  1.06s, ---- Loss: 0.5708, Acc.: 0.7718, Val. Loss: 0.7964, Val. Acc.: 0.7696
Epoch 90
Loss did not decrease. Count = 3
Time:  1.04s, ---- Loss: 0.5746, Acc.: 0.7720, Val. Loss: 0.7963, Val. Acc.: 0.7694
Epoch 91
Loss did not decrease. Count = 4
Time:  1.06s, ---- Loss: 0.5701, Acc.: 0.7720, Val. Loss: 0.7958, Val. Acc.: 0.7704
Epoch 92
Loss did not decrease. Count = 5
Time:  1.06s, ---- Loss: 0.5685, Acc.: 0.7717, Val. Loss: 0.7948, Val. Acc.: 0.7710
Epoch 93
Loss did not decrease. Count = 6
Time:  1.05s, ---- Loss: 0.5675, Acc.: 0.7717, Val. Loss: 0.7951, Val. Acc.: 0.7708
Epoch 94
Loss did not decrease. Count = 7
Time:  1.06s, ---- Loss: 0.5669, Acc.: 0.7726, Val. Loss: 0.7943, Val. Acc.: 0.7717
Epoch 95
Loss did not decrease. Count = 8
Time:  1.05s, ---- Loss: 0.5687, Acc.: 0.7721, Val. Loss: 0.7958, Val. Acc.: 0.7711
Epoch 96
Loss did not decrease. Count = 9
Time:  1.05s, ---- Loss: 0.5669, Acc.: 0.7722, Val. Loss: 0.7961, Val. Acc.: 0.7706
Epoch 97
Loss did not decrease. Count = 10
Time:  1.07s, ---- Loss: 0.5628, Acc.: 0.7720, Val. Loss: 0.7967, Val. Acc.: 0.7692
Epoch 98
Loss did not decrease. Count = 11
Time:  1.05s, ---- Loss: 0.5661, Acc.: 0.7721, Val. Loss: 0.7952, Val. Acc.: 0.7709
Epoch 99
Loss did not decrease. Count = 12
Time:  1.03s, ---- Loss: 0.5694, Acc.: 0.7721, Val. Loss: 0.7959, Val. Acc.: 0.7698
Saving at models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binB/hist.png
Done in 1139.51s

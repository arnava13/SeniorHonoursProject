2024-04-01 12:42:32.245541: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-04-01 12:42:32.245585: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-04-01 12:42:32.247501: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-04-01 12:42:33.273235: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-04-01 12:42:35.712320: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
using 1D layers and 4 channels
/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:98: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.
loc = add_variable_fn(
/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:108: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.
untransformed_scale = add_variable_fn(
Expected output dimension after layer: conv1d_flipout : 48
Expected output dimension after layer: conv1d_flipout_1 : 21
Expected output dimension after layer: conv1d_flipout_2 : 20
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1711979202.050060  204170 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Creating directory models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_
-------- Parameters:
bayesian True
test_mode False
n_test_idx 2
seed 1312
fine_tune False
one_vs_all False
c_0 ['lcdm']
c_1 ['True', 'dgp', 'ds', 'fR', 'rand--save_ckpt', 'wcdm']
dataset_balanced False
include_last False
log_path models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5__log.txt
restore False
fname sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_
model_name custom
my_path None
DIR data/train
TEST_DIR data/test
models_dir models/
save_ckpt True
out_path_overwrite False
curves_folder data/curve_files_sys/theory_error
save_processed_spectra False
cache_dir False
im_depth 500
im_width 1
im_channels 4
swap_axes True
sort_labels True
norm_data_name /planck_ee2.txt
normalization stdcosmo
sample_pace 1
k_max 2.5
k_min 0.15
i_max None
i_min None
add_noise True
n_noisy_samples 10
add_shot False
add_sys True
add_cosvar True
sigma_sys None
sys_scaled None
sys_factor None
sys_max None
sigma_curves 0.05
sigma_curves_default 0.05
rescale_curves uniform
z_bins [0, 1, 2, 3]
n_dense 1
filters [8, 16, 32]
kernel_sizes [10, 5, 2]
strides [2, 2, 1]
pool_sizes [2, 2, 0]
strides_pooling [2, 1, 0]
add_FT_dense False
trainable False
unfreeze False
lr 0.01
drop 0.5
n_epochs 100
val_size 0.15
test_size 0.0
batch_size 12000
patience 20
GPU True
TPU False
decay 0.95
BatchNorm True
padding valid
shuffle True
------------ CREATING DATA GENERATORS ------------
labels : ['dgp', 'ds', 'fr', 'lcdm', 'rand', 'wcdm']
Labels encoding:
{'dgp': 0, 'ds': 1, 'fr': 2, 'lcdm': 3, 'rand': 4, 'wcdm': 5}
n_labels : 6
dgp - 20000 training examples
ds - 20000 training examples
fr - 20000 training examples
lcdm - 20000 training examples
rand - 20000 training examples
wcdm - 20000 training examples
N. of data files: 20000
get_all_indexes labels dict: {'dgp': 0, 'ds': 1, 'fr': 2, 'lcdm': 3, 'rand': 4, 'wcdm': 5}
create_generators n_labels: 6
create_generators n_labels_eff: 6
create_generators len_c1: 1
Check for no duplicates in test: (0=ok):
0.0
Check for no duplicates in val: (0=ok):
0
N of indexes in training set: 17000
N of indexes in validation set: 3000
N of indexes in test set: 0
Check - total per class: 20000
--create_generators, train indexes
batch_size: 12000
- Cut sample
bs: 12000
N_labels: 6
N_noise: 10
len_c1: 1
Train index length: 17000
--create_generators, validation indexes
- Cut sample
bs: 12000
N_labels: 6
N_noise: 10
len_c1: 1
Val index length: 3000
len(train_index_1), batch_size, n_labels_eff, n_noisy_samples = 17000, 12000, 6, 10
--DataSet Train
DataSet Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 2.5
Corresponding i_max is 399
Closest k to k_max is 2.504942
Specified k_min is 0.15
Corresponding i_min is 196
Closest k to k_min is 0.1507845
New data dim: (203, 1)
Final i_max used is 399
Final i_min used is 196
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 6
N. n_classes in output: 6
LABELS: ['dgp', 'ds', 'fr', 'lcdm', 'rand', 'wcdm']
list_IDs length: 17000
n_indexes (n of file IDs read for each batch): 200
batch size: 12000
n_batches : 85
For each batch we read 200 file IDs
For each file ID we have 6 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 12000 training examples
Input batch size: 12000
N of batches to cover all file IDs: 85
len(fname_list), batch_size, n_noisy_samples, n_batches: 102000, 12000, 10, 85
--DataSet Validation
DataSet Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 2.5
Corresponding i_max is 399
Closest k to k_max is 2.504942
Specified k_min is 0.15
Corresponding i_min is 196
Closest k to k_min is 0.1507845
New data dim: (203, 1)
Final i_max used is 399
Final i_min used is 196
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 6
N. n_classes in output: 6
LABELS: ['dgp', 'ds', 'fr', 'lcdm', 'rand', 'wcdm']
list_IDs length: 3000
n_indexes (n of file IDs read for each batch): 200
batch size: 12000
n_batches : 15
For each batch we read 200 file IDs
For each file ID we have 6 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 12000 training examples
Input batch size: 12000
N of batches to cover all file IDs: 15
len(fname_list), batch_size, n_noisy_samples, n_batches: 18000, 12000, 10, 15
------------ DONE ------------
------------ BUILDING MODEL ------------
Input shape (203, 4)
Model: "model"
_________________________________________________________________
Layer (type)                Output Shape              Param #
=================================================================
input_1 (InputLayer)        [(None, 203, 4)]          0
conv1d_flipout (Conv1DFlip  (None, 97, 8)             648
out)
max_pooling1d (MaxPooling1  (None, 48, 8)             0
D)
batch_normalization (Batch  (None, 48, 8)             32
Normalization)
conv1d_flipout_1 (Conv1DFl  (None, 22, 16)            1296
ipout)
max_pooling1d_1 (MaxPoolin  (None, 21, 16)            0
g1D)
batch_normalization_1 (Bat  (None, 21, 16)            64
chNormalization)
conv1d_flipout_2 (Conv1DFl  (None, 20, 32)            2080
ipout)
batch_normalization_2 (Bat  (None, 20, 32)            128
chNormalization)
global_average_pooling1d (  (None, 32)                0
GlobalAveragePooling1D)
dense_flipout (DenseFlipou  (None, 32)                2080
t)
batch_normalization_3 (Bat  (None, 32)                128
chNormalization)
dense_flipout_1 (DenseFlip  (None, 6)                 390
out)
=================================================================
Total params: 6846 (26.74 KB)
Trainable params: 6670 (26.05 KB)
Non-trainable params: 176 (704.00 Byte)
_________________________________________________________________
None
Found GPU at: /device:GPU:0
------------ TRAINING ------------
Features shape: (12000, 203, 4)
Labels shape: (12000, 6)
Initializing checkpoint from scratch.
Epoch 0
Validation loss decreased. Saved checkpoint for step 1: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-1
Time:  42.69s, ---- Loss: 1.3553, Acc.: 0.3752, Val. Loss: 1.8005, Val. Acc.: 0.2774
Epoch 1
Loss did not decrease. Count = 1
Time:  1.57s, ---- Loss: 1.1538, Acc.: 0.5151, Val. Loss: 1.8890, Val. Acc.: 0.2989
Epoch 2
Loss did not decrease. Count = 2
Time:  1.67s, ---- Loss: 1.0416, Acc.: 0.5726, Val. Loss: 2.1305, Val. Acc.: 0.2949
Epoch 3
Loss did not decrease. Count = 3
Time:  1.57s, ---- Loss: 0.9783, Acc.: 0.6028, Val. Loss: 2.2135, Val. Acc.: 0.3214
Epoch 4
Loss did not decrease. Count = 4
Time:  1.58s, ---- Loss: 0.9391, Acc.: 0.6205, Val. Loss: 2.0846, Val. Acc.: 0.3111
Epoch 5
Validation loss decreased. Saved checkpoint for step 6: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-2
Time:  1.68s, ---- Loss: 0.9301, Acc.: 0.6322, Val. Loss: 1.5239, Val. Acc.: 0.4272
Epoch 6
Validation loss decreased. Saved checkpoint for step 7: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-3
Time:  1.68s, ---- Loss: 0.9080, Acc.: 0.6412, Val. Loss: 1.4434, Val. Acc.: 0.4607
Epoch 7
Validation loss decreased. Saved checkpoint for step 8: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-4
Time:  1.69s, ---- Loss: 0.8732, Acc.: 0.6486, Val. Loss: 1.3912, Val. Acc.: 0.4926
Epoch 8
Loss did not decrease. Count = 1
Time:  1.57s, ---- Loss: 0.8562, Acc.: 0.6572, Val. Loss: 1.4633, Val. Acc.: 0.4939
Epoch 9
Loss did not decrease. Count = 2
Time:  1.56s, ---- Loss: 0.8350, Acc.: 0.6655, Val. Loss: 1.4673, Val. Acc.: 0.4965
Epoch 10
Loss did not decrease. Count = 3
Time:  1.55s, ---- Loss: 0.8267, Acc.: 0.6722, Val. Loss: 1.3948, Val. Acc.: 0.5146
Epoch 11
Validation loss decreased. Saved checkpoint for step 12: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-5
Time:  1.70s, ---- Loss: 0.8102, Acc.: 0.6772, Val. Loss: 1.2546, Val. Acc.: 0.5474
Epoch 12
Validation loss decreased. Saved checkpoint for step 13: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-6
Time:  1.67s, ---- Loss: 0.8013, Acc.: 0.6806, Val. Loss: 1.0804, Val. Acc.: 0.5969
Epoch 13
Validation loss decreased. Saved checkpoint for step 14: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-7
Time:  1.68s, ---- Loss: 0.7960, Acc.: 0.6837, Val. Loss: 1.0013, Val. Acc.: 0.6274
Epoch 14
Validation loss decreased. Saved checkpoint for step 15: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-8
Time:  1.68s, ---- Loss: 0.7878, Acc.: 0.6859, Val. Loss: 0.9548, Val. Acc.: 0.6462
Epoch 15
Validation loss decreased. Saved checkpoint for step 16: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-9
Time:  1.67s, ---- Loss: 0.7807, Acc.: 0.6882, Val. Loss: 0.9182, Val. Acc.: 0.6593
Epoch 16
Validation loss decreased. Saved checkpoint for step 17: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-10
Time:  1.68s, ---- Loss: 0.7770, Acc.: 0.6906, Val. Loss: 0.8939, Val. Acc.: 0.6686
Epoch 17
Validation loss decreased. Saved checkpoint for step 18: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-11
Time:  1.68s, ---- Loss: 0.7800, Acc.: 0.6918, Val. Loss: 0.8790, Val. Acc.: 0.6739
Epoch 18
Validation loss decreased. Saved checkpoint for step 19: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-12
Time:  1.71s, ---- Loss: 0.7673, Acc.: 0.6939, Val. Loss: 0.8573, Val. Acc.: 0.6814
Epoch 19
Validation loss decreased. Saved checkpoint for step 20: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-13
Time:  1.68s, ---- Loss: 0.7689, Acc.: 0.6950, Val. Loss: 0.8454, Val. Acc.: 0.6841
Epoch 20
Validation loss decreased. Saved checkpoint for step 21: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-14
Time:  1.68s, ---- Loss: 0.7640, Acc.: 0.6967, Val. Loss: 0.8355, Val. Acc.: 0.6874
Epoch 21
Validation loss decreased. Saved checkpoint for step 22: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-15
Time:  1.73s, ---- Loss: 0.7588, Acc.: 0.6976, Val. Loss: 0.8330, Val. Acc.: 0.6882
Epoch 22
Validation loss decreased. Saved checkpoint for step 23: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-16
Time:  1.70s, ---- Loss: 0.7575, Acc.: 0.6989, Val. Loss: 0.8279, Val. Acc.: 0.6892
Epoch 23
Validation loss decreased. Saved checkpoint for step 24: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-17
Time:  1.67s, ---- Loss: 0.7541, Acc.: 0.6999, Val. Loss: 0.8246, Val. Acc.: 0.6901
Epoch 24
Loss did not decrease. Count = 1
Time:  1.55s, ---- Loss: 0.7535, Acc.: 0.7010, Val. Loss: 0.8247, Val. Acc.: 0.6906
Epoch 25
Validation loss decreased. Saved checkpoint for step 26: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-18
Time:  1.68s, ---- Loss: 0.7510, Acc.: 0.7021, Val. Loss: 0.8196, Val. Acc.: 0.6930
Epoch 26
Loss did not decrease. Count = 1
Time:  1.54s, ---- Loss: 0.7499, Acc.: 0.7024, Val. Loss: 0.8344, Val. Acc.: 0.6863
Epoch 27
Loss did not decrease. Count = 2
Time:  1.55s, ---- Loss: 0.7459, Acc.: 0.7035, Val. Loss: 0.8225, Val. Acc.: 0.6907
Epoch 28
Validation loss decreased. Saved checkpoint for step 29: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-19
Time:  1.67s, ---- Loss: 0.7482, Acc.: 0.7044, Val. Loss: 0.8133, Val. Acc.: 0.6955
Epoch 29
Validation loss decreased. Saved checkpoint for step 30: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-20
Time:  1.66s, ---- Loss: 0.7414, Acc.: 0.7050, Val. Loss: 0.8070, Val. Acc.: 0.6981
Epoch 30
Validation loss decreased. Saved checkpoint for step 31: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-21
Time:  1.66s, ---- Loss: 0.7406, Acc.: 0.7055, Val. Loss: 0.8067, Val. Acc.: 0.6987
Epoch 31
Validation loss decreased. Saved checkpoint for step 32: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-22
Time:  1.67s, ---- Loss: 0.7436, Acc.: 0.7064, Val. Loss: 0.8020, Val. Acc.: 0.7002
Epoch 32
Validation loss decreased. Saved checkpoint for step 33: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-23
Time:  1.71s, ---- Loss: 0.7384, Acc.: 0.7071, Val. Loss: 0.7979, Val. Acc.: 0.7015
Epoch 33
Loss did not decrease. Count = 1
Time:  1.59s, ---- Loss: 0.7361, Acc.: 0.7077, Val. Loss: 0.7985, Val. Acc.: 0.7012
Epoch 34
Loss did not decrease. Count = 2
Time:  1.57s, ---- Loss: 0.7351, Acc.: 0.7079, Val. Loss: 0.7981, Val. Acc.: 0.7024
Epoch 35
Loss did not decrease. Count = 3
Time:  1.56s, ---- Loss: 0.7367, Acc.: 0.7085, Val. Loss: 0.7985, Val. Acc.: 0.7023
Epoch 36
Validation loss decreased. Saved checkpoint for step 37: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-24
Time:  1.70s, ---- Loss: 0.7308, Acc.: 0.7091, Val. Loss: 0.7976, Val. Acc.: 0.7021
Epoch 37
Loss did not decrease. Count = 1
Time:  1.57s, ---- Loss: 0.7322, Acc.: 0.7099, Val. Loss: 0.7992, Val. Acc.: 0.7009
Epoch 38
Loss did not decrease. Count = 2
Time:  1.60s, ---- Loss: 0.7304, Acc.: 0.7101, Val. Loss: 0.7979, Val. Acc.: 0.7013
Epoch 39
Validation loss decreased. Saved checkpoint for step 40: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-25
Time:  1.72s, ---- Loss: 0.7288, Acc.: 0.7105, Val. Loss: 0.7908, Val. Acc.: 0.7048
Epoch 40
Loss did not decrease. Count = 1
Time:  1.55s, ---- Loss: 0.7278, Acc.: 0.7108, Val. Loss: 0.7996, Val. Acc.: 0.7004
Epoch 41
Loss did not decrease. Count = 2
Time:  1.54s, ---- Loss: 0.7265, Acc.: 0.7117, Val. Loss: 0.7931, Val. Acc.: 0.7033
Epoch 42
Loss did not decrease. Count = 3
Time:  1.54s, ---- Loss: 0.7243, Acc.: 0.7116, Val. Loss: 0.7909, Val. Acc.: 0.7048
Epoch 43
Loss did not decrease. Count = 4
Time:  1.55s, ---- Loss: 0.7239, Acc.: 0.7123, Val. Loss: 0.7921, Val. Acc.: 0.7031
Epoch 44
Validation loss decreased. Saved checkpoint for step 45: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-26
Time:  1.67s, ---- Loss: 0.7228, Acc.: 0.7125, Val. Loss: 0.7902, Val. Acc.: 0.7043
Epoch 45
Loss did not decrease. Count = 1
Time:  1.54s, ---- Loss: 0.7202, Acc.: 0.7126, Val. Loss: 0.7902, Val. Acc.: 0.7042
Epoch 46
Validation loss decreased. Saved checkpoint for step 47: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-27
Time:  1.69s, ---- Loss: 0.7204, Acc.: 0.7131, Val. Loss: 0.7837, Val. Acc.: 0.7074
Epoch 47
Validation loss decreased. Saved checkpoint for step 48: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-28
Time:  1.67s, ---- Loss: 0.7199, Acc.: 0.7132, Val. Loss: 0.7822, Val. Acc.: 0.7082
Epoch 48
Loss did not decrease. Count = 1
Time:  1.54s, ---- Loss: 0.7206, Acc.: 0.7135, Val. Loss: 0.7827, Val. Acc.: 0.7079
Epoch 49
Loss did not decrease. Count = 2
Time:  1.54s, ---- Loss: 0.7170, Acc.: 0.7137, Val. Loss: 0.7836, Val. Acc.: 0.7072
Epoch 50
Validation loss decreased. Saved checkpoint for step 51: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-29
Time:  1.67s, ---- Loss: 0.7158, Acc.: 0.7139, Val. Loss: 0.7800, Val. Acc.: 0.7090
Epoch 51
Validation loss decreased. Saved checkpoint for step 52: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-30
Time:  1.66s, ---- Loss: 0.7172, Acc.: 0.7140, Val. Loss: 0.7774, Val. Acc.: 0.7100
Epoch 52
Validation loss decreased. Saved checkpoint for step 53: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-31
Time:  1.66s, ---- Loss: 0.7152, Acc.: 0.7145, Val. Loss: 0.7769, Val. Acc.: 0.7105
Epoch 53
Loss did not decrease. Count = 1
Time:  1.56s, ---- Loss: 0.7157, Acc.: 0.7147, Val. Loss: 0.7770, Val. Acc.: 0.7101
Epoch 54
Loss did not decrease. Count = 2
Time:  1.55s, ---- Loss: 0.7153, Acc.: 0.7148, Val. Loss: 0.7781, Val. Acc.: 0.7096
Epoch 55
Validation loss decreased. Saved checkpoint for step 56: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-32
Time:  1.66s, ---- Loss: 0.7152, Acc.: 0.7147, Val. Loss: 0.7765, Val. Acc.: 0.7098
Epoch 56
Loss did not decrease. Count = 1
Time:  1.56s, ---- Loss: 0.7138, Acc.: 0.7155, Val. Loss: 0.7766, Val. Acc.: 0.7104
Epoch 57
Loss did not decrease. Count = 2
Time:  1.55s, ---- Loss: 0.7168, Acc.: 0.7153, Val. Loss: 0.7768, Val. Acc.: 0.7096
Epoch 58
Validation loss decreased. Saved checkpoint for step 59: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-33
Time:  1.66s, ---- Loss: 0.7130, Acc.: 0.7159, Val. Loss: 0.7758, Val. Acc.: 0.7104
Epoch 59
Loss did not decrease. Count = 1
Time:  1.54s, ---- Loss: 0.7146, Acc.: 0.7157, Val. Loss: 0.7762, Val. Acc.: 0.7099
Epoch 60
Validation loss decreased. Saved checkpoint for step 61: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-34
Time:  1.69s, ---- Loss: 0.7131, Acc.: 0.7161, Val. Loss: 0.7732, Val. Acc.: 0.7117
Epoch 61
Loss did not decrease. Count = 1
Time:  1.55s, ---- Loss: 0.7125, Acc.: 0.7158, Val. Loss: 0.7744, Val. Acc.: 0.7115
Epoch 62
Loss did not decrease. Count = 2
Time:  1.55s, ---- Loss: 0.7117, Acc.: 0.7162, Val. Loss: 0.7738, Val. Acc.: 0.7111
Epoch 63
Loss did not decrease. Count = 3
Time:  1.55s, ---- Loss: 0.7121, Acc.: 0.7163, Val. Loss: 0.7739, Val. Acc.: 0.7109
Epoch 64
Loss did not decrease. Count = 4
Time:  1.55s, ---- Loss: 0.7097, Acc.: 0.7160, Val. Loss: 0.7732, Val. Acc.: 0.7114
Epoch 65
Validation loss decreased. Saved checkpoint for step 66: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-35
Time:  1.68s, ---- Loss: 0.7107, Acc.: 0.7163, Val. Loss: 0.7727, Val. Acc.: 0.7114
Epoch 66
Validation loss decreased. Saved checkpoint for step 67: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-36
Time:  1.67s, ---- Loss: 0.7159, Acc.: 0.7168, Val. Loss: 0.7718, Val. Acc.: 0.7121
Epoch 67
Loss did not decrease. Count = 1
Time:  1.56s, ---- Loss: 0.7112, Acc.: 0.7166, Val. Loss: 0.7719, Val. Acc.: 0.7125
Epoch 68
Validation loss decreased. Saved checkpoint for step 69: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-37
Time:  1.69s, ---- Loss: 0.7112, Acc.: 0.7166, Val. Loss: 0.7712, Val. Acc.: 0.7130
Epoch 69
Validation loss decreased. Saved checkpoint for step 70: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-38
Time:  1.66s, ---- Loss: 0.7105, Acc.: 0.7167, Val. Loss: 0.7703, Val. Acc.: 0.7132
Epoch 70
Validation loss decreased. Saved checkpoint for step 71: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-39
Time:  1.66s, ---- Loss: 0.7101, Acc.: 0.7170, Val. Loss: 0.7699, Val. Acc.: 0.7128
Epoch 71
Loss did not decrease. Count = 1
Time:  1.54s, ---- Loss: 0.7094, Acc.: 0.7170, Val. Loss: 0.7702, Val. Acc.: 0.7128
Epoch 72
Loss did not decrease. Count = 2
Time:  1.54s, ---- Loss: 0.7095, Acc.: 0.7171, Val. Loss: 0.7706, Val. Acc.: 0.7130
Epoch 73
Validation loss decreased. Saved checkpoint for step 74: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-40
Time:  1.66s, ---- Loss: 0.7093, Acc.: 0.7170, Val. Loss: 0.7694, Val. Acc.: 0.7134
Epoch 74
Validation loss decreased. Saved checkpoint for step 75: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-41
Time:  1.67s, ---- Loss: 0.7087, Acc.: 0.7172, Val. Loss: 0.7693, Val. Acc.: 0.7135
Epoch 75
Validation loss decreased. Saved checkpoint for step 76: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-42
Time:  1.69s, ---- Loss: 0.7092, Acc.: 0.7173, Val. Loss: 0.7692, Val. Acc.: 0.7131
Epoch 76
Validation loss decreased. Saved checkpoint for step 77: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-43
Time:  1.68s, ---- Loss: 0.7081, Acc.: 0.7171, Val. Loss: 0.7690, Val. Acc.: 0.7136
Epoch 77
Loss did not decrease. Count = 1
Time:  1.55s, ---- Loss: 0.7088, Acc.: 0.7172, Val. Loss: 0.7694, Val. Acc.: 0.7133
Epoch 78
Loss did not decrease. Count = 2
Time:  1.55s, ---- Loss: 0.7096, Acc.: 0.7175, Val. Loss: 0.7692, Val. Acc.: 0.7132
Epoch 79
Validation loss decreased. Saved checkpoint for step 80: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-44
Time:  1.67s, ---- Loss: 0.7091, Acc.: 0.7174, Val. Loss: 0.7679, Val. Acc.: 0.7140
Epoch 80
Loss did not decrease. Count = 1
Time:  1.54s, ---- Loss: 0.7072, Acc.: 0.7176, Val. Loss: 0.7680, Val. Acc.: 0.7138
Epoch 81
Validation loss decreased. Saved checkpoint for step 82: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-45
Time:  1.69s, ---- Loss: 0.7080, Acc.: 0.7176, Val. Loss: 0.7678, Val. Acc.: 0.7142
Epoch 82
Loss did not decrease. Count = 1
Time:  1.57s, ---- Loss: 0.7066, Acc.: 0.7178, Val. Loss: 0.7678, Val. Acc.: 0.7134
Epoch 83
Validation loss decreased. Saved checkpoint for step 84: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-46
Time:  1.68s, ---- Loss: 0.7071, Acc.: 0.7175, Val. Loss: 0.7672, Val. Acc.: 0.7142
Epoch 84
Loss did not decrease. Count = 1
Time:  1.54s, ---- Loss: 0.7069, Acc.: 0.7179, Val. Loss: 0.7677, Val. Acc.: 0.7145
Epoch 85
Validation loss decreased. Saved checkpoint for step 86: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-47
Time:  1.66s, ---- Loss: 0.7073, Acc.: 0.7179, Val. Loss: 0.7672, Val. Acc.: 0.7140
Epoch 86
Loss did not decrease. Count = 1
Time:  1.54s, ---- Loss: 0.7090, Acc.: 0.7178, Val. Loss: 0.7679, Val. Acc.: 0.7143
Epoch 87
Loss did not decrease. Count = 2
Time:  1.55s, ---- Loss: 0.7072, Acc.: 0.7180, Val. Loss: 0.7678, Val. Acc.: 0.7141
Epoch 88
Loss did not decrease. Count = 3
Time:  1.56s, ---- Loss: 0.7084, Acc.: 0.7177, Val. Loss: 0.7677, Val. Acc.: 0.7137
Epoch 89
Validation loss decreased. Saved checkpoint for step 90: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-48
Time:  1.70s, ---- Loss: 0.7080, Acc.: 0.7178, Val. Loss: 0.7667, Val. Acc.: 0.7146
Epoch 90
Loss did not decrease. Count = 1
Time:  1.56s, ---- Loss: 0.7068, Acc.: 0.7182, Val. Loss: 0.7674, Val. Acc.: 0.7149
Epoch 91
Loss did not decrease. Count = 2
Time:  1.55s, ---- Loss: 0.7070, Acc.: 0.7179, Val. Loss: 0.7673, Val. Acc.: 0.7145
Epoch 92
Validation loss decreased. Saved checkpoint for step 93: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-49
Time:  1.69s, ---- Loss: 0.7074, Acc.: 0.7180, Val. Loss: 0.7667, Val. Acc.: 0.7148
Epoch 93
Loss did not decrease. Count = 1
Time:  1.56s, ---- Loss: 0.7081, Acc.: 0.7181, Val. Loss: 0.7670, Val. Acc.: 0.7139
Epoch 94
Loss did not decrease. Count = 2
Time:  1.55s, ---- Loss: 0.7065, Acc.: 0.7175, Val. Loss: 0.7668, Val. Acc.: 0.7150
Epoch 95
Validation loss decreased. Saved checkpoint for step 96: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-50
Time:  1.67s, ---- Loss: 0.7073, Acc.: 0.7181, Val. Loss: 0.7664, Val. Acc.: 0.7145
Epoch 96
Validation loss decreased. Saved checkpoint for step 97: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/tf_ckpts/ckpt-51
Time:  1.69s, ---- Loss: 0.7052, Acc.: 0.7180, Val. Loss: 0.7662, Val. Acc.: 0.7146
Epoch 97
Loss did not decrease. Count = 1
Time:  1.54s, ---- Loss: 0.7046, Acc.: 0.7181, Val. Loss: 0.7670, Val. Acc.: 0.7148
Epoch 98
Loss did not decrease. Count = 2
Time:  1.54s, ---- Loss: 0.7074, Acc.: 0.7182, Val. Loss: 0.7664, Val. Acc.: 0.7144
Epoch 99
Loss did not decrease. Count = 3
Time:  1.55s, ---- Loss: 0.7065, Acc.: 0.7182, Val. Loss: 0.7669, Val. Acc.: 0.7145
Saving at models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.15_kmax-2.5_/hist.png
Done in 4040.53s

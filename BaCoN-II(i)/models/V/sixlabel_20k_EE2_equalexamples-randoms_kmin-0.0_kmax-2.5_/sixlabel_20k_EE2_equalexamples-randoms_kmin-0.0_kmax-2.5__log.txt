
 -------- Parameters:
bayesian True
test_mode False
n_test_idx 2
seed 1312
fine_tune False
one_vs_all False
c_0 ['lcdm']
c_1 ['True', 'dgp', 'ds', 'fR', 'rand--save_ckpt', 'wcdm']
dataset_balanced False
include_last False
log_path models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5__log.txt
restore False
fname sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_
model_name custom
my_path None
DIR data/train
TEST_DIR data/test
models_dir models/
save_ckpt True
out_path_overwrite False
curves_folder data/curve_files_sys/theory_error
save_processed_spectra False
cache_dir False
im_depth 500
im_width 1
im_channels 4
swap_axes True
sort_labels True
norm_data_name /planck_ee2.txt
normalization stdcosmo
sample_pace 1
k_max 2.5
k_min 0.0
i_max None
i_min None
add_noise True
n_noisy_samples 10
add_shot False
add_sys True
add_cosvar True
sigma_sys None
sys_scaled None
sys_factor None
sys_max None
sigma_curves 0.05
sigma_curves_default 0.05
rescale_curves uniform
z_bins [0, 1, 2, 3]
n_dense 1
filters [8, 16, 32]
kernel_sizes [10, 5, 2]
strides [2, 2, 1]
pool_sizes [2, 2, 0]
strides_pooling [2, 1, 0]
add_FT_dense False
trainable False
unfreeze False
lr 0.01
drop 0.5
n_epochs 100
val_size 0.15
test_size 0.0
batch_size 12000
patience 20
GPU True
TPU False
decay 0.95
BatchNorm True
padding valid
shuffle True

------------ CREATING DATA GENERATORS ------------
labels : ['dgp', 'ds', 'fr', 'lcdm', 'rand', 'wcdm']
Labels encoding: 
{'dgp': 0, 'ds': 1, 'fr': 2, 'lcdm': 3, 'rand': 4, 'wcdm': 5}
n_labels : 6
dgp - 20000 training examples
ds - 20000 training examples
fr - 20000 training examples
lcdm - 20000 training examples
rand - 20000 training examples
wcdm - 20000 training examples

N. of data files: 20000
get_all_indexes labels dict: {'dgp': 0, 'ds': 1, 'fr': 2, 'lcdm': 3, 'rand': 4, 'wcdm': 5}
create_generators n_labels: 6
create_generators n_labels_eff: 6
create_generators len_c1: 1
Check for no duplicates in test: (0=ok):
0.0
Check for no duplicates in val: (0=ok):
0
N of indexes in training set: 17000
N of indexes in validation set: 3000
N of indexes in test set: 0
Check - total per class: 20000
--create_generators, train indexes
batch_size: 12000
- Cut sample
bs: 12000
N_labels: 6
N_noise: 10
len_c1: 1
Train index length: 17000
--create_generators, validation indexes
- Cut sample
bs: 12000
N_labels: 6
N_noise: 10
len_c1: 1
Val index length: 3000
len(train_index_1), batch_size, n_labels_eff, n_noisy_samples = 17000, 12000, 6, 10

--DataSet Train
DataSet Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 2.5
Corresponding i_max is 399
Closest k to k_max is 2.504942
Specified k_min is 0.0
Corresponding i_min is 0
Closest k to k_min is 0.01
New data dim: (399, 1)
Final i_max used is 399
Final i_min used is 0
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 6
N. n_classes in output: 6
LABELS: ['dgp', 'ds', 'fr', 'lcdm', 'rand', 'wcdm']
list_IDs length: 17000
n_indexes (n of file IDs read for each batch): 200
batch size: 12000
n_batches : 85
For each batch we read 200 file IDs
For each file ID we have 6 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 12000 training examples
Input batch size: 12000
N of batches to cover all file IDs: 85
len(fname_list), batch_size, n_noisy_samples, n_batches: 102000, 12000, 10, 85

--DataSet Validation
DataSet Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 2.5
Corresponding i_max is 399
Closest k to k_max is 2.504942
Specified k_min is 0.0
Corresponding i_min is 0
Closest k to k_min is 0.01
New data dim: (399, 1)
Final i_max used is 399
Final i_min used is 0
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 6
N. n_classes in output: 6
LABELS: ['dgp', 'ds', 'fr', 'lcdm', 'rand', 'wcdm']
list_IDs length: 3000
n_indexes (n of file IDs read for each batch): 200
batch size: 12000
n_batches : 15
For each batch we read 200 file IDs
For each file ID we have 6 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 12000 training examples
Input batch size: 12000
N of batches to cover all file IDs: 15
len(fname_list), batch_size, n_noisy_samples, n_batches: 18000, 12000, 10, 15
------------ DONE ------------

------------ BUILDING MODEL ------------
Input shape (399, 4)
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 399, 4)]          0         
                                                                 
 conv1d_flipout (Conv1DFlip  (None, 195, 8)            648       
 out)                                                            
                                                                 
 max_pooling1d (MaxPooling1  (None, 97, 8)             0         
 D)                                                              
                                                                 
 batch_normalization (Batch  (None, 97, 8)             32        
 Normalization)                                                  
                                                                 
 conv1d_flipout_1 (Conv1DFl  (None, 47, 16)            1296      
 ipout)                                                          
                                                                 
 max_pooling1d_1 (MaxPoolin  (None, 46, 16)            0         
 g1D)                                                            
                                                                 
 batch_normalization_1 (Bat  (None, 46, 16)            64        
 chNormalization)                                                
                                                                 
 conv1d_flipout_2 (Conv1DFl  (None, 45, 32)            2080      
 ipout)                                                          
                                                                 
 batch_normalization_2 (Bat  (None, 45, 32)            128       
 chNormalization)                                                
                                                                 
 global_average_pooling1d (  (None, 32)                0         
 GlobalAveragePooling1D)                                         
                                                                 
 dense_flipout (DenseFlipou  (None, 32)                2080      
 t)                                                              
                                                                 
 batch_normalization_3 (Bat  (None, 32)                128       
 chNormalization)                                                
                                                                 
 dense_flipout_1 (DenseFlip  (None, 6)                 390       
 out)                                                            
                                                                 
=================================================================
Total params: 6846 (26.74 KB)
Trainable params: 6670 (26.05 KB)
Non-trainable params: 176 (704.00 Byte)
_________________________________________________________________
None
Found GPU at: /device:GPU:0
------------ TRAINING ------------

Features shape: (12000, 399, 4)
Labels shape: (12000, 6)
Initializing checkpoint from scratch.
Epoch 0
Validation loss decreased. Saved checkpoint for step 1: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-1
Time:  49.76s, ---- Loss: 1.0839, Acc.: 0.4763, Val. Loss: 1.8784, Val. Acc.: 0.2737

Epoch 1
Loss did not decrease. Count = 1
Time:  2.77s, ---- Loss: 0.8875, Acc.: 0.6076, Val. Loss: 2.4449, Val. Acc.: 0.2262

Epoch 2
Validation loss decreased. Saved checkpoint for step 3: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-2
Time:  2.93s, ---- Loss: 0.7973, Acc.: 0.6610, Val. Loss: 1.7575, Val. Acc.: 0.4051

Epoch 3
Validation loss decreased. Saved checkpoint for step 4: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-3
Time:  2.90s, ---- Loss: 0.7507, Acc.: 0.6841, Val. Loss: 1.3078, Val. Acc.: 0.4988

Epoch 4
Validation loss decreased. Saved checkpoint for step 5: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-4
Time:  2.90s, ---- Loss: 0.7353, Acc.: 0.6974, Val. Loss: 1.0795, Val. Acc.: 0.5797

Epoch 5
Validation loss decreased. Saved checkpoint for step 6: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-5
Time:  2.89s, ---- Loss: 0.7009, Acc.: 0.7093, Val. Loss: 1.0067, Val. Acc.: 0.6182

Epoch 6
Validation loss decreased. Saved checkpoint for step 7: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-6
Time:  2.91s, ---- Loss: 0.6728, Acc.: 0.7186, Val. Loss: 0.9415, Val. Acc.: 0.6449

Epoch 7
Validation loss decreased. Saved checkpoint for step 8: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-7
Time:  2.89s, ---- Loss: 0.6630, Acc.: 0.7255, Val. Loss: 0.9105, Val. Acc.: 0.6578

Epoch 8
Validation loss decreased. Saved checkpoint for step 9: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-8
Time:  2.89s, ---- Loss: 0.6491, Acc.: 0.7304, Val. Loss: 0.8949, Val. Acc.: 0.6615

Epoch 9
Validation loss decreased. Saved checkpoint for step 10: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-9
Time:  2.89s, ---- Loss: 0.6399, Acc.: 0.7347, Val. Loss: 0.8802, Val. Acc.: 0.6700

Epoch 10
Loss did not decrease. Count = 1
Time:  2.77s, ---- Loss: 0.6277, Acc.: 0.7382, Val. Loss: 0.9293, Val. Acc.: 0.6511

Epoch 11
Loss did not decrease. Count = 2
Time:  2.76s, ---- Loss: 0.6234, Acc.: 0.7415, Val. Loss: 0.9530, Val. Acc.: 0.6544

Epoch 12
Loss did not decrease. Count = 3
Time:  2.76s, ---- Loss: 0.6217, Acc.: 0.7442, Val. Loss: 0.9693, Val. Acc.: 0.6426

Epoch 13
Loss did not decrease. Count = 4
Time:  2.76s, ---- Loss: 0.6085, Acc.: 0.7462, Val. Loss: 1.0396, Val. Acc.: 0.6204

Epoch 14
Loss did not decrease. Count = 5
Time:  2.78s, ---- Loss: 0.6095, Acc.: 0.7484, Val. Loss: 1.0025, Val. Acc.: 0.6285

Epoch 15
Loss did not decrease. Count = 6
Time:  2.75s, ---- Loss: 0.6023, Acc.: 0.7502, Val. Loss: 0.9372, Val. Acc.: 0.6476

Epoch 16
Loss did not decrease. Count = 7
Time:  2.76s, ---- Loss: 0.5954, Acc.: 0.7521, Val. Loss: 0.9204, Val. Acc.: 0.6527

Epoch 17
Loss did not decrease. Count = 8
Time:  2.77s, ---- Loss: 0.5899, Acc.: 0.7536, Val. Loss: 0.9127, Val. Acc.: 0.6580

Epoch 18
Validation loss decreased. Saved checkpoint for step 19: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-10
Time:  2.91s, ---- Loss: 0.5895, Acc.: 0.7550, Val. Loss: 0.8682, Val. Acc.: 0.6701

Epoch 19
Validation loss decreased. Saved checkpoint for step 20: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-11
Time:  2.88s, ---- Loss: 0.5841, Acc.: 0.7564, Val. Loss: 0.7874, Val. Acc.: 0.6999

Epoch 20
Validation loss decreased. Saved checkpoint for step 21: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-12
Time:  2.88s, ---- Loss: 0.5795, Acc.: 0.7578, Val. Loss: 0.7658, Val. Acc.: 0.7078

Epoch 21
Validation loss decreased. Saved checkpoint for step 22: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-13
Time:  2.93s, ---- Loss: 0.5785, Acc.: 0.7589, Val. Loss: 0.7284, Val. Acc.: 0.7231

Epoch 22
Validation loss decreased. Saved checkpoint for step 23: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-14
Time:  2.95s, ---- Loss: 0.5768, Acc.: 0.7600, Val. Loss: 0.7155, Val. Acc.: 0.7287

Epoch 23
Validation loss decreased. Saved checkpoint for step 24: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-15
Time:  2.89s, ---- Loss: 0.5733, Acc.: 0.7610, Val. Loss: 0.6933, Val. Acc.: 0.7374

Epoch 24
Loss did not decrease. Count = 1
Time:  2.75s, ---- Loss: 0.5710, Acc.: 0.7622, Val. Loss: 0.7042, Val. Acc.: 0.7313

Epoch 25
Loss did not decrease. Count = 2
Time:  2.76s, ---- Loss: 0.5672, Acc.: 0.7627, Val. Loss: 0.7094, Val. Acc.: 0.7285

Epoch 26
Loss did not decrease. Count = 3
Time:  2.77s, ---- Loss: 0.5658, Acc.: 0.7640, Val. Loss: 0.7020, Val. Acc.: 0.7326

Epoch 27
Validation loss decreased. Saved checkpoint for step 28: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-16
Time:  3.15s, ---- Loss: 0.5609, Acc.: 0.7649, Val. Loss: 0.6897, Val. Acc.: 0.7373

Epoch 28
Validation loss decreased. Saved checkpoint for step 29: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-17
Time:  2.89s, ---- Loss: 0.5566, Acc.: 0.7657, Val. Loss: 0.6843, Val. Acc.: 0.7395

Epoch 29
Validation loss decreased. Saved checkpoint for step 30: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-18
Time:  2.89s, ---- Loss: 0.5578, Acc.: 0.7670, Val. Loss: 0.6536, Val. Acc.: 0.7530

Epoch 30
Loss did not decrease. Count = 1
Time:  2.80s, ---- Loss: 0.5560, Acc.: 0.7675, Val. Loss: 0.6554, Val. Acc.: 0.7527

Epoch 31
Validation loss decreased. Saved checkpoint for step 32: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-19
Time:  2.89s, ---- Loss: 0.5497, Acc.: 0.7683, Val. Loss: 0.6489, Val. Acc.: 0.7553

Epoch 32
Validation loss decreased. Saved checkpoint for step 33: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-20
Time:  2.89s, ---- Loss: 0.5538, Acc.: 0.7689, Val. Loss: 0.6392, Val. Acc.: 0.7594

Epoch 33
Loss did not decrease. Count = 1
Time:  2.76s, ---- Loss: 0.5492, Acc.: 0.7693, Val. Loss: 0.6396, Val. Acc.: 0.7598

Epoch 34
Validation loss decreased. Saved checkpoint for step 35: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-21
Time:  2.90s, ---- Loss: 0.5507, Acc.: 0.7699, Val. Loss: 0.6291, Val. Acc.: 0.7634

Epoch 35
Loss did not decrease. Count = 1
Time:  2.76s, ---- Loss: 0.5457, Acc.: 0.7707, Val. Loss: 0.6331, Val. Acc.: 0.7616

Epoch 36
Loss did not decrease. Count = 2
Time:  2.75s, ---- Loss: 0.5456, Acc.: 0.7713, Val. Loss: 0.6306, Val. Acc.: 0.7640

Epoch 37
Loss did not decrease. Count = 3
Time:  2.77s, ---- Loss: 0.5427, Acc.: 0.7715, Val. Loss: 0.6368, Val. Acc.: 0.7609

Epoch 38
Validation loss decreased. Saved checkpoint for step 39: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-22
Time:  2.90s, ---- Loss: 0.5405, Acc.: 0.7721, Val. Loss: 0.6272, Val. Acc.: 0.7644

Epoch 39
Validation loss decreased. Saved checkpoint for step 40: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-23
Time:  2.89s, ---- Loss: 0.5398, Acc.: 0.7723, Val. Loss: 0.6213, Val. Acc.: 0.7664

Epoch 40
Loss did not decrease. Count = 1
Time:  2.76s, ---- Loss: 0.5414, Acc.: 0.7726, Val. Loss: 0.6232, Val. Acc.: 0.7656

Epoch 41
Loss did not decrease. Count = 2
Time:  2.75s, ---- Loss: 0.5394, Acc.: 0.7731, Val. Loss: 0.6253, Val. Acc.: 0.7656

Epoch 42
Loss did not decrease. Count = 3
Time:  2.79s, ---- Loss: 0.5395, Acc.: 0.7734, Val. Loss: 0.6215, Val. Acc.: 0.7671

Epoch 43
Validation loss decreased. Saved checkpoint for step 44: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-24
Time:  2.89s, ---- Loss: 0.5373, Acc.: 0.7737, Val. Loss: 0.6192, Val. Acc.: 0.7681

Epoch 44
Validation loss decreased. Saved checkpoint for step 45: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-25
Time:  2.88s, ---- Loss: 0.5381, Acc.: 0.7738, Val. Loss: 0.6159, Val. Acc.: 0.7691

Epoch 45
Validation loss decreased. Saved checkpoint for step 46: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-26
Time:  2.88s, ---- Loss: 0.5368, Acc.: 0.7744, Val. Loss: 0.6130, Val. Acc.: 0.7704

Epoch 46
Loss did not decrease. Count = 1
Time:  2.79s, ---- Loss: 0.5348, Acc.: 0.7745, Val. Loss: 0.6130, Val. Acc.: 0.7700

Epoch 47
Validation loss decreased. Saved checkpoint for step 48: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-27
Time:  2.88s, ---- Loss: 0.5332, Acc.: 0.7749, Val. Loss: 0.6119, Val. Acc.: 0.7703

Epoch 48
Validation loss decreased. Saved checkpoint for step 49: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-28
Time:  2.88s, ---- Loss: 0.5327, Acc.: 0.7753, Val. Loss: 0.6113, Val. Acc.: 0.7710

Epoch 49
Loss did not decrease. Count = 1
Time:  2.76s, ---- Loss: 0.5301, Acc.: 0.7756, Val. Loss: 0.6144, Val. Acc.: 0.7696

Epoch 50
Loss did not decrease. Count = 2
Time:  2.78s, ---- Loss: 0.5341, Acc.: 0.7758, Val. Loss: 0.6144, Val. Acc.: 0.7691

Epoch 51
Loss did not decrease. Count = 3
Time:  2.76s, ---- Loss: 0.5308, Acc.: 0.7758, Val. Loss: 0.6127, Val. Acc.: 0.7705

Epoch 52
Validation loss decreased. Saved checkpoint for step 53: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-29
Time:  2.89s, ---- Loss: 0.5334, Acc.: 0.7760, Val. Loss: 0.6101, Val. Acc.: 0.7710

Epoch 53
Validation loss decreased. Saved checkpoint for step 54: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-30
Time:  2.88s, ---- Loss: 0.5298, Acc.: 0.7764, Val. Loss: 0.6077, Val. Acc.: 0.7732

Epoch 54
Validation loss decreased. Saved checkpoint for step 55: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-31
Time:  2.89s, ---- Loss: 0.5324, Acc.: 0.7766, Val. Loss: 0.6059, Val. Acc.: 0.7743

Epoch 55
Loss did not decrease. Count = 1
Time:  2.77s, ---- Loss: 0.5298, Acc.: 0.7767, Val. Loss: 0.6078, Val. Acc.: 0.7725

Epoch 56
Loss did not decrease. Count = 2
Time:  2.76s, ---- Loss: 0.5296, Acc.: 0.7771, Val. Loss: 0.6088, Val. Acc.: 0.7718

Epoch 57
Loss did not decrease. Count = 3
Time:  2.77s, ---- Loss: 0.5297, Acc.: 0.7770, Val. Loss: 0.6127, Val. Acc.: 0.7701

Epoch 58
Validation loss decreased. Saved checkpoint for step 59: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-32
Time:  2.92s, ---- Loss: 0.5272, Acc.: 0.7775, Val. Loss: 0.6052, Val. Acc.: 0.7734

Epoch 59
Loss did not decrease. Count = 1
Time:  2.77s, ---- Loss: 0.5285, Acc.: 0.7775, Val. Loss: 0.6068, Val. Acc.: 0.7731

Epoch 60
Loss did not decrease. Count = 2
Time:  2.76s, ---- Loss: 0.5276, Acc.: 0.7775, Val. Loss: 0.6080, Val. Acc.: 0.7725

Epoch 61
Validation loss decreased. Saved checkpoint for step 62: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-33
Time:  2.89s, ---- Loss: 0.5258, Acc.: 0.7779, Val. Loss: 0.6027, Val. Acc.: 0.7753

Epoch 62
Validation loss decreased. Saved checkpoint for step 63: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-34
Time:  2.93s, ---- Loss: 0.5272, Acc.: 0.7776, Val. Loss: 0.6018, Val. Acc.: 0.7752

Epoch 63
Loss did not decrease. Count = 1
Time:  2.78s, ---- Loss: 0.5277, Acc.: 0.7780, Val. Loss: 0.6021, Val. Acc.: 0.7756

Epoch 64
Loss did not decrease. Count = 2
Time:  2.77s, ---- Loss: 0.5239, Acc.: 0.7780, Val. Loss: 0.6028, Val. Acc.: 0.7748

Epoch 65
Validation loss decreased. Saved checkpoint for step 66: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-35
Time:  2.90s, ---- Loss: 0.5258, Acc.: 0.7780, Val. Loss: 0.6010, Val. Acc.: 0.7754

Epoch 66
Loss did not decrease. Count = 1
Time:  2.78s, ---- Loss: 0.5252, Acc.: 0.7784, Val. Loss: 0.6013, Val. Acc.: 0.7752

Epoch 67
Validation loss decreased. Saved checkpoint for step 68: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-36
Time:  2.93s, ---- Loss: 0.5247, Acc.: 0.7785, Val. Loss: 0.6004, Val. Acc.: 0.7754

Epoch 68
Validation loss decreased. Saved checkpoint for step 69: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-37
Time:  2.94s, ---- Loss: 0.5248, Acc.: 0.7788, Val. Loss: 0.5992, Val. Acc.: 0.7770

Epoch 69
Loss did not decrease. Count = 1
Time:  2.78s, ---- Loss: 0.5274, Acc.: 0.7785, Val. Loss: 0.5999, Val. Acc.: 0.7761

Epoch 70
Loss did not decrease. Count = 2
Time:  2.80s, ---- Loss: 0.5244, Acc.: 0.7786, Val. Loss: 0.5997, Val. Acc.: 0.7755

Epoch 71
Validation loss decreased. Saved checkpoint for step 72: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-38
Time:  2.90s, ---- Loss: 0.5253, Acc.: 0.7787, Val. Loss: 0.5990, Val. Acc.: 0.7775

Epoch 72
Validation loss decreased. Saved checkpoint for step 73: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-39
Time:  2.90s, ---- Loss: 0.5245, Acc.: 0.7787, Val. Loss: 0.5988, Val. Acc.: 0.7764

Epoch 73
Validation loss decreased. Saved checkpoint for step 74: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-40
Time:  2.88s, ---- Loss: 0.5246, Acc.: 0.7790, Val. Loss: 0.5982, Val. Acc.: 0.7776

Epoch 74
Loss did not decrease. Count = 1
Time:  2.78s, ---- Loss: 0.5235, Acc.: 0.7789, Val. Loss: 0.5984, Val. Acc.: 0.7768

Epoch 75
Validation loss decreased. Saved checkpoint for step 76: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-41
Time:  2.88s, ---- Loss: 0.5249, Acc.: 0.7791, Val. Loss: 0.5979, Val. Acc.: 0.7774

Epoch 76
Validation loss decreased. Saved checkpoint for step 77: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-42
Time:  2.88s, ---- Loss: 0.5249, Acc.: 0.7792, Val. Loss: 0.5979, Val. Acc.: 0.7773

Epoch 77
Validation loss decreased. Saved checkpoint for step 78: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-43
Time:  2.89s, ---- Loss: 0.5231, Acc.: 0.7794, Val. Loss: 0.5969, Val. Acc.: 0.7773

Epoch 78
Loss did not decrease. Count = 1
Time:  2.78s, ---- Loss: 0.5228, Acc.: 0.7792, Val. Loss: 0.5980, Val. Acc.: 0.7767

Epoch 79
Loss did not decrease. Count = 2
Time:  2.77s, ---- Loss: 0.5236, Acc.: 0.7795, Val. Loss: 0.5978, Val. Acc.: 0.7771

Epoch 80
Loss did not decrease. Count = 3
Time:  2.76s, ---- Loss: 0.5233, Acc.: 0.7795, Val. Loss: 0.5977, Val. Acc.: 0.7776

Epoch 81
Loss did not decrease. Count = 4
Time:  2.77s, ---- Loss: 0.5236, Acc.: 0.7793, Val. Loss: 0.5969, Val. Acc.: 0.7775

Epoch 82
Loss did not decrease. Count = 5
Time:  2.79s, ---- Loss: 0.5236, Acc.: 0.7796, Val. Loss: 0.5978, Val. Acc.: 0.7772

Epoch 83
Loss did not decrease. Count = 6
Time:  2.76s, ---- Loss: 0.5216, Acc.: 0.7796, Val. Loss: 0.5970, Val. Acc.: 0.7781

Epoch 84
Validation loss decreased. Saved checkpoint for step 85: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-44
Time:  2.90s, ---- Loss: 0.5225, Acc.: 0.7797, Val. Loss: 0.5969, Val. Acc.: 0.7780

Epoch 85
Validation loss decreased. Saved checkpoint for step 86: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-45
Time:  2.89s, ---- Loss: 0.5221, Acc.: 0.7795, Val. Loss: 0.5968, Val. Acc.: 0.7775

Epoch 86
Loss did not decrease. Count = 1
Time:  2.79s, ---- Loss: 0.5237, Acc.: 0.7798, Val. Loss: 0.5976, Val. Acc.: 0.7772

Epoch 87
Validation loss decreased. Saved checkpoint for step 88: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-46
Time:  2.90s, ---- Loss: 0.5220, Acc.: 0.7796, Val. Loss: 0.5963, Val. Acc.: 0.7778

Epoch 88
Validation loss decreased. Saved checkpoint for step 89: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-47
Time:  2.89s, ---- Loss: 0.5241, Acc.: 0.7800, Val. Loss: 0.5959, Val. Acc.: 0.7783

Epoch 89
Validation loss decreased. Saved checkpoint for step 90: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-48
Time:  2.91s, ---- Loss: 0.5224, Acc.: 0.7797, Val. Loss: 0.5958, Val. Acc.: 0.7782

Epoch 90
Loss did not decrease. Count = 1
Time:  2.78s, ---- Loss: 0.5209, Acc.: 0.7799, Val. Loss: 0.5960, Val. Acc.: 0.7781

Epoch 91
Loss did not decrease. Count = 2
Time:  2.77s, ---- Loss: 0.5231, Acc.: 0.7800, Val. Loss: 0.5966, Val. Acc.: 0.7782

Epoch 92
Validation loss decreased. Saved checkpoint for step 93: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-49
Time:  2.87s, ---- Loss: 0.5208, Acc.: 0.7799, Val. Loss: 0.5951, Val. Acc.: 0.7785

Epoch 93
Validation loss decreased. Saved checkpoint for step 94: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-50
Time:  2.89s, ---- Loss: 0.5237, Acc.: 0.7796, Val. Loss: 0.5947, Val. Acc.: 0.7783

Epoch 94
Loss did not decrease. Count = 1
Time:  2.76s, ---- Loss: 0.5204, Acc.: 0.7798, Val. Loss: 0.5952, Val. Acc.: 0.7782

Epoch 95
Loss did not decrease. Count = 2
Time:  2.77s, ---- Loss: 0.5214, Acc.: 0.7800, Val. Loss: 0.5950, Val. Acc.: 0.7783

Epoch 96
Loss did not decrease. Count = 3
Time:  2.76s, ---- Loss: 0.5217, Acc.: 0.7801, Val. Loss: 0.5951, Val. Acc.: 0.7791

Epoch 97
Validation loss decreased. Saved checkpoint for step 98: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-51
Time:  2.88s, ---- Loss: 0.5194, Acc.: 0.7801, Val. Loss: 0.5945, Val. Acc.: 0.7792

Epoch 98
Loss did not decrease. Count = 1
Time:  2.76s, ---- Loss: 0.5214, Acc.: 0.7801, Val. Loss: 0.5952, Val. Acc.: 0.7786

Epoch 99
Loss did not decrease. Count = 2
Time:  2.77s, ---- Loss: 0.5226, Acc.: 0.7801, Val. Loss: 0.5950, Val. Acc.: 0.7784

Saving at models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_/hist.png
Done in 4312.14s

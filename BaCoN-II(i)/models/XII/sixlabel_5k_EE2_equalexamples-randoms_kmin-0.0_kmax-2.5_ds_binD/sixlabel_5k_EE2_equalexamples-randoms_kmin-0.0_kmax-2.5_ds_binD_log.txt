
 -------- Parameters:
bayesian True
test_mode False
n_test_idx 2
seed 1312
fine_tune False
one_vs_all False
c_0 ['lcdm']
c_1 ['dgp', 'ds', 'fR', 'rand', 'wcdm']
dataset_balanced False
include_last False
log_path models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD_log.txt
restore False
fname sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD
model_name custom
my_path None
DIR data/train
TEST_DIR data/test/
models_dir models/
save_ckpt True
out_path_overwrite False
curves_folder data/curve_files_sys/theory_error
save_processed_spectra False
cache_dir False
im_depth 500
im_width 1
im_channels 4
swap_axes True
sort_labels True
norm_data_name /planck_ee2.txt
normalization stdcosmo
sample_pace 1
k_max 2.5
k_min 0.0
i_max None
i_min None
add_noise True
n_noisy_samples 10
add_shot False
add_sys True
add_cosvar True
sigma_sys None
sys_scaled None
sys_factor None
sys_max None
sigma_curves 0.05
sigma_curves_default 0.05
rescale_curves uniform
z_bins [0, 1, 2, 3]
n_dense 1
filters [8, 16, 32]
kernel_sizes [10, 5, 2]
strides [2, 2, 1]
pool_sizes [2, 2, 0]
strides_pooling [2, 1, 0]
add_FT_dense False
trainable False
unfreeze False
lr 0.01
drop 0.5
n_epochs 100
val_size 0.15
test_size 0.0
batch_size 3000
patience 20
GPU True
TPU False
decay 0.95
BatchNorm True
padding valid
shuffle True

------------ CREATING DATA GENERATORS ------------
labels : ['dgp', 'ds_binD', 'fr', 'lcdm', 'rand', 'wcdm']
Labels encoding: 
{'dgp': 0, 'ds_binD': 1, 'fr': 2, 'lcdm': 3, 'rand': 4, 'wcdm': 5}
n_labels : 6
dgp - 5000 training examples
ds_binD - 5000 training examples
fr - 5000 training examples
lcdm - 5000 training examples
rand - 5000 training examples
wcdm - 5000 training examples

N. of data files: 5000
get_all_indexes labels dict: {'dgp': 0, 'ds_binD': 1, 'fr': 2, 'lcdm': 3, 'rand': 4, 'wcdm': 5}
create_generators n_labels: 6
create_generators n_labels_eff: 6
create_generators len_c1: 1
Check for no duplicates in test: (0=ok):
0.0
Check for no duplicates in val: (0=ok):
0
N of indexes in training set: 4250
N of indexes in validation set: 750
N of indexes in test set: 0
Check - total per class: 5000
--create_generators, train indexes
batch_size: 3000
- Cut sample
bs: 3000
N_labels: 6
N_noise: 10
len_c1: 1
Train index length: 4250
--create_generators, validation indexes
- Cut sample
bs: 3000
N_labels: 6
N_noise: 10
len_c1: 1
Val index length: 750
len(train_index_1), batch_size, n_labels_eff, n_noisy_samples = 4250, 3000, 6, 10

--DataSet Train
DataSet Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 2.5
Corresponding i_max is 399
Closest k to k_max is 2.504942
Specified k_min is 0.0
Corresponding i_min is 0
Closest k to k_min is 0.01
New data dim: (399, 1)
Final i_max used is 399
Final i_min used is 0
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 6
N. n_classes in output: 6
LABELS: ['dgp', 'ds_binD', 'fr', 'lcdm', 'rand', 'wcdm']
list_IDs length: 4250
n_indexes (n of file IDs read for each batch): 50
batch size: 3000
n_batches : 85
For each batch we read 50 file IDs
For each file ID we have 6 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 3000 training examples
Input batch size: 3000
N of batches to cover all file IDs: 85
len(fname_list), batch_size, n_noisy_samples, n_batches: 25500, 3000, 10, 85

--DataSet Validation
DataSet Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 2.5
Corresponding i_max is 399
Closest k to k_max is 2.504942
Specified k_min is 0.0
Corresponding i_min is 0
Closest k to k_min is 0.01
New data dim: (399, 1)
Final i_max used is 399
Final i_min used is 0
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 6
N. n_classes in output: 6
LABELS: ['dgp', 'ds_binD', 'fr', 'lcdm', 'rand', 'wcdm']
list_IDs length: 750
n_indexes (n of file IDs read for each batch): 50
batch size: 3000
n_batches : 15
For each batch we read 50 file IDs
For each file ID we have 6 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 3000 training examples
Input batch size: 3000
N of batches to cover all file IDs: 15
len(fname_list), batch_size, n_noisy_samples, n_batches: 4500, 3000, 10, 15
------------ DONE ------------

------------ BUILDING MODEL ------------
Input shape (399, 4)
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 399, 4)]          0         
                                                                 
 conv1d_flipout (Conv1DFlip  (None, 195, 8)            648       
 out)                                                            
                                                                 
 max_pooling1d (MaxPooling1  (None, 97, 8)             0         
 D)                                                              
                                                                 
 batch_normalization (Batch  (None, 97, 8)             32        
 Normalization)                                                  
                                                                 
 conv1d_flipout_1 (Conv1DFl  (None, 47, 16)            1296      
 ipout)                                                          
                                                                 
 max_pooling1d_1 (MaxPoolin  (None, 46, 16)            0         
 g1D)                                                            
                                                                 
 batch_normalization_1 (Bat  (None, 46, 16)            64        
 chNormalization)                                                
                                                                 
 conv1d_flipout_2 (Conv1DFl  (None, 45, 32)            2080      
 ipout)                                                          
                                                                 
 batch_normalization_2 (Bat  (None, 45, 32)            128       
 chNormalization)                                                
                                                                 
 global_average_pooling1d (  (None, 32)                0         
 GlobalAveragePooling1D)                                         
                                                                 
 dense_flipout (DenseFlipou  (None, 32)                2080      
 t)                                                              
                                                                 
 batch_normalization_3 (Bat  (None, 32)                128       
 chNormalization)                                                
                                                                 
 dense_flipout_1 (DenseFlip  (None, 6)                 390       
 out)                                                            
                                                                 
=================================================================
Total params: 6846 (26.74 KB)
Trainable params: 6670 (26.05 KB)
Non-trainable params: 176 (704.00 Byte)
_________________________________________________________________
None
Found GPU at: /device:GPU:0
------------ TRAINING ------------

Features shape: (3000, 399, 4)
Labels shape: (3000, 6)
Initializing checkpoint from scratch.
Epoch 0
Validation loss decreased. Saved checkpoint for step 1: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-1
Time:  38.64s, ---- Loss: 1.1076, Acc.: 0.4633, Val. Loss: 3.4836, Val. Acc.: 0.2398

Epoch 1
Validation loss decreased. Saved checkpoint for step 2: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-2
Time:  1.19s, ---- Loss: 0.9421, Acc.: 0.5935, Val. Loss: 2.3306, Val. Acc.: 0.3012

Epoch 2
Validation loss decreased. Saved checkpoint for step 3: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-3
Time:  1.17s, ---- Loss: 0.8517, Acc.: 0.6484, Val. Loss: 1.6983, Val. Acc.: 0.4824

Epoch 3
Validation loss decreased. Saved checkpoint for step 4: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-4
Time:  1.17s, ---- Loss: 0.7910, Acc.: 0.6755, Val. Loss: 1.4270, Val. Acc.: 0.5532

Epoch 4
Validation loss decreased. Saved checkpoint for step 5: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-5
Time:  1.17s, ---- Loss: 0.7518, Acc.: 0.6935, Val. Loss: 1.2653, Val. Acc.: 0.5952

Epoch 5
Validation loss decreased. Saved checkpoint for step 6: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-6
Time:  1.16s, ---- Loss: 0.7353, Acc.: 0.7057, Val. Loss: 1.2301, Val. Acc.: 0.5950

Epoch 6
Validation loss decreased. Saved checkpoint for step 7: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-7
Time:  1.17s, ---- Loss: 0.7034, Acc.: 0.7150, Val. Loss: 1.0294, Val. Acc.: 0.6711

Epoch 7
Validation loss decreased. Saved checkpoint for step 8: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-8
Time:  1.16s, ---- Loss: 0.6944, Acc.: 0.7228, Val. Loss: 0.9772, Val. Acc.: 0.6962

Epoch 8
Validation loss decreased. Saved checkpoint for step 9: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-9
Time:  1.15s, ---- Loss: 0.6929, Acc.: 0.7291, Val. Loss: 0.9725, Val. Acc.: 0.7008

Epoch 9
Validation loss decreased. Saved checkpoint for step 10: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-10
Time:  1.17s, ---- Loss: 0.6737, Acc.: 0.7329, Val. Loss: 0.9270, Val. Acc.: 0.7199

Epoch 10
Validation loss decreased. Saved checkpoint for step 11: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-11
Time:  1.17s, ---- Loss: 0.6592, Acc.: 0.7375, Val. Loss: 0.9035, Val. Acc.: 0.7330

Epoch 11
Validation loss decreased. Saved checkpoint for step 12: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-12
Time:  1.15s, ---- Loss: 0.6541, Acc.: 0.7419, Val. Loss: 0.8945, Val. Acc.: 0.7342

Epoch 12
Validation loss decreased. Saved checkpoint for step 13: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-13
Time:  1.16s, ---- Loss: 0.6395, Acc.: 0.7444, Val. Loss: 0.8720, Val. Acc.: 0.7445

Epoch 13
Loss did not decrease. Count = 1
Time:  1.03s, ---- Loss: 0.6370, Acc.: 0.7469, Val. Loss: 0.8788, Val. Acc.: 0.7418

Epoch 14
Validation loss decreased. Saved checkpoint for step 15: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-14
Time:  1.15s, ---- Loss: 0.6304, Acc.: 0.7487, Val. Loss: 0.8703, Val. Acc.: 0.7466

Epoch 15
Validation loss decreased. Saved checkpoint for step 16: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-15
Time:  1.15s, ---- Loss: 0.6357, Acc.: 0.7501, Val. Loss: 0.8663, Val. Acc.: 0.7470

Epoch 16
Validation loss decreased. Saved checkpoint for step 17: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-16
Time:  1.15s, ---- Loss: 0.6256, Acc.: 0.7511, Val. Loss: 0.8645, Val. Acc.: 0.7493

Epoch 17
Loss did not decrease. Count = 1
Time:  1.03s, ---- Loss: 0.6208, Acc.: 0.7530, Val. Loss: 0.8682, Val. Acc.: 0.7480

Epoch 18
Loss did not decrease. Count = 2
Time:  1.03s, ---- Loss: 0.6294, Acc.: 0.7536, Val. Loss: 0.8775, Val. Acc.: 0.7421

Epoch 19
Validation loss decreased. Saved checkpoint for step 20: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-17
Time:  1.16s, ---- Loss: 0.6194, Acc.: 0.7549, Val. Loss: 0.8564, Val. Acc.: 0.7520

Epoch 20
Loss did not decrease. Count = 1
Time:  1.05s, ---- Loss: 0.6140, Acc.: 0.7557, Val. Loss: 0.8605, Val. Acc.: 0.7531

Epoch 21
Validation loss decreased. Saved checkpoint for step 22: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-18
Time:  1.16s, ---- Loss: 0.6171, Acc.: 0.7588, Val. Loss: 0.8539, Val. Acc.: 0.7529

Epoch 22
Validation loss decreased. Saved checkpoint for step 23: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-19
Time:  1.15s, ---- Loss: 0.6112, Acc.: 0.7592, Val. Loss: 0.8534, Val. Acc.: 0.7547

Epoch 23
Validation loss decreased. Saved checkpoint for step 24: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-20
Time:  1.14s, ---- Loss: 0.6047, Acc.: 0.7604, Val. Loss: 0.8462, Val. Acc.: 0.7576

Epoch 24
Validation loss decreased. Saved checkpoint for step 25: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-21
Time:  1.16s, ---- Loss: 0.6075, Acc.: 0.7607, Val. Loss: 0.8457, Val. Acc.: 0.7570

Epoch 25
Validation loss decreased. Saved checkpoint for step 26: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-22
Time:  1.15s, ---- Loss: 0.6058, Acc.: 0.7624, Val. Loss: 0.8440, Val. Acc.: 0.7583

Epoch 26
Loss did not decrease. Count = 1
Time:  1.04s, ---- Loss: 0.6100, Acc.: 0.7628, Val. Loss: 0.8453, Val. Acc.: 0.7588

Epoch 27
Loss did not decrease. Count = 2
Time:  1.03s, ---- Loss: 0.6082, Acc.: 0.7633, Val. Loss: 0.8463, Val. Acc.: 0.7573

Epoch 28
Loss did not decrease. Count = 3
Time:  1.03s, ---- Loss: 0.5984, Acc.: 0.7640, Val. Loss: 0.8446, Val. Acc.: 0.7589

Epoch 29
Validation loss decreased. Saved checkpoint for step 30: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-23
Time:  1.17s, ---- Loss: 0.6039, Acc.: 0.7644, Val. Loss: 0.8395, Val. Acc.: 0.7624

Epoch 30
Validation loss decreased. Saved checkpoint for step 31: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-24
Time:  1.18s, ---- Loss: 0.6021, Acc.: 0.7650, Val. Loss: 0.8362, Val. Acc.: 0.7639

Epoch 31
Validation loss decreased. Saved checkpoint for step 32: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-25
Time:  1.17s, ---- Loss: 0.5921, Acc.: 0.7654, Val. Loss: 0.8362, Val. Acc.: 0.7618

Epoch 32
Loss did not decrease. Count = 1
Time:  1.04s, ---- Loss: 0.5937, Acc.: 0.7661, Val. Loss: 0.8383, Val. Acc.: 0.7619

Epoch 33
Loss did not decrease. Count = 2
Time:  1.02s, ---- Loss: 0.5955, Acc.: 0.7672, Val. Loss: 0.8404, Val. Acc.: 0.7615

Epoch 34
Loss did not decrease. Count = 3
Time:  1.03s, ---- Loss: 0.5984, Acc.: 0.7675, Val. Loss: 0.8404, Val. Acc.: 0.7624

Epoch 35
Loss did not decrease. Count = 4
Time:  1.02s, ---- Loss: 0.5941, Acc.: 0.7669, Val. Loss: 0.8395, Val. Acc.: 0.7626

Epoch 36
Validation loss decreased. Saved checkpoint for step 37: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-26
Time:  1.16s, ---- Loss: 0.5887, Acc.: 0.7675, Val. Loss: 0.8348, Val. Acc.: 0.7653

Epoch 37
Validation loss decreased. Saved checkpoint for step 38: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-27
Time:  1.15s, ---- Loss: 0.5926, Acc.: 0.7685, Val. Loss: 0.8325, Val. Acc.: 0.7662

Epoch 38
Loss did not decrease. Count = 1
Time:  1.03s, ---- Loss: 0.5863, Acc.: 0.7691, Val. Loss: 0.8330, Val. Acc.: 0.7644

Epoch 39
Validation loss decreased. Saved checkpoint for step 40: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-28
Time:  1.15s, ---- Loss: 0.5843, Acc.: 0.7697, Val. Loss: 0.8322, Val. Acc.: 0.7672

Epoch 40
Validation loss decreased. Saved checkpoint for step 41: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-29
Time:  1.16s, ---- Loss: 0.5849, Acc.: 0.7694, Val. Loss: 0.8311, Val. Acc.: 0.7666

Epoch 41
Loss did not decrease. Count = 1
Time:  1.04s, ---- Loss: 0.5812, Acc.: 0.7700, Val. Loss: 0.8322, Val. Acc.: 0.7664

Epoch 42
Validation loss decreased. Saved checkpoint for step 43: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-30
Time:  1.16s, ---- Loss: 0.5869, Acc.: 0.7704, Val. Loss: 0.8290, Val. Acc.: 0.7683

Epoch 43
Validation loss decreased. Saved checkpoint for step 44: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-31
Time:  1.16s, ---- Loss: 0.5836, Acc.: 0.7708, Val. Loss: 0.8283, Val. Acc.: 0.7673

Epoch 44
Validation loss decreased. Saved checkpoint for step 45: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-32
Time:  1.15s, ---- Loss: 0.5808, Acc.: 0.7709, Val. Loss: 0.8260, Val. Acc.: 0.7697

Epoch 45
Validation loss decreased. Saved checkpoint for step 46: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-33
Time:  1.15s, ---- Loss: 0.5818, Acc.: 0.7718, Val. Loss: 0.8254, Val. Acc.: 0.7691

Epoch 46
Loss did not decrease. Count = 1
Time:  1.03s, ---- Loss: 0.5794, Acc.: 0.7721, Val. Loss: 0.8255, Val. Acc.: 0.7699

Epoch 47
Validation loss decreased. Saved checkpoint for step 48: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-34
Time:  1.16s, ---- Loss: 0.5777, Acc.: 0.7721, Val. Loss: 0.8248, Val. Acc.: 0.7701

Epoch 48
Loss did not decrease. Count = 1
Time:  1.02s, ---- Loss: 0.5842, Acc.: 0.7724, Val. Loss: 0.8249, Val. Acc.: 0.7700

Epoch 49
Validation loss decreased. Saved checkpoint for step 50: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-35
Time:  1.15s, ---- Loss: 0.5771, Acc.: 0.7719, Val. Loss: 0.8243, Val. Acc.: 0.7697

Epoch 50
Validation loss decreased. Saved checkpoint for step 51: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-36
Time:  1.17s, ---- Loss: 0.5714, Acc.: 0.7725, Val. Loss: 0.8202, Val. Acc.: 0.7727

Epoch 51
Loss did not decrease. Count = 1
Time:  1.06s, ---- Loss: 0.5750, Acc.: 0.7733, Val. Loss: 0.8213, Val. Acc.: 0.7714

Epoch 52
Loss did not decrease. Count = 2
Time:  1.03s, ---- Loss: 0.5742, Acc.: 0.7732, Val. Loss: 0.8220, Val. Acc.: 0.7718

Epoch 53
Loss did not decrease. Count = 3
Time:  1.03s, ---- Loss: 0.5786, Acc.: 0.7735, Val. Loss: 0.8222, Val. Acc.: 0.7722

Epoch 54
Loss did not decrease. Count = 4
Time:  1.03s, ---- Loss: 0.5790, Acc.: 0.7735, Val. Loss: 0.8217, Val. Acc.: 0.7728

Epoch 55
Loss did not decrease. Count = 5
Time:  1.03s, ---- Loss: 0.5721, Acc.: 0.7742, Val. Loss: 0.8207, Val. Acc.: 0.7722

Epoch 56
Loss did not decrease. Count = 6
Time:  1.04s, ---- Loss: 0.5788, Acc.: 0.7738, Val. Loss: 0.8207, Val. Acc.: 0.7729

Epoch 57
Validation loss decreased. Saved checkpoint for step 58: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-37
Time:  1.17s, ---- Loss: 0.5743, Acc.: 0.7743, Val. Loss: 0.8196, Val. Acc.: 0.7733

Epoch 58
Validation loss decreased. Saved checkpoint for step 59: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-38
Time:  1.15s, ---- Loss: 0.5733, Acc.: 0.7739, Val. Loss: 0.8189, Val. Acc.: 0.7722

Epoch 59
Loss did not decrease. Count = 1
Time:  1.03s, ---- Loss: 0.5719, Acc.: 0.7738, Val. Loss: 0.8194, Val. Acc.: 0.7746

Epoch 60
Loss did not decrease. Count = 2
Time:  1.03s, ---- Loss: 0.5744, Acc.: 0.7742, Val. Loss: 0.8190, Val. Acc.: 0.7747

Epoch 61
Validation loss decreased. Saved checkpoint for step 62: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-39
Time:  1.16s, ---- Loss: 0.5717, Acc.: 0.7748, Val. Loss: 0.8182, Val. Acc.: 0.7749

Epoch 62
Validation loss decreased. Saved checkpoint for step 63: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-40
Time:  1.18s, ---- Loss: 0.5682, Acc.: 0.7759, Val. Loss: 0.8166, Val. Acc.: 0.7767

Epoch 63
Loss did not decrease. Count = 1
Time:  1.03s, ---- Loss: 0.5758, Acc.: 0.7747, Val. Loss: 0.8190, Val. Acc.: 0.7732

Epoch 64
Loss did not decrease. Count = 2
Time:  1.04s, ---- Loss: 0.5686, Acc.: 0.7751, Val. Loss: 0.8179, Val. Acc.: 0.7720

Epoch 65
Loss did not decrease. Count = 3
Time:  1.03s, ---- Loss: 0.5713, Acc.: 0.7749, Val. Loss: 0.8167, Val. Acc.: 0.7746

Epoch 66
Loss did not decrease. Count = 4
Time:  1.03s, ---- Loss: 0.5726, Acc.: 0.7762, Val. Loss: 0.8176, Val. Acc.: 0.7752

Epoch 67
Loss did not decrease. Count = 5
Time:  1.03s, ---- Loss: 0.5734, Acc.: 0.7756, Val. Loss: 0.8171, Val. Acc.: 0.7741

Epoch 68
Loss did not decrease. Count = 6
Time:  1.03s, ---- Loss: 0.5715, Acc.: 0.7762, Val. Loss: 0.8169, Val. Acc.: 0.7748

Epoch 69
Validation loss decreased. Saved checkpoint for step 70: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-41
Time:  1.15s, ---- Loss: 0.5670, Acc.: 0.7760, Val. Loss: 0.8158, Val. Acc.: 0.7756

Epoch 70
Loss did not decrease. Count = 1
Time:  1.02s, ---- Loss: 0.5705, Acc.: 0.7756, Val. Loss: 0.8173, Val. Acc.: 0.7754

Epoch 71
Validation loss decreased. Saved checkpoint for step 72: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-42
Time:  1.15s, ---- Loss: 0.5722, Acc.: 0.7759, Val. Loss: 0.8156, Val. Acc.: 0.7766

Epoch 72
Loss did not decrease. Count = 1
Time:  1.05s, ---- Loss: 0.5636, Acc.: 0.7765, Val. Loss: 0.8171, Val. Acc.: 0.7748

Epoch 73
Loss did not decrease. Count = 2
Time:  1.04s, ---- Loss: 0.5649, Acc.: 0.7761, Val. Loss: 0.8161, Val. Acc.: 0.7744

Epoch 74
Loss did not decrease. Count = 3
Time:  1.03s, ---- Loss: 0.5684, Acc.: 0.7759, Val. Loss: 0.8158, Val. Acc.: 0.7772

Epoch 75
Loss did not decrease. Count = 4
Time:  1.03s, ---- Loss: 0.5700, Acc.: 0.7771, Val. Loss: 0.8164, Val. Acc.: 0.7751

Epoch 76
Loss did not decrease. Count = 5
Time:  1.03s, ---- Loss: 0.5660, Acc.: 0.7765, Val. Loss: 0.8160, Val. Acc.: 0.7749

Epoch 77
Loss did not decrease. Count = 6
Time:  1.04s, ---- Loss: 0.5666, Acc.: 0.7766, Val. Loss: 0.8157, Val. Acc.: 0.7767

Epoch 78
Validation loss decreased. Saved checkpoint for step 79: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-43
Time:  1.15s, ---- Loss: 0.5690, Acc.: 0.7762, Val. Loss: 0.8143, Val. Acc.: 0.7767

Epoch 79
Loss did not decrease. Count = 1
Time:  1.03s, ---- Loss: 0.5639, Acc.: 0.7761, Val. Loss: 0.8160, Val. Acc.: 0.7754

Epoch 80
Loss did not decrease. Count = 2
Time:  1.03s, ---- Loss: 0.5690, Acc.: 0.7760, Val. Loss: 0.8156, Val. Acc.: 0.7754

Epoch 81
Loss did not decrease. Count = 3
Time:  1.03s, ---- Loss: 0.5621, Acc.: 0.7774, Val. Loss: 0.8153, Val. Acc.: 0.7759

Epoch 82
Loss did not decrease. Count = 4
Time:  1.03s, ---- Loss: 0.5647, Acc.: 0.7774, Val. Loss: 0.8155, Val. Acc.: 0.7758

Epoch 83
Loss did not decrease. Count = 5
Time:  1.05s, ---- Loss: 0.5718, Acc.: 0.7774, Val. Loss: 0.8147, Val. Acc.: 0.7776

Epoch 84
Loss did not decrease. Count = 6
Time:  1.04s, ---- Loss: 0.5685, Acc.: 0.7775, Val. Loss: 0.8156, Val. Acc.: 0.7764

Epoch 85
Validation loss decreased. Saved checkpoint for step 86: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/tf_ckpts/ckpt-44
Time:  1.16s, ---- Loss: 0.5720, Acc.: 0.7770, Val. Loss: 0.8139, Val. Acc.: 0.7754

Epoch 86
Loss did not decrease. Count = 1
Time:  1.02s, ---- Loss: 0.5676, Acc.: 0.7772, Val. Loss: 0.8159, Val. Acc.: 0.7754

Epoch 87
Loss did not decrease. Count = 2
Time:  1.02s, ---- Loss: 0.5709, Acc.: 0.7775, Val. Loss: 0.8150, Val. Acc.: 0.7752

Epoch 88
Loss did not decrease. Count = 3
Time:  1.02s, ---- Loss: 0.5705, Acc.: 0.7773, Val. Loss: 0.8147, Val. Acc.: 0.7774

Epoch 89
Loss did not decrease. Count = 4
Time:  1.03s, ---- Loss: 0.5675, Acc.: 0.7771, Val. Loss: 0.8150, Val. Acc.: 0.7758

Epoch 90
Loss did not decrease. Count = 5
Time:  1.03s, ---- Loss: 0.5637, Acc.: 0.7772, Val. Loss: 0.8161, Val. Acc.: 0.7748

Epoch 91
Loss did not decrease. Count = 6
Time:  1.03s, ---- Loss: 0.5687, Acc.: 0.7772, Val. Loss: 0.8150, Val. Acc.: 0.7752

Epoch 92
Loss did not decrease. Count = 7
Time:  1.03s, ---- Loss: 0.5601, Acc.: 0.7774, Val. Loss: 0.8144, Val. Acc.: 0.7760

Epoch 93
Loss did not decrease. Count = 8
Time:  1.03s, ---- Loss: 0.5626, Acc.: 0.7775, Val. Loss: 0.8163, Val. Acc.: 0.7762

Epoch 94
Loss did not decrease. Count = 9
Time:  1.05s, ---- Loss: 0.5649, Acc.: 0.7767, Val. Loss: 0.8142, Val. Acc.: 0.7763

Epoch 95
Loss did not decrease. Count = 10
Time:  1.38s, ---- Loss: 0.5604, Acc.: 0.7772, Val. Loss: 0.8143, Val. Acc.: 0.7752

Epoch 96
Loss did not decrease. Count = 11
Time:  1.04s, ---- Loss: 0.5671, Acc.: 0.7775, Val. Loss: 0.8145, Val. Acc.: 0.7771

Epoch 97
Loss did not decrease. Count = 12
Time:  1.03s, ---- Loss: 0.5669, Acc.: 0.7776, Val. Loss: 0.8154, Val. Acc.: 0.7763

Epoch 98
Loss did not decrease. Count = 13
Time:  1.03s, ---- Loss: 0.5633, Acc.: 0.7778, Val. Loss: 0.8143, Val. Acc.: 0.7740

Epoch 99
Loss did not decrease. Count = 14
Time:  1.02s, ---- Loss: 0.5685, Acc.: 0.7778, Val. Loss: 0.8144, Val. Acc.: 0.7755

Saving at models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binD/hist.png
Done in 1137.51s

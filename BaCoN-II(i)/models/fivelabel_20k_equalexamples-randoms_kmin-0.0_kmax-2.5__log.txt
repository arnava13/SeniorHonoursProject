2024-04-09 22:31:15.534224: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-04-09 22:31:15.534267: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-04-09 22:31:15.536264: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-04-09 22:31:16.561364: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-04-09 22:31:18.977277: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
using 1D layers and 4 channels
/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:98: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.
loc = add_variable_fn(
/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:108: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.
untransformed_scale = add_variable_fn(
Expected output dimension after layer: conv1d_flipout : 97
Expected output dimension after layer: conv1d_flipout_1 : 46
Expected output dimension after layer: conv1d_flipout_2 : 45
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1712705167.020390    5010 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
Directory models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_ not created
-------- Parameters:
bayesian True
test_mode False
n_test_idx 2
seed 1312
fine_tune False
one_vs_all False
c_0 ['lcdm']
c_1 ['dgp', 'ds', 'fR', 'rand']
dataset_balanced False
include_last False
log_path models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5__log.txt
restore False
fname fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_
model_name custom
my_path None
DIR data/train
TEST_DIR data/test/
models_dir models/
save_ckpt True
out_path_overwrite False
curves_folder data/curve_files_sys/theory_error
save_processed_spectra False
cache_dir False
im_depth 500
im_width 1
im_channels 4
swap_axes True
sort_labels True
norm_data_name /planck_ee2.txt
normalization stdcosmo
sample_pace 1
k_max 2.5
k_min 0.0
i_max None
i_min None
add_noise True
n_noisy_samples 10
add_shot False
add_sys True
add_cosvar True
sigma_sys None
sys_scaled None
sys_factor None
sys_max None
sigma_curves 0.05
sigma_curves_default 0.05
rescale_curves uniform
z_bins [0, 1, 2, 3]
n_dense 1
filters [8, 16, 32]
kernel_sizes [10, 5, 2]
strides [2, 2, 1]
pool_sizes [2, 2, 0]
strides_pooling [2, 1, 0]
add_FT_dense False
trainable False
unfreeze False
lr 0.01
drop 0.5
n_epochs 100
val_size 0.15
test_size 0.0
batch_size 10000
patience 20
GPU True
TPU False
decay 0.95
BatchNorm True
padding valid
shuffle True
------------ CREATING DATA GENERATORS ------------
labels : ['dgp', 'ds', 'fr', 'lcdm', 'rand']
Labels encoding:
{'dgp': 0, 'ds': 1, 'fr': 2, 'lcdm': 3, 'rand': 4}
n_labels : 5
dgp - 20000 training examples
ds - 20000 training examples
fr - 20000 training examples
lcdm - 20000 training examples
rand - 20000 training examples
N. of data files: 20000
get_all_indexes labels dict: {'dgp': 0, 'ds': 1, 'fr': 2, 'lcdm': 3, 'rand': 4}
create_generators n_labels: 5
create_generators n_labels_eff: 5
create_generators len_c1: 1
Check for no duplicates in test: (0=ok):
0.0
Check for no duplicates in val: (0=ok):
0
N of indexes in training set: 17000
N of indexes in validation set: 3000
N of indexes in test set: 0
Check - total per class: 20000
--create_generators, train indexes
batch_size: 10000
- Cut sample
bs: 10000
N_labels: 5
N_noise: 10
len_c1: 1
Train index length: 17000
--create_generators, validation indexes
- Cut sample
bs: 10000
N_labels: 5
N_noise: 10
len_c1: 1
Val index length: 3000
len(train_index_1), batch_size, n_labels_eff, n_noisy_samples = 17000, 10000, 5, 10
--DataSet Train
DataSet Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 2.5
Corresponding i_max is 399
Closest k to k_max is 2.504942
Specified k_min is 0.0
Corresponding i_min is 0
Closest k to k_min is 0.01
New data dim: (399, 1)
Final i_max used is 399
Final i_min used is 0
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 5
N. n_classes in output: 5
LABELS: ['dgp', 'ds', 'fr', 'lcdm', 'rand']
list_IDs length: 17000
n_indexes (n of file IDs read for each batch): 200
batch size: 10000
n_batches : 85
For each batch we read 200 file IDs
For each file ID we have 5 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 10000 training examples
Input batch size: 10000
N of batches to cover all file IDs: 85
len(fname_list), batch_size, n_noisy_samples, n_batches: 85000, 10000, 10, 85
--DataSet Validation
DataSet Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 2.5
Corresponding i_max is 399
Closest k to k_max is 2.504942
Specified k_min is 0.0
Corresponding i_min is 0
Closest k to k_min is 0.01
New data dim: (399, 1)
Final i_max used is 399
Final i_min used is 0
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 5
N. n_classes in output: 5
LABELS: ['dgp', 'ds', 'fr', 'lcdm', 'rand']
list_IDs length: 3000
n_indexes (n of file IDs read for each batch): 200
batch size: 10000
n_batches : 15
For each batch we read 200 file IDs
For each file ID we have 5 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 10000 training examples
Input batch size: 10000
N of batches to cover all file IDs: 15
len(fname_list), batch_size, n_noisy_samples, n_batches: 15000, 10000, 10, 15
------------ DONE ------------
------------ BUILDING MODEL ------------
Input shape (399, 4)
Model: "model"
_________________________________________________________________
Layer (type)                Output Shape              Param #
=================================================================
input_1 (InputLayer)        [(None, 399, 4)]          0
conv1d_flipout (Conv1DFlip  (None, 195, 8)            648
out)
max_pooling1d (MaxPooling1  (None, 97, 8)             0
D)
batch_normalization (Batch  (None, 97, 8)             32
Normalization)
conv1d_flipout_1 (Conv1DFl  (None, 47, 16)            1296
ipout)
max_pooling1d_1 (MaxPoolin  (None, 46, 16)            0
g1D)
batch_normalization_1 (Bat  (None, 46, 16)            64
chNormalization)
conv1d_flipout_2 (Conv1DFl  (None, 45, 32)            2080
ipout)
batch_normalization_2 (Bat  (None, 45, 32)            128
chNormalization)
global_average_pooling1d (  (None, 32)                0
GlobalAveragePooling1D)
dense_flipout (DenseFlipou  (None, 32)                2080
t)
batch_normalization_3 (Bat  (None, 32)                128
chNormalization)
dense_flipout_1 (DenseFlip  (None, 5)                 325
out)
=================================================================
Total params: 6781 (26.49 KB)
Trainable params: 6605 (25.80 KB)
Non-trainable params: 176 (704.00 Byte)
_________________________________________________________________
None
Found GPU at: /device:GPU:0
------------ TRAINING ------------
Features shape: (10000, 399, 4)
Labels shape: (10000, 5)
Initializing checkpoint from scratch.
Epoch 0
Validation loss decreased. Saved checkpoint for step 1: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-1
Time:  45.57s, ---- Loss: 0.7934, Acc.: 0.5715, Val. Loss: 1.6714, Val. Acc.: 0.3762
Epoch 1
Loss did not decrease. Count = 1
Time:  2.34s, ---- Loss: 0.6097, Acc.: 0.7335, Val. Loss: 2.0015, Val. Acc.: 0.3804
Epoch 2
Loss did not decrease. Count = 2
Time:  2.34s, ---- Loss: 0.5626, Acc.: 0.7759, Val. Loss: 2.4356, Val. Acc.: 0.4250
Epoch 3
Loss did not decrease. Count = 3
Time:  2.33s, ---- Loss: 0.5200, Acc.: 0.7955, Val. Loss: 2.1892, Val. Acc.: 0.4878
Epoch 4
Validation loss decreased. Saved checkpoint for step 5: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-2
Time:  2.46s, ---- Loss: 0.4957, Acc.: 0.8069, Val. Loss: 1.5085, Val. Acc.: 0.5608
Epoch 5
Validation loss decreased. Saved checkpoint for step 6: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-3
Time:  2.45s, ---- Loss: 0.4703, Acc.: 0.8152, Val. Loss: 1.0709, Val. Acc.: 0.6487
Epoch 6
Validation loss decreased. Saved checkpoint for step 7: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-4
Time:  2.46s, ---- Loss: 0.4529, Acc.: 0.8236, Val. Loss: 0.9210, Val. Acc.: 0.7000
Epoch 7
Validation loss decreased. Saved checkpoint for step 8: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-5
Time:  2.45s, ---- Loss: 0.4377, Acc.: 0.8301, Val. Loss: 0.7780, Val. Acc.: 0.7514
Epoch 8
Validation loss decreased. Saved checkpoint for step 9: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-6
Time:  2.47s, ---- Loss: 0.4266, Acc.: 0.8357, Val. Loss: 0.6724, Val. Acc.: 0.7759
Epoch 9
Validation loss decreased. Saved checkpoint for step 10: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-7
Time:  2.45s, ---- Loss: 0.4242, Acc.: 0.8405, Val. Loss: 0.6235, Val. Acc.: 0.7891
Epoch 10
Validation loss decreased. Saved checkpoint for step 11: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-8
Time:  2.45s, ---- Loss: 0.4102, Acc.: 0.8449, Val. Loss: 0.6033, Val. Acc.: 0.7950
Epoch 11
Validation loss decreased. Saved checkpoint for step 12: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-9
Time:  2.45s, ---- Loss: 0.4048, Acc.: 0.8481, Val. Loss: 0.5567, Val. Acc.: 0.8091
Epoch 12
Validation loss decreased. Saved checkpoint for step 13: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-10
Time:  2.45s, ---- Loss: 0.3993, Acc.: 0.8519, Val. Loss: 0.5512, Val. Acc.: 0.8148
Epoch 13
Validation loss decreased. Saved checkpoint for step 14: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-11
Time:  2.47s, ---- Loss: 0.3854, Acc.: 0.8543, Val. Loss: 0.5447, Val. Acc.: 0.8179
Epoch 14
Loss did not decrease. Count = 1
Time:  2.33s, ---- Loss: 0.3800, Acc.: 0.8568, Val. Loss: 0.5535, Val. Acc.: 0.8147
Epoch 15
Validation loss decreased. Saved checkpoint for step 16: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-12
Time:  2.44s, ---- Loss: 0.3768, Acc.: 0.8593, Val. Loss: 0.5318, Val. Acc.: 0.8249
Epoch 16
Validation loss decreased. Saved checkpoint for step 17: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-13
Time:  2.45s, ---- Loss: 0.3750, Acc.: 0.8607, Val. Loss: 0.5132, Val. Acc.: 0.8315
Epoch 17
Loss did not decrease. Count = 1
Time:  2.33s, ---- Loss: 0.3688, Acc.: 0.8628, Val. Loss: 0.5134, Val. Acc.: 0.8326
Epoch 18
Validation loss decreased. Saved checkpoint for step 19: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-14
Time:  2.47s, ---- Loss: 0.3664, Acc.: 0.8642, Val. Loss: 0.4944, Val. Acc.: 0.8383
Epoch 19
Validation loss decreased. Saved checkpoint for step 20: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-15
Time:  2.45s, ---- Loss: 0.3627, Acc.: 0.8652, Val. Loss: 0.4942, Val. Acc.: 0.8391
Epoch 20
Validation loss decreased. Saved checkpoint for step 21: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-16
Time:  2.46s, ---- Loss: 0.3582, Acc.: 0.8669, Val. Loss: 0.4578, Val. Acc.: 0.8523
Epoch 21
Loss did not decrease. Count = 1
Time:  2.33s, ---- Loss: 0.3570, Acc.: 0.8682, Val. Loss: 0.4760, Val. Acc.: 0.8462
Epoch 22
Loss did not decrease. Count = 2
Time:  2.34s, ---- Loss: 0.3566, Acc.: 0.8693, Val. Loss: 0.4629, Val. Acc.: 0.8510
Epoch 23
Loss did not decrease. Count = 3
Time:  2.34s, ---- Loss: 0.3487, Acc.: 0.8706, Val. Loss: 0.4598, Val. Acc.: 0.8517
Epoch 24
Validation loss decreased. Saved checkpoint for step 25: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-17
Time:  2.44s, ---- Loss: 0.3492, Acc.: 0.8716, Val. Loss: 0.4415, Val. Acc.: 0.8611
Epoch 25
Validation loss decreased. Saved checkpoint for step 26: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-18
Time:  2.46s, ---- Loss: 0.3485, Acc.: 0.8728, Val. Loss: 0.4339, Val. Acc.: 0.8640
Epoch 26
Validation loss decreased. Saved checkpoint for step 27: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-19
Time:  2.45s, ---- Loss: 0.3421, Acc.: 0.8737, Val. Loss: 0.4314, Val. Acc.: 0.8647
Epoch 27
Loss did not decrease. Count = 1
Time:  2.35s, ---- Loss: 0.3448, Acc.: 0.8745, Val. Loss: 0.4380, Val. Acc.: 0.8629
Epoch 28
Validation loss decreased. Saved checkpoint for step 29: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-20
Time:  2.46s, ---- Loss: 0.3391, Acc.: 0.8753, Val. Loss: 0.4305, Val. Acc.: 0.8648
Epoch 29
Loss did not decrease. Count = 1
Time:  2.35s, ---- Loss: 0.3403, Acc.: 0.8762, Val. Loss: 0.4316, Val. Acc.: 0.8638
Epoch 30
Validation loss decreased. Saved checkpoint for step 31: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-21
Time:  2.45s, ---- Loss: 0.3385, Acc.: 0.8768, Val. Loss: 0.4275, Val. Acc.: 0.8658
Epoch 31
Loss did not decrease. Count = 1
Time:  2.33s, ---- Loss: 0.3395, Acc.: 0.8772, Val. Loss: 0.4286, Val. Acc.: 0.8650
Epoch 32
Validation loss decreased. Saved checkpoint for step 33: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-22
Time:  2.48s, ---- Loss: 0.3329, Acc.: 0.8779, Val. Loss: 0.4194, Val. Acc.: 0.8699
Epoch 33
Validation loss decreased. Saved checkpoint for step 34: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-23
Time:  2.46s, ---- Loss: 0.3314, Acc.: 0.8784, Val. Loss: 0.4154, Val. Acc.: 0.8727
Epoch 34
Loss did not decrease. Count = 1
Time:  2.32s, ---- Loss: 0.3340, Acc.: 0.8788, Val. Loss: 0.4218, Val. Acc.: 0.8701
Epoch 35
Loss did not decrease. Count = 2
Time:  2.32s, ---- Loss: 0.3304, Acc.: 0.8794, Val. Loss: 0.4167, Val. Acc.: 0.8731
Epoch 36
Loss did not decrease. Count = 3
Time:  2.33s, ---- Loss: 0.3336, Acc.: 0.8795, Val. Loss: 0.4224, Val. Acc.: 0.8707
Epoch 37
Loss did not decrease. Count = 4
Time:  2.34s, ---- Loss: 0.3270, Acc.: 0.8803, Val. Loss: 0.4198, Val. Acc.: 0.8714
Epoch 38
Loss did not decrease. Count = 5
Time:  2.33s, ---- Loss: 0.3297, Acc.: 0.8806, Val. Loss: 0.4158, Val. Acc.: 0.8735
Epoch 39
Validation loss decreased. Saved checkpoint for step 40: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-24
Time:  2.46s, ---- Loss: 0.3283, Acc.: 0.8807, Val. Loss: 0.4135, Val. Acc.: 0.8738
Epoch 40
Loss did not decrease. Count = 1
Time:  2.33s, ---- Loss: 0.3277, Acc.: 0.8813, Val. Loss: 0.4152, Val. Acc.: 0.8733
Epoch 41
Validation loss decreased. Saved checkpoint for step 42: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-25
Time:  2.47s, ---- Loss: 0.3271, Acc.: 0.8817, Val. Loss: 0.4123, Val. Acc.: 0.8751
Epoch 42
Validation loss decreased. Saved checkpoint for step 43: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-26
Time:  2.46s, ---- Loss: 0.3261, Acc.: 0.8821, Val. Loss: 0.4090, Val. Acc.: 0.8761
Epoch 43
Validation loss decreased. Saved checkpoint for step 44: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-27
Time:  2.44s, ---- Loss: 0.3204, Acc.: 0.8820, Val. Loss: 0.4052, Val. Acc.: 0.8778
Epoch 44
Loss did not decrease. Count = 1
Time:  2.32s, ---- Loss: 0.3263, Acc.: 0.8823, Val. Loss: 0.4086, Val. Acc.: 0.8764
Epoch 45
Loss did not decrease. Count = 2
Time:  2.33s, ---- Loss: 0.3221, Acc.: 0.8829, Val. Loss: 0.4062, Val. Acc.: 0.8777
Epoch 46
Loss did not decrease. Count = 3
Time:  2.33s, ---- Loss: 0.3263, Acc.: 0.8830, Val. Loss: 0.4053, Val. Acc.: 0.8786
Epoch 47
Validation loss decreased. Saved checkpoint for step 48: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-28
Time:  2.45s, ---- Loss: 0.3220, Acc.: 0.8834, Val. Loss: 0.4040, Val. Acc.: 0.8797
Epoch 48
Loss did not decrease. Count = 1
Time:  2.33s, ---- Loss: 0.3197, Acc.: 0.8834, Val. Loss: 0.4075, Val. Acc.: 0.8778
Epoch 49
Loss did not decrease. Count = 2
Time:  2.33s, ---- Loss: 0.3205, Acc.: 0.8838, Val. Loss: 0.4185, Val. Acc.: 0.8733
Epoch 50
Loss did not decrease. Count = 3
Time:  2.33s, ---- Loss: 0.3220, Acc.: 0.8839, Val. Loss: 0.4176, Val. Acc.: 0.8741
Epoch 51
Loss did not decrease. Count = 4
Time:  2.35s, ---- Loss: 0.3189, Acc.: 0.8840, Val. Loss: 0.4054, Val. Acc.: 0.8788
Epoch 52
Validation loss decreased. Saved checkpoint for step 53: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-29
Time:  2.45s, ---- Loss: 0.3210, Acc.: 0.8840, Val. Loss: 0.3990, Val. Acc.: 0.8816
Epoch 53
Loss did not decrease. Count = 1
Time:  2.33s, ---- Loss: 0.3193, Acc.: 0.8845, Val. Loss: 0.4018, Val. Acc.: 0.8799
Epoch 54
Loss did not decrease. Count = 2
Time:  2.33s, ---- Loss: 0.3203, Acc.: 0.8845, Val. Loss: 0.4089, Val. Acc.: 0.8775
Epoch 55
Loss did not decrease. Count = 3
Time:  2.33s, ---- Loss: 0.3190, Acc.: 0.8847, Val. Loss: 0.4096, Val. Acc.: 0.8771
Epoch 56
Loss did not decrease. Count = 4
Time:  2.37s, ---- Loss: 0.3161, Acc.: 0.8849, Val. Loss: 0.4012, Val. Acc.: 0.8810
Epoch 57
Loss did not decrease. Count = 5
Time:  2.33s, ---- Loss: 0.3186, Acc.: 0.8851, Val. Loss: 0.4017, Val. Acc.: 0.8802
Epoch 58
Loss did not decrease. Count = 6
Time:  2.33s, ---- Loss: 0.3156, Acc.: 0.8852, Val. Loss: 0.3991, Val. Acc.: 0.8814
Epoch 59
Loss did not decrease. Count = 7
Time:  2.33s, ---- Loss: 0.3196, Acc.: 0.8852, Val. Loss: 0.4016, Val. Acc.: 0.8799
Epoch 60
Loss did not decrease. Count = 8
Time:  2.34s, ---- Loss: 0.3174, Acc.: 0.8853, Val. Loss: 0.4048, Val. Acc.: 0.8795
Epoch 61
Validation loss decreased. Saved checkpoint for step 62: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-30
Time:  2.47s, ---- Loss: 0.3166, Acc.: 0.8856, Val. Loss: 0.3975, Val. Acc.: 0.8825
Epoch 62
Loss did not decrease. Count = 1
Time:  2.33s, ---- Loss: 0.3146, Acc.: 0.8856, Val. Loss: 0.3983, Val. Acc.: 0.8820
Epoch 63
Validation loss decreased. Saved checkpoint for step 64: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-31
Time:  2.45s, ---- Loss: 0.3132, Acc.: 0.8858, Val. Loss: 0.3964, Val. Acc.: 0.8822
Epoch 64
Loss did not decrease. Count = 1
Time:  2.34s, ---- Loss: 0.3161, Acc.: 0.8861, Val. Loss: 0.3974, Val. Acc.: 0.8821
Epoch 65
Validation loss decreased. Saved checkpoint for step 66: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-32
Time:  2.47s, ---- Loss: 0.3178, Acc.: 0.8859, Val. Loss: 0.3953, Val. Acc.: 0.8832
Epoch 66
Validation loss decreased. Saved checkpoint for step 67: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-33
Time:  2.46s, ---- Loss: 0.3158, Acc.: 0.8864, Val. Loss: 0.3945, Val. Acc.: 0.8830
Epoch 67
Loss did not decrease. Count = 1
Time:  2.33s, ---- Loss: 0.3163, Acc.: 0.8862, Val. Loss: 0.3958, Val. Acc.: 0.8829
Epoch 68
Loss did not decrease. Count = 2
Time:  2.33s, ---- Loss: 0.3162, Acc.: 0.8860, Val. Loss: 0.3957, Val. Acc.: 0.8832
Epoch 69
Loss did not decrease. Count = 3
Time:  2.34s, ---- Loss: 0.3134, Acc.: 0.8862, Val. Loss: 0.3962, Val. Acc.: 0.8825
Epoch 70
Validation loss decreased. Saved checkpoint for step 71: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-34
Time:  2.46s, ---- Loss: 0.3162, Acc.: 0.8862, Val. Loss: 0.3927, Val. Acc.: 0.8841
Epoch 71
Loss did not decrease. Count = 1
Time:  2.34s, ---- Loss: 0.3130, Acc.: 0.8861, Val. Loss: 0.3935, Val. Acc.: 0.8842
Epoch 72
Validation loss decreased. Saved checkpoint for step 73: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-35
Time:  2.45s, ---- Loss: 0.3135, Acc.: 0.8861, Val. Loss: 0.3923, Val. Acc.: 0.8842
Epoch 73
Validation loss decreased. Saved checkpoint for step 74: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-36
Time:  2.46s, ---- Loss: 0.3188, Acc.: 0.8866, Val. Loss: 0.3921, Val. Acc.: 0.8845
Epoch 74
Loss did not decrease. Count = 1
Time:  2.32s, ---- Loss: 0.3140, Acc.: 0.8865, Val. Loss: 0.3953, Val. Acc.: 0.8836
Epoch 75
Loss did not decrease. Count = 2
Time:  2.34s, ---- Loss: 0.3160, Acc.: 0.8866, Val. Loss: 0.3937, Val. Acc.: 0.8841
Epoch 76
Validation loss decreased. Saved checkpoint for step 77: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-37
Time:  2.45s, ---- Loss: 0.3147, Acc.: 0.8868, Val. Loss: 0.3918, Val. Acc.: 0.8849
Epoch 77
Loss did not decrease. Count = 1
Time:  2.34s, ---- Loss: 0.3134, Acc.: 0.8869, Val. Loss: 0.3925, Val. Acc.: 0.8847
Epoch 78
Validation loss decreased. Saved checkpoint for step 79: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-38
Time:  2.45s, ---- Loss: 0.3135, Acc.: 0.8867, Val. Loss: 0.3912, Val. Acc.: 0.8850
Epoch 79
Validation loss decreased. Saved checkpoint for step 80: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-39
Time:  2.46s, ---- Loss: 0.3127, Acc.: 0.8869, Val. Loss: 0.3911, Val. Acc.: 0.8852
Epoch 80
Validation loss decreased. Saved checkpoint for step 81: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-40
Time:  2.48s, ---- Loss: 0.3145, Acc.: 0.8867, Val. Loss: 0.3907, Val. Acc.: 0.8850
Epoch 81
Validation loss decreased. Saved checkpoint for step 82: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-41
Time:  2.47s, ---- Loss: 0.3120, Acc.: 0.8870, Val. Loss: 0.3906, Val. Acc.: 0.8851
Epoch 82
Loss did not decrease. Count = 1
Time:  2.33s, ---- Loss: 0.3134, Acc.: 0.8871, Val. Loss: 0.3915, Val. Acc.: 0.8855
Epoch 83
Validation loss decreased. Saved checkpoint for step 84: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-42
Time:  2.45s, ---- Loss: 0.3142, Acc.: 0.8869, Val. Loss: 0.3903, Val. Acc.: 0.8855
Epoch 84
Validation loss decreased. Saved checkpoint for step 85: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-43
Time:  2.45s, ---- Loss: 0.3123, Acc.: 0.8868, Val. Loss: 0.3897, Val. Acc.: 0.8861
Epoch 85
Validation loss decreased. Saved checkpoint for step 86: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-44
Time:  2.47s, ---- Loss: 0.3117, Acc.: 0.8871, Val. Loss: 0.3896, Val. Acc.: 0.8857
Epoch 86
Validation loss decreased. Saved checkpoint for step 87: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-45
Time:  2.45s, ---- Loss: 0.3147, Acc.: 0.8871, Val. Loss: 0.3892, Val. Acc.: 0.8859
Epoch 87
Loss did not decrease. Count = 1
Time:  2.33s, ---- Loss: 0.3134, Acc.: 0.8872, Val. Loss: 0.3895, Val. Acc.: 0.8859
Epoch 88
Loss did not decrease. Count = 2
Time:  2.33s, ---- Loss: 0.3122, Acc.: 0.8872, Val. Loss: 0.3893, Val. Acc.: 0.8859
Epoch 89
Loss did not decrease. Count = 3
Time:  2.33s, ---- Loss: 0.3129, Acc.: 0.8873, Val. Loss: 0.3894, Val. Acc.: 0.8859
Epoch 90
Loss did not decrease. Count = 4
Time:  2.34s, ---- Loss: 0.3132, Acc.: 0.8872, Val. Loss: 0.3895, Val. Acc.: 0.8856
Epoch 91
Validation loss decreased. Saved checkpoint for step 92: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-46
Time:  2.46s, ---- Loss: 0.3136, Acc.: 0.8874, Val. Loss: 0.3889, Val. Acc.: 0.8856
Epoch 92
Loss did not decrease. Count = 1
Time:  2.33s, ---- Loss: 0.3123, Acc.: 0.8873, Val. Loss: 0.3891, Val. Acc.: 0.8858
Epoch 93
Validation loss decreased. Saved checkpoint for step 94: models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/tf_ckpts/ckpt-47
Time:  2.45s, ---- Loss: 0.3111, Acc.: 0.8872, Val. Loss: 0.3889, Val. Acc.: 0.8858
Epoch 94
Loss did not decrease. Count = 1
Time:  2.35s, ---- Loss: 0.3146, Acc.: 0.8874, Val. Loss: 0.3891, Val. Acc.: 0.8862
Epoch 95
Loss did not decrease. Count = 2
Time:  2.33s, ---- Loss: 0.3139, Acc.: 0.8874, Val. Loss: 0.3894, Val. Acc.: 0.8858
Epoch 96
Loss did not decrease. Count = 3
Time:  2.34s, ---- Loss: 0.3130, Acc.: 0.8878, Val. Loss: 0.3894, Val. Acc.: 0.8856
Epoch 97
Loss did not decrease. Count = 4
Time:  2.33s, ---- Loss: 0.3119, Acc.: 0.8875, Val. Loss: 0.3892, Val. Acc.: 0.8859
Epoch 98
Loss did not decrease. Count = 5
Time:  2.33s, ---- Loss: 0.3125, Acc.: 0.8876, Val. Loss: 0.3889, Val. Acc.: 0.8859
Epoch 99
Loss did not decrease. Count = 6
Time:  2.34s, ---- Loss: 0.3123, Acc.: 0.8873, Val. Loss: 0.3889, Val. Acc.: 0.8861
Saving at models/fivelabel_20k_equalexamples-randoms_kmin-0.0_kmax-2.5_/hist.png
Done in 3561.18s


 -------- Parameters:
bayesian True
test_mode False
n_test_idx 2
seed 1312
fine_tune False
one_vs_all False
c_0 ['lcdm']
c_1 ['True', 'dgp', 'ds', 'fR', 'rand--save_ckpt', 'wcdm']
dataset_balanced False
include_last False
log_path models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA_log.txt
restore False
fname sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA
model_name custom
my_path None
DIR data/train
TEST_DIR data/test/
models_dir models/
save_ckpt True
out_path_overwrite False
curves_folder data/curve_files_sys/theory_error
save_processed_spectra False
cache_dir False
im_depth 500
im_width 1
im_channels 4
swap_axes True
sort_labels True
norm_data_name /planck_ee2.txt
normalization stdcosmo
sample_pace 1
k_max 2.5
k_min 0.0
i_max None
i_min None
add_noise True
n_noisy_samples 10
add_shot False
add_sys True
add_cosvar True
sigma_sys None
sys_scaled None
sys_factor None
sys_max None
sigma_curves 0.05
sigma_curves_default 0.05
rescale_curves uniform
z_bins [0, 1, 2, 3]
n_dense 1
filters [8, 16, 32]
kernel_sizes [10, 5, 2]
strides [2, 2, 1]
pool_sizes [2, 2, 0]
strides_pooling [2, 1, 0]
add_FT_dense False
trainable False
unfreeze False
lr 0.01
drop 0.5
n_epochs 100
val_size 0.15
test_size 0.0
batch_size 3000
patience 20
GPU True
TPU False
decay 0.95
BatchNorm True
padding valid
shuffle True

------------ CREATING DATA GENERATORS ------------
labels : ['dgp', 'ds_binA', 'fr', 'lcdm', 'rand', 'wcdm']
Labels encoding: 
{'dgp': 0, 'ds_binA': 1, 'fr': 2, 'lcdm': 3, 'rand': 4, 'wcdm': 5}
n_labels : 6
dgp - 5000 training examples
ds_binA - 5000 training examples
fr - 5000 training examples
lcdm - 5000 training examples
rand - 5000 training examples
wcdm - 5000 training examples

N. of data files: 5000
get_all_indexes labels dict: {'dgp': 0, 'ds_binA': 1, 'fr': 2, 'lcdm': 3, 'rand': 4, 'wcdm': 5}
create_generators n_labels: 6
create_generators n_labels_eff: 6
create_generators len_c1: 1
Check for no duplicates in test: (0=ok):
0.0
Check for no duplicates in val: (0=ok):
0
N of indexes in training set: 4250
N of indexes in validation set: 750
N of indexes in test set: 0
Check - total per class: 5000
--create_generators, train indexes
batch_size: 3000
- Cut sample
bs: 3000
N_labels: 6
N_noise: 10
len_c1: 1
Train index length: 4250
--create_generators, validation indexes
- Cut sample
bs: 3000
N_labels: 6
N_noise: 10
len_c1: 1
Val index length: 750
len(train_index_1), batch_size, n_labels_eff, n_noisy_samples = 4250, 3000, 6, 10

--DataSet Train
DataSet Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 2.5
Corresponding i_max is 399
Closest k to k_max is 2.504942
Specified k_min is 0.0
Corresponding i_min is 0
Closest k to k_min is 0.01
New data dim: (399, 1)
Final i_max used is 399
Final i_min used is 0
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 6
N. n_classes in output: 6
LABELS: ['dgp', 'ds_binA', 'fr', 'lcdm', 'rand', 'wcdm']
list_IDs length: 4250
n_indexes (n of file IDs read for each batch): 50
batch size: 3000
n_batches : 85
For each batch we read 50 file IDs
For each file ID we have 6 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 3000 training examples
Input batch size: 3000
N of batches to cover all file IDs: 85
len(fname_list), batch_size, n_noisy_samples, n_batches: 25500, 3000, 10, 85

--DataSet Validation
DataSet Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 2.5
Corresponding i_max is 399
Closest k to k_max is 2.504942
Specified k_min is 0.0
Corresponding i_min is 0
Closest k to k_min is 0.01
New data dim: (399, 1)
Final i_max used is 399
Final i_min used is 0
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 6
N. n_classes in output: 6
LABELS: ['dgp', 'ds_binA', 'fr', 'lcdm', 'rand', 'wcdm']
list_IDs length: 750
n_indexes (n of file IDs read for each batch): 50
batch size: 3000
n_batches : 15
For each batch we read 50 file IDs
For each file ID we have 6 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 3000 training examples
Input batch size: 3000
N of batches to cover all file IDs: 15
len(fname_list), batch_size, n_noisy_samples, n_batches: 4500, 3000, 10, 15
------------ DONE ------------

------------ BUILDING MODEL ------------
Input shape (399, 4)
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 399, 4)]          0         
                                                                 
 conv1d_flipout (Conv1DFlip  (None, 195, 8)            648       
 out)                                                            
                                                                 
 max_pooling1d (MaxPooling1  (None, 97, 8)             0         
 D)                                                              
                                                                 
 batch_normalization (Batch  (None, 97, 8)             32        
 Normalization)                                                  
                                                                 
 conv1d_flipout_1 (Conv1DFl  (None, 47, 16)            1296      
 ipout)                                                          
                                                                 
 max_pooling1d_1 (MaxPoolin  (None, 46, 16)            0         
 g1D)                                                            
                                                                 
 batch_normalization_1 (Bat  (None, 46, 16)            64        
 chNormalization)                                                
                                                                 
 conv1d_flipout_2 (Conv1DFl  (None, 45, 32)            2080      
 ipout)                                                          
                                                                 
 batch_normalization_2 (Bat  (None, 45, 32)            128       
 chNormalization)                                                
                                                                 
 global_average_pooling1d (  (None, 32)                0         
 GlobalAveragePooling1D)                                         
                                                                 
 dense_flipout (DenseFlipou  (None, 32)                2080      
 t)                                                              
                                                                 
 batch_normalization_3 (Bat  (None, 32)                128       
 chNormalization)                                                
                                                                 
 dense_flipout_1 (DenseFlip  (None, 6)                 390       
 out)                                                            
                                                                 
=================================================================
Total params: 6846 (26.74 KB)
Trainable params: 6670 (26.05 KB)
Non-trainable params: 176 (704.00 Byte)
_________________________________________________________________
None
Found GPU at: /device:GPU:0
------------ TRAINING ------------

Features shape: (3000, 399, 4)
Labels shape: (3000, 6)
Initializing checkpoint from scratch.
Epoch 0
Validation loss decreased. Saved checkpoint for step 1: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-1
Time:  33.83s, ---- Loss: 1.1399, Acc.: 0.4642, Val. Loss: 2.9978, Val. Acc.: 0.2013

Epoch 1
Loss did not decrease. Count = 1
Time:  0.98s, ---- Loss: 0.9856, Acc.: 0.5750, Val. Loss: 3.8621, Val. Acc.: 0.1670

Epoch 2
Loss did not decrease. Count = 2
Time:  0.95s, ---- Loss: 0.8866, Acc.: 0.6278, Val. Loss: 3.4531, Val. Acc.: 0.2182

Epoch 3
Validation loss decreased. Saved checkpoint for step 4: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-2
Time:  1.07s, ---- Loss: 0.8310, Acc.: 0.6580, Val. Loss: 2.3518, Val. Acc.: 0.3442

Epoch 4
Validation loss decreased. Saved checkpoint for step 5: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-3
Time:  1.08s, ---- Loss: 0.8039, Acc.: 0.6734, Val. Loss: 1.6382, Val. Acc.: 0.4388

Epoch 5
Validation loss decreased. Saved checkpoint for step 6: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-4
Time:  1.07s, ---- Loss: 0.7840, Acc.: 0.6855, Val. Loss: 1.1403, Val. Acc.: 0.6143

Epoch 6
Validation loss decreased. Saved checkpoint for step 7: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-5
Time:  1.08s, ---- Loss: 0.7680, Acc.: 0.6935, Val. Loss: 1.0366, Val. Acc.: 0.6572

Epoch 7
Validation loss decreased. Saved checkpoint for step 8: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-6
Time:  1.07s, ---- Loss: 0.7537, Acc.: 0.6997, Val. Loss: 1.0196, Val. Acc.: 0.6630

Epoch 8
Validation loss decreased. Saved checkpoint for step 9: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-7
Time:  1.08s, ---- Loss: 0.7238, Acc.: 0.7047, Val. Loss: 1.0174, Val. Acc.: 0.6629

Epoch 9
Loss did not decrease. Count = 1
Time:  0.96s, ---- Loss: 0.7321, Acc.: 0.7093, Val. Loss: 1.0621, Val. Acc.: 0.6477

Epoch 10
Loss did not decrease. Count = 2
Time:  0.96s, ---- Loss: 0.7127, Acc.: 0.7130, Val. Loss: 1.0748, Val. Acc.: 0.6424

Epoch 11
Validation loss decreased. Saved checkpoint for step 12: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-8
Time:  1.08s, ---- Loss: 0.7086, Acc.: 0.7162, Val. Loss: 1.0095, Val. Acc.: 0.6665

Epoch 12
Validation loss decreased. Saved checkpoint for step 13: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-9
Time:  1.08s, ---- Loss: 0.6980, Acc.: 0.7185, Val. Loss: 0.9897, Val. Acc.: 0.6750

Epoch 13
Loss did not decrease. Count = 1
Time:  0.95s, ---- Loss: 0.6919, Acc.: 0.7217, Val. Loss: 0.9911, Val. Acc.: 0.6742

Epoch 14
Validation loss decreased. Saved checkpoint for step 15: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-10
Time:  1.07s, ---- Loss: 0.6884, Acc.: 0.7232, Val. Loss: 0.9231, Val. Acc.: 0.7026

Epoch 15
Validation loss decreased. Saved checkpoint for step 16: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-11
Time:  1.07s, ---- Loss: 0.6815, Acc.: 0.7255, Val. Loss: 0.9101, Val. Acc.: 0.7054

Epoch 16
Loss did not decrease. Count = 1
Time:  0.95s, ---- Loss: 0.6856, Acc.: 0.7279, Val. Loss: 0.9208, Val. Acc.: 0.7059

Epoch 17
Loss did not decrease. Count = 2
Time:  0.95s, ---- Loss: 0.6775, Acc.: 0.7294, Val. Loss: 0.9382, Val. Acc.: 0.6989

Epoch 18
Loss did not decrease. Count = 3
Time:  0.95s, ---- Loss: 0.6687, Acc.: 0.7312, Val. Loss: 0.9237, Val. Acc.: 0.7067

Epoch 19
Validation loss decreased. Saved checkpoint for step 20: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-12
Time:  1.06s, ---- Loss: 0.6729, Acc.: 0.7329, Val. Loss: 0.8877, Val. Acc.: 0.7198

Epoch 20
Loss did not decrease. Count = 1
Time:  0.98s, ---- Loss: 0.6671, Acc.: 0.7332, Val. Loss: 0.8877, Val. Acc.: 0.7206

Epoch 21
Loss did not decrease. Count = 2
Time:  0.96s, ---- Loss: 0.6643, Acc.: 0.7352, Val. Loss: 0.9135, Val. Acc.: 0.7128

Epoch 22
Loss did not decrease. Count = 3
Time:  0.95s, ---- Loss: 0.6596, Acc.: 0.7363, Val. Loss: 0.9131, Val. Acc.: 0.7128

Epoch 23
Loss did not decrease. Count = 4
Time:  0.95s, ---- Loss: 0.6683, Acc.: 0.7360, Val. Loss: 0.9012, Val. Acc.: 0.7170

Epoch 24
Loss did not decrease. Count = 5
Time:  0.95s, ---- Loss: 0.6688, Acc.: 0.7379, Val. Loss: 0.9047, Val. Acc.: 0.7172

Epoch 25
Loss did not decrease. Count = 6
Time:  0.95s, ---- Loss: 0.6529, Acc.: 0.7385, Val. Loss: 0.8907, Val. Acc.: 0.7223

Epoch 26
Loss did not decrease. Count = 7
Time:  0.95s, ---- Loss: 0.6570, Acc.: 0.7397, Val. Loss: 0.9105, Val. Acc.: 0.7202

Epoch 27
Loss did not decrease. Count = 8
Time:  0.96s, ---- Loss: 0.6576, Acc.: 0.7406, Val. Loss: 0.9184, Val. Acc.: 0.7162

Epoch 28
Loss did not decrease. Count = 9
Time:  0.96s, ---- Loss: 0.6498, Acc.: 0.7410, Val. Loss: 0.9271, Val. Acc.: 0.7145

Epoch 29
Loss did not decrease. Count = 10
Time:  0.95s, ---- Loss: 0.6506, Acc.: 0.7414, Val. Loss: 0.8970, Val. Acc.: 0.7192

Epoch 30
Loss did not decrease. Count = 11
Time:  0.95s, ---- Loss: 0.6507, Acc.: 0.7421, Val. Loss: 0.8899, Val. Acc.: 0.7221

Epoch 31
Validation loss decreased. Saved checkpoint for step 32: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-13
Time:  1.07s, ---- Loss: 0.6425, Acc.: 0.7423, Val. Loss: 0.8781, Val. Acc.: 0.7262

Epoch 32
Validation loss decreased. Saved checkpoint for step 33: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-14
Time:  1.08s, ---- Loss: 0.6380, Acc.: 0.7435, Val. Loss: 0.8673, Val. Acc.: 0.7301

Epoch 33
Validation loss decreased. Saved checkpoint for step 34: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-15
Time:  1.07s, ---- Loss: 0.6390, Acc.: 0.7432, Val. Loss: 0.8519, Val. Acc.: 0.7342

Epoch 34
Loss did not decrease. Count = 1
Time:  0.95s, ---- Loss: 0.6392, Acc.: 0.7439, Val. Loss: 0.8526, Val. Acc.: 0.7353

Epoch 35
Loss did not decrease. Count = 2
Time:  0.95s, ---- Loss: 0.6392, Acc.: 0.7440, Val. Loss: 0.8588, Val. Acc.: 0.7334

Epoch 36
Loss did not decrease. Count = 3
Time:  0.95s, ---- Loss: 0.6352, Acc.: 0.7451, Val. Loss: 0.8598, Val. Acc.: 0.7317

Epoch 37
Loss did not decrease. Count = 4
Time:  0.95s, ---- Loss: 0.6356, Acc.: 0.7462, Val. Loss: 0.8678, Val. Acc.: 0.7262

Epoch 38
Loss did not decrease. Count = 5
Time:  0.95s, ---- Loss: 0.6396, Acc.: 0.7460, Val. Loss: 0.8611, Val. Acc.: 0.7303

Epoch 39
Validation loss decreased. Saved checkpoint for step 40: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-16
Time:  1.08s, ---- Loss: 0.6336, Acc.: 0.7461, Val. Loss: 0.8517, Val. Acc.: 0.7348

Epoch 40
Loss did not decrease. Count = 1
Time:  0.96s, ---- Loss: 0.6351, Acc.: 0.7468, Val. Loss: 0.8705, Val. Acc.: 0.7288

Epoch 41
Loss did not decrease. Count = 2
Time:  0.96s, ---- Loss: 0.6325, Acc.: 0.7464, Val. Loss: 0.8606, Val. Acc.: 0.7317

Epoch 42
Loss did not decrease. Count = 3
Time:  0.95s, ---- Loss: 0.6333, Acc.: 0.7474, Val. Loss: 0.8536, Val. Acc.: 0.7341

Epoch 43
Loss did not decrease. Count = 4
Time:  0.96s, ---- Loss: 0.6362, Acc.: 0.7482, Val. Loss: 0.8693, Val. Acc.: 0.7286

Epoch 44
Loss did not decrease. Count = 5
Time:  0.96s, ---- Loss: 0.6385, Acc.: 0.7478, Val. Loss: 0.8558, Val. Acc.: 0.7338

Epoch 45
Loss did not decrease. Count = 6
Time:  0.95s, ---- Loss: 0.6372, Acc.: 0.7484, Val. Loss: 0.8655, Val. Acc.: 0.7304

Epoch 46
Validation loss decreased. Saved checkpoint for step 47: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-17
Time:  1.07s, ---- Loss: 0.6288, Acc.: 0.7489, Val. Loss: 0.8514, Val. Acc.: 0.7378

Epoch 47
Loss did not decrease. Count = 1
Time:  0.96s, ---- Loss: 0.6279, Acc.: 0.7485, Val. Loss: 0.8558, Val. Acc.: 0.7342

Epoch 48
Validation loss decreased. Saved checkpoint for step 49: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-18
Time:  1.07s, ---- Loss: 0.6293, Acc.: 0.7495, Val. Loss: 0.8482, Val. Acc.: 0.7376

Epoch 49
Loss did not decrease. Count = 1
Time:  0.95s, ---- Loss: 0.6280, Acc.: 0.7486, Val. Loss: 0.8604, Val. Acc.: 0.7324

Epoch 50
Loss did not decrease. Count = 2
Time:  0.95s, ---- Loss: 0.6352, Acc.: 0.7497, Val. Loss: 0.8618, Val. Acc.: 0.7330

Epoch 51
Loss did not decrease. Count = 3
Time:  0.95s, ---- Loss: 0.6246, Acc.: 0.7494, Val. Loss: 0.8493, Val. Acc.: 0.7389

Epoch 52
Validation loss decreased. Saved checkpoint for step 53: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-19
Time:  1.06s, ---- Loss: 0.6289, Acc.: 0.7495, Val. Loss: 0.8466, Val. Acc.: 0.7374

Epoch 53
Validation loss decreased. Saved checkpoint for step 54: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-20
Time:  1.07s, ---- Loss: 0.6259, Acc.: 0.7498, Val. Loss: 0.8466, Val. Acc.: 0.7379

Epoch 54
Validation loss decreased. Saved checkpoint for step 55: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-21
Time:  1.09s, ---- Loss: 0.6247, Acc.: 0.7502, Val. Loss: 0.8436, Val. Acc.: 0.7402

Epoch 55
Loss did not decrease. Count = 1
Time:  0.97s, ---- Loss: 0.6251, Acc.: 0.7505, Val. Loss: 0.8448, Val. Acc.: 0.7410

Epoch 56
Validation loss decreased. Saved checkpoint for step 57: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-22
Time:  1.07s, ---- Loss: 0.6285, Acc.: 0.7507, Val. Loss: 0.8401, Val. Acc.: 0.7410

Epoch 57
Loss did not decrease. Count = 1
Time:  0.95s, ---- Loss: 0.6290, Acc.: 0.7512, Val. Loss: 0.8437, Val. Acc.: 0.7390

Epoch 58
Loss did not decrease. Count = 2
Time:  0.95s, ---- Loss: 0.6220, Acc.: 0.7514, Val. Loss: 0.8438, Val. Acc.: 0.7399

Epoch 59
Validation loss decreased. Saved checkpoint for step 60: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-23
Time:  1.09s, ---- Loss: 0.6238, Acc.: 0.7512, Val. Loss: 0.8397, Val. Acc.: 0.7409

Epoch 60
Validation loss decreased. Saved checkpoint for step 61: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-24
Time:  1.09s, ---- Loss: 0.6220, Acc.: 0.7514, Val. Loss: 0.8374, Val. Acc.: 0.7440

Epoch 61
Validation loss decreased. Saved checkpoint for step 62: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-25
Time:  1.07s, ---- Loss: 0.6216, Acc.: 0.7510, Val. Loss: 0.8373, Val. Acc.: 0.7426

Epoch 62
Loss did not decrease. Count = 1
Time:  0.95s, ---- Loss: 0.6225, Acc.: 0.7517, Val. Loss: 0.8405, Val. Acc.: 0.7400

Epoch 63
Loss did not decrease. Count = 2
Time:  0.94s, ---- Loss: 0.6224, Acc.: 0.7513, Val. Loss: 0.8380, Val. Acc.: 0.7444

Epoch 64
Validation loss decreased. Saved checkpoint for step 65: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-26
Time:  1.07s, ---- Loss: 0.6322, Acc.: 0.7525, Val. Loss: 0.8360, Val. Acc.: 0.7427

Epoch 65
Loss did not decrease. Count = 1
Time:  0.96s, ---- Loss: 0.6225, Acc.: 0.7516, Val. Loss: 0.8394, Val. Acc.: 0.7435

Epoch 66
Loss did not decrease. Count = 2
Time:  0.97s, ---- Loss: 0.6243, Acc.: 0.7518, Val. Loss: 0.8360, Val. Acc.: 0.7441

Epoch 67
Validation loss decreased. Saved checkpoint for step 68: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-27
Time:  1.09s, ---- Loss: 0.6240, Acc.: 0.7518, Val. Loss: 0.8355, Val. Acc.: 0.7454

Epoch 68
Validation loss decreased. Saved checkpoint for step 69: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-28
Time:  1.07s, ---- Loss: 0.6250, Acc.: 0.7516, Val. Loss: 0.8338, Val. Acc.: 0.7448

Epoch 69
Loss did not decrease. Count = 1
Time:  0.95s, ---- Loss: 0.6285, Acc.: 0.7522, Val. Loss: 0.8347, Val. Acc.: 0.7441

Epoch 70
Loss did not decrease. Count = 2
Time:  0.95s, ---- Loss: 0.6237, Acc.: 0.7512, Val. Loss: 0.8356, Val. Acc.: 0.7442

Epoch 71
Loss did not decrease. Count = 3
Time:  0.95s, ---- Loss: 0.6178, Acc.: 0.7520, Val. Loss: 0.8344, Val. Acc.: 0.7444

Epoch 72
Loss did not decrease. Count = 4
Time:  0.96s, ---- Loss: 0.6216, Acc.: 0.7525, Val. Loss: 0.8339, Val. Acc.: 0.7458

Epoch 73
Validation loss decreased. Saved checkpoint for step 74: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-29
Time:  1.08s, ---- Loss: 0.6229, Acc.: 0.7525, Val. Loss: 0.8328, Val. Acc.: 0.7462

Epoch 74
Loss did not decrease. Count = 1
Time:  0.95s, ---- Loss: 0.6229, Acc.: 0.7526, Val. Loss: 0.8332, Val. Acc.: 0.7438

Epoch 75
Loss did not decrease. Count = 2
Time:  0.95s, ---- Loss: 0.6185, Acc.: 0.7531, Val. Loss: 0.8333, Val. Acc.: 0.7449

Epoch 76
Validation loss decreased. Saved checkpoint for step 77: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-30
Time:  1.07s, ---- Loss: 0.6195, Acc.: 0.7528, Val. Loss: 0.8323, Val. Acc.: 0.7450

Epoch 77
Loss did not decrease. Count = 1
Time:  0.96s, ---- Loss: 0.6211, Acc.: 0.7528, Val. Loss: 0.8325, Val. Acc.: 0.7457

Epoch 78
Validation loss decreased. Saved checkpoint for step 79: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-31
Time:  1.07s, ---- Loss: 0.6244, Acc.: 0.7527, Val. Loss: 0.8320, Val. Acc.: 0.7452

Epoch 79
Validation loss decreased. Saved checkpoint for step 80: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-32
Time:  1.07s, ---- Loss: 0.6202, Acc.: 0.7528, Val. Loss: 0.8316, Val. Acc.: 0.7465

Epoch 80
Validation loss decreased. Saved checkpoint for step 81: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-33
Time:  1.07s, ---- Loss: 0.6225, Acc.: 0.7529, Val. Loss: 0.8307, Val. Acc.: 0.7469

Epoch 81
Loss did not decrease. Count = 1
Time:  0.95s, ---- Loss: 0.6224, Acc.: 0.7531, Val. Loss: 0.8331, Val. Acc.: 0.7459

Epoch 82
Validation loss decreased. Saved checkpoint for step 83: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-34
Time:  1.07s, ---- Loss: 0.6182, Acc.: 0.7526, Val. Loss: 0.8295, Val. Acc.: 0.7471

Epoch 83
Validation loss decreased. Saved checkpoint for step 84: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-35
Time:  1.07s, ---- Loss: 0.6225, Acc.: 0.7528, Val. Loss: 0.8293, Val. Acc.: 0.7486

Epoch 84
Loss did not decrease. Count = 1
Time:  0.95s, ---- Loss: 0.6168, Acc.: 0.7531, Val. Loss: 0.8299, Val. Acc.: 0.7470

Epoch 85
Loss did not decrease. Count = 2
Time:  0.96s, ---- Loss: 0.6257, Acc.: 0.7532, Val. Loss: 0.8298, Val. Acc.: 0.7470

Epoch 86
Loss did not decrease. Count = 3
Time:  0.95s, ---- Loss: 0.6199, Acc.: 0.7538, Val. Loss: 0.8308, Val. Acc.: 0.7476

Epoch 87
Loss did not decrease. Count = 4
Time:  0.95s, ---- Loss: 0.6206, Acc.: 0.7528, Val. Loss: 0.8312, Val. Acc.: 0.7459

Epoch 88
Validation loss decreased. Saved checkpoint for step 89: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-36
Time:  1.09s, ---- Loss: 0.6179, Acc.: 0.7529, Val. Loss: 0.8288, Val. Acc.: 0.7480

Epoch 89
Loss did not decrease. Count = 1
Time:  0.95s, ---- Loss: 0.6244, Acc.: 0.7535, Val. Loss: 0.8314, Val. Acc.: 0.7451

Epoch 90
Loss did not decrease. Count = 2
Time:  0.95s, ---- Loss: 0.6248, Acc.: 0.7529, Val. Loss: 0.8301, Val. Acc.: 0.7471

Epoch 91
Validation loss decreased. Saved checkpoint for step 92: models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/tf_ckpts/ckpt-37
Time:  1.08s, ---- Loss: 0.6190, Acc.: 0.7530, Val. Loss: 0.8279, Val. Acc.: 0.7483

Epoch 92
Loss did not decrease. Count = 1
Time:  0.95s, ---- Loss: 0.6210, Acc.: 0.7534, Val. Loss: 0.8304, Val. Acc.: 0.7480

Epoch 93
Loss did not decrease. Count = 2
Time:  0.96s, ---- Loss: 0.6181, Acc.: 0.7537, Val. Loss: 0.8292, Val. Acc.: 0.7478

Epoch 94
Loss did not decrease. Count = 3
Time:  0.95s, ---- Loss: 0.6206, Acc.: 0.7535, Val. Loss: 0.8289, Val. Acc.: 0.7483

Epoch 95
Loss did not decrease. Count = 4
Time:  0.95s, ---- Loss: 0.6245, Acc.: 0.7535, Val. Loss: 0.8295, Val. Acc.: 0.7463

Epoch 96
Loss did not decrease. Count = 5
Time:  0.94s, ---- Loss: 0.6194, Acc.: 0.7533, Val. Loss: 0.8285, Val. Acc.: 0.7484

Epoch 97
Loss did not decrease. Count = 6
Time:  0.95s, ---- Loss: 0.6257, Acc.: 0.7536, Val. Loss: 0.8298, Val. Acc.: 0.7471

Epoch 98
Loss did not decrease. Count = 7
Time:  0.95s, ---- Loss: 0.6210, Acc.: 0.7536, Val. Loss: 0.8296, Val. Acc.: 0.7468

Epoch 99
Loss did not decrease. Count = 8
Time:  0.96s, ---- Loss: 0.6215, Acc.: 0.7534, Val. Loss: 0.8291, Val. Acc.: 0.7480

Saving at models/sixlabel_5k_EE2_equalexamples-randoms_kmin-0.0_kmax-2.5_ds_binA/hist.png
Done in 1106.46s


 -------- Parameters:
bayesian True
test_mode False
n_test_idx 2
seed 1312
fine_tune False
one_vs_all False
c_0 ['lcdm']
c_1 ['True', 'dgp', 'ds', 'fR', 'rand--save_ckpt', 'wcdm']
dataset_balanced False
include_last False
log_path models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5__log.txt
restore False
fname sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_
model_name custom
my_path None
DIR data/train
TEST_DIR data/test
models_dir models/
save_ckpt True
out_path_overwrite False
curves_folder data/curve_files_sys/theory_error
save_processed_spectra False
cache_dir False
im_depth 500
im_width 1
im_channels 4
swap_axes True
sort_labels True
norm_data_name /planck_ee2.txt
normalization stdcosmo
sample_pace 1
k_max 2.5
k_min 0.4
i_max None
i_min None
add_noise True
n_noisy_samples 10
add_shot False
add_sys True
add_cosvar True
sigma_sys None
sys_scaled None
sys_factor None
sys_max None
sigma_curves 0.05
sigma_curves_default 0.05
rescale_curves uniform
z_bins [0, 1, 2, 3]
n_dense 1
filters [8, 16, 32]
kernel_sizes [10, 5, 2]
strides [2, 2, 1]
pool_sizes [2, 2, 0]
strides_pooling [2, 1, 0]
add_FT_dense False
trainable False
unfreeze False
lr 0.01
drop 0.5
n_epochs 100
val_size 0.15
test_size 0.0
batch_size 12000
patience 20
GPU True
TPU False
decay 0.95
BatchNorm True
padding valid
shuffle True

------------ CREATING DATA GENERATORS ------------
labels : ['dgp', 'ds', 'fr', 'lcdm', 'rand', 'wcdm']
Labels encoding: 
{'dgp': 0, 'ds': 1, 'fr': 2, 'lcdm': 3, 'rand': 4, 'wcdm': 5}
n_labels : 6
dgp - 20000 training examples
ds - 20000 training examples
fr - 20000 training examples
lcdm - 20000 training examples
rand - 20000 training examples
wcdm - 20000 training examples

N. of data files: 20000
get_all_indexes labels dict: {'dgp': 0, 'ds': 1, 'fr': 2, 'lcdm': 3, 'rand': 4, 'wcdm': 5}
create_generators n_labels: 6
create_generators n_labels_eff: 6
create_generators len_c1: 1
Check for no duplicates in test: (0=ok):
0.0
Check for no duplicates in val: (0=ok):
0
N of indexes in training set: 17000
N of indexes in validation set: 3000
N of indexes in test set: 0
Check - total per class: 20000
--create_generators, train indexes
batch_size: 12000
- Cut sample
bs: 12000
N_labels: 6
N_noise: 10
len_c1: 1
Train index length: 17000
--create_generators, validation indexes
- Cut sample
bs: 12000
N_labels: 6
N_noise: 10
len_c1: 1
Val index length: 3000
len(train_index_1), batch_size, n_labels_eff, n_noisy_samples = 17000, 12000, 6, 10

--DataSet Train
DataSet Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 2.5
Corresponding i_max is 399
Closest k to k_max is 2.504942
Specified k_min is 0.4
Corresponding i_min is 266
Closest k to k_min is 0.397373
New data dim: (133, 1)
Final i_max used is 399
Final i_min used is 266
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 6
N. n_classes in output: 6
LABELS: ['dgp', 'ds', 'fr', 'lcdm', 'rand', 'wcdm']
list_IDs length: 17000
n_indexes (n of file IDs read for each batch): 200
batch size: 12000
n_batches : 85
For each batch we read 200 file IDs
For each file ID we have 6 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 12000 training examples
Input batch size: 12000
N of batches to cover all file IDs: 85
len(fname_list), batch_size, n_noisy_samples, n_batches: 102000, 12000, 10, 85

--DataSet Validation
DataSet Initialization
Using z bins [0, 1, 2, 3]
Normalisation file is /planck_ee2.txt
Specified k_max is 2.5
Corresponding i_max is 399
Closest k to k_max is 2.504942
Specified k_min is 0.4
Corresponding i_min is 266
Closest k to k_min is 0.397373
New data dim: (133, 1)
Final i_max used is 399
Final i_min used is 266
one_vs_all: False
dataset_balanced: False
base_case_dataset: True
N. classes: 6
N. n_classes in output: 6
LABELS: ['dgp', 'ds', 'fr', 'lcdm', 'rand', 'wcdm']
list_IDs length: 3000
n_indexes (n of file IDs read for each batch): 200
batch size: 12000
n_batches : 15
For each batch we read 200 file IDs
For each file ID we have 6 labels
For each ID, label we have 10 realizations of noise
In total, for each batch we have 12000 training examples
Input batch size: 12000
N of batches to cover all file IDs: 15
len(fname_list), batch_size, n_noisy_samples, n_batches: 18000, 12000, 10, 15
------------ DONE ------------

------------ BUILDING MODEL ------------
Input shape (133, 4)
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 133, 4)]          0         
                                                                 
 conv1d_flipout (Conv1DFlip  (None, 62, 8)             648       
 out)                                                            
                                                                 
 max_pooling1d (MaxPooling1  (None, 31, 8)             0         
 D)                                                              
                                                                 
 batch_normalization (Batch  (None, 31, 8)             32        
 Normalization)                                                  
                                                                 
 conv1d_flipout_1 (Conv1DFl  (None, 14, 16)            1296      
 ipout)                                                          
                                                                 
 max_pooling1d_1 (MaxPoolin  (None, 13, 16)            0         
 g1D)                                                            
                                                                 
 batch_normalization_1 (Bat  (None, 13, 16)            64        
 chNormalization)                                                
                                                                 
 conv1d_flipout_2 (Conv1DFl  (None, 12, 32)            2080      
 ipout)                                                          
                                                                 
 batch_normalization_2 (Bat  (None, 12, 32)            128       
 chNormalization)                                                
                                                                 
 global_average_pooling1d (  (None, 32)                0         
 GlobalAveragePooling1D)                                         
                                                                 
 dense_flipout (DenseFlipou  (None, 32)                2080      
 t)                                                              
                                                                 
 batch_normalization_3 (Bat  (None, 32)                128       
 chNormalization)                                                
                                                                 
 dense_flipout_1 (DenseFlip  (None, 6)                 390       
 out)                                                            
                                                                 
=================================================================
Total params: 6846 (26.74 KB)
Trainable params: 6670 (26.05 KB)
Non-trainable params: 176 (704.00 Byte)
_________________________________________________________________
None
Found GPU at: /device:GPU:0
------------ TRAINING ------------

Features shape: (12000, 133, 4)
Labels shape: (12000, 6)
Initializing checkpoint from scratch.
Epoch 0
Validation loss decreased. Saved checkpoint for step 1: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-1
Time:  40.10s, ---- Loss: 1.4246, Acc.: 0.3585, Val. Loss: 1.7872, Val. Acc.: 0.2669

Epoch 1
Loss did not decrease. Count = 1
Time:  1.16s, ---- Loss: 1.2668, Acc.: 0.4780, Val. Loss: 1.8181, Val. Acc.: 0.2841

Epoch 2
Loss did not decrease. Count = 2
Time:  1.13s, ---- Loss: 1.1765, Acc.: 0.5186, Val. Loss: 3.1312, Val. Acc.: 0.1560

Epoch 3
Loss did not decrease. Count = 3
Time:  1.14s, ---- Loss: 1.0944, Acc.: 0.5550, Val. Loss: 3.6634, Val. Acc.: 0.1639

Epoch 4
Loss did not decrease. Count = 4
Time:  1.13s, ---- Loss: 1.0323, Acc.: 0.5813, Val. Loss: 2.8591, Val. Acc.: 0.1935

Epoch 5
Loss did not decrease. Count = 5
Time:  1.14s, ---- Loss: 1.0024, Acc.: 0.5993, Val. Loss: 2.2051, Val. Acc.: 0.2426

Epoch 6
Validation loss decreased. Saved checkpoint for step 7: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-2
Time:  1.26s, ---- Loss: 0.9765, Acc.: 0.6101, Val. Loss: 1.6849, Val. Acc.: 0.3646

Epoch 7
Validation loss decreased. Saved checkpoint for step 8: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-3
Time:  1.25s, ---- Loss: 0.9538, Acc.: 0.6190, Val. Loss: 1.5116, Val. Acc.: 0.4431

Epoch 8
Validation loss decreased. Saved checkpoint for step 9: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-4
Time:  1.25s, ---- Loss: 0.9443, Acc.: 0.6251, Val. Loss: 1.3106, Val. Acc.: 0.5116

Epoch 9
Validation loss decreased. Saved checkpoint for step 10: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-5
Time:  1.25s, ---- Loss: 0.9316, Acc.: 0.6294, Val. Loss: 1.1996, Val. Acc.: 0.5547

Epoch 10
Validation loss decreased. Saved checkpoint for step 11: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-6
Time:  1.25s, ---- Loss: 0.9280, Acc.: 0.6323, Val. Loss: 1.1122, Val. Acc.: 0.5811

Epoch 11
Validation loss decreased. Saved checkpoint for step 12: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-7
Time:  1.25s, ---- Loss: 0.9163, Acc.: 0.6360, Val. Loss: 1.0679, Val. Acc.: 0.5978

Epoch 12
Validation loss decreased. Saved checkpoint for step 13: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-8
Time:  1.25s, ---- Loss: 0.9192, Acc.: 0.6372, Val. Loss: 1.0437, Val. Acc.: 0.6078

Epoch 13
Validation loss decreased. Saved checkpoint for step 14: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-9
Time:  1.25s, ---- Loss: 0.9143, Acc.: 0.6404, Val. Loss: 1.0437, Val. Acc.: 0.6113

Epoch 14
Validation loss decreased. Saved checkpoint for step 15: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-10
Time:  1.25s, ---- Loss: 0.9054, Acc.: 0.6420, Val. Loss: 1.0149, Val. Acc.: 0.6226

Epoch 15
Loss did not decrease. Count = 1
Time:  1.13s, ---- Loss: 0.8975, Acc.: 0.6439, Val. Loss: 1.0339, Val. Acc.: 0.6170

Epoch 16
Loss did not decrease. Count = 2
Time:  1.13s, ---- Loss: 0.8905, Acc.: 0.6460, Val. Loss: 1.0455, Val. Acc.: 0.6144

Epoch 17
Loss did not decrease. Count = 3
Time:  1.11s, ---- Loss: 0.8888, Acc.: 0.6472, Val. Loss: 1.0396, Val. Acc.: 0.6135

Epoch 18
Loss did not decrease. Count = 4
Time:  1.12s, ---- Loss: 0.8822, Acc.: 0.6488, Val. Loss: 1.0239, Val. Acc.: 0.6208

Epoch 19
Loss did not decrease. Count = 5
Time:  1.11s, ---- Loss: 0.8792, Acc.: 0.6503, Val. Loss: 1.0156, Val. Acc.: 0.6230

Epoch 20
Loss did not decrease. Count = 6
Time:  1.13s, ---- Loss: 0.8775, Acc.: 0.6515, Val. Loss: 1.0171, Val. Acc.: 0.6217

Epoch 21
Validation loss decreased. Saved checkpoint for step 22: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-11
Time:  1.24s, ---- Loss: 0.8775, Acc.: 0.6524, Val. Loss: 0.9982, Val. Acc.: 0.6279

Epoch 22
Loss did not decrease. Count = 1
Time:  1.11s, ---- Loss: 0.8721, Acc.: 0.6536, Val. Loss: 1.0050, Val. Acc.: 0.6253

Epoch 23
Validation loss decreased. Saved checkpoint for step 24: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-12
Time:  1.26s, ---- Loss: 0.8693, Acc.: 0.6547, Val. Loss: 0.9701, Val. Acc.: 0.6376

Epoch 24
Loss did not decrease. Count = 1
Time:  1.13s, ---- Loss: 0.8682, Acc.: 0.6554, Val. Loss: 0.9708, Val. Acc.: 0.6387

Epoch 25
Validation loss decreased. Saved checkpoint for step 26: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-13
Time:  1.27s, ---- Loss: 0.8670, Acc.: 0.6565, Val. Loss: 0.9572, Val. Acc.: 0.6440

Epoch 26
Validation loss decreased. Saved checkpoint for step 27: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-14
Time:  1.28s, ---- Loss: 0.8648, Acc.: 0.6571, Val. Loss: 0.9478, Val. Acc.: 0.6466

Epoch 27
Validation loss decreased. Saved checkpoint for step 28: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-15
Time:  1.25s, ---- Loss: 0.8572, Acc.: 0.6583, Val. Loss: 0.9426, Val. Acc.: 0.6480

Epoch 28
Loss did not decrease. Count = 1
Time:  1.16s, ---- Loss: 0.8593, Acc.: 0.6590, Val. Loss: 0.9438, Val. Acc.: 0.6484

Epoch 29
Validation loss decreased. Saved checkpoint for step 30: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-16
Time:  1.26s, ---- Loss: 0.8512, Acc.: 0.6597, Val. Loss: 0.9349, Val. Acc.: 0.6512

Epoch 30
Loss did not decrease. Count = 1
Time:  1.14s, ---- Loss: 0.8508, Acc.: 0.6608, Val. Loss: 0.9353, Val. Acc.: 0.6520

Epoch 31
Loss did not decrease. Count = 2
Time:  1.14s, ---- Loss: 0.8505, Acc.: 0.6612, Val. Loss: 0.9357, Val. Acc.: 0.6500

Epoch 32
Loss did not decrease. Count = 3
Time:  1.13s, ---- Loss: 0.8465, Acc.: 0.6619, Val. Loss: 0.9351, Val. Acc.: 0.6505

Epoch 33
Validation loss decreased. Saved checkpoint for step 34: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-17
Time:  1.26s, ---- Loss: 0.8473, Acc.: 0.6622, Val. Loss: 0.9291, Val. Acc.: 0.6534

Epoch 34
Validation loss decreased. Saved checkpoint for step 35: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-18
Time:  1.25s, ---- Loss: 0.8419, Acc.: 0.6631, Val. Loss: 0.9218, Val. Acc.: 0.6562

Epoch 35
Loss did not decrease. Count = 1
Time:  1.14s, ---- Loss: 0.8401, Acc.: 0.6639, Val. Loss: 0.9240, Val. Acc.: 0.6551

Epoch 36
Validation loss decreased. Saved checkpoint for step 37: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-19
Time:  1.25s, ---- Loss: 0.8413, Acc.: 0.6642, Val. Loss: 0.9169, Val. Acc.: 0.6590

Epoch 37
Validation loss decreased. Saved checkpoint for step 38: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-20
Time:  1.24s, ---- Loss: 0.8406, Acc.: 0.6646, Val. Loss: 0.9131, Val. Acc.: 0.6605

Epoch 38
Validation loss decreased. Saved checkpoint for step 39: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-21
Time:  1.25s, ---- Loss: 0.8380, Acc.: 0.6652, Val. Loss: 0.9093, Val. Acc.: 0.6619

Epoch 39
Validation loss decreased. Saved checkpoint for step 40: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-22
Time:  1.24s, ---- Loss: 0.8349, Acc.: 0.6655, Val. Loss: 0.9056, Val. Acc.: 0.6634

Epoch 40
Validation loss decreased. Saved checkpoint for step 41: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-23
Time:  1.24s, ---- Loss: 0.8338, Acc.: 0.6661, Val. Loss: 0.9052, Val. Acc.: 0.6633

Epoch 41
Validation loss decreased. Saved checkpoint for step 42: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-24
Time:  1.25s, ---- Loss: 0.8352, Acc.: 0.6667, Val. Loss: 0.9031, Val. Acc.: 0.6641

Epoch 42
Validation loss decreased. Saved checkpoint for step 43: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-25
Time:  1.24s, ---- Loss: 0.8282, Acc.: 0.6670, Val. Loss: 0.9007, Val. Acc.: 0.6655

Epoch 43
Validation loss decreased. Saved checkpoint for step 44: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-26
Time:  1.26s, ---- Loss: 0.8299, Acc.: 0.6673, Val. Loss: 0.9002, Val. Acc.: 0.6659

Epoch 44
Loss did not decrease. Count = 1
Time:  1.14s, ---- Loss: 0.8293, Acc.: 0.6679, Val. Loss: 0.9003, Val. Acc.: 0.6658

Epoch 45
Validation loss decreased. Saved checkpoint for step 46: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-27
Time:  1.24s, ---- Loss: 0.8281, Acc.: 0.6679, Val. Loss: 0.8963, Val. Acc.: 0.6665

Epoch 46
Validation loss decreased. Saved checkpoint for step 47: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-28
Time:  1.24s, ---- Loss: 0.8267, Acc.: 0.6683, Val. Loss: 0.8962, Val. Acc.: 0.6668

Epoch 47
Validation loss decreased. Saved checkpoint for step 48: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-29
Time:  1.24s, ---- Loss: 0.8281, Acc.: 0.6689, Val. Loss: 0.8932, Val. Acc.: 0.6684

Epoch 48
Loss did not decrease. Count = 1
Time:  1.12s, ---- Loss: 0.8246, Acc.: 0.6690, Val. Loss: 0.8939, Val. Acc.: 0.6681

Epoch 49
Loss did not decrease. Count = 2
Time:  1.12s, ---- Loss: 0.8219, Acc.: 0.6690, Val. Loss: 0.8933, Val. Acc.: 0.6688

Epoch 50
Validation loss decreased. Saved checkpoint for step 51: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-30
Time:  1.26s, ---- Loss: 0.8210, Acc.: 0.6693, Val. Loss: 0.8904, Val. Acc.: 0.6700

Epoch 51
Loss did not decrease. Count = 1
Time:  1.15s, ---- Loss: 0.8227, Acc.: 0.6696, Val. Loss: 0.8905, Val. Acc.: 0.6689

Epoch 52
Validation loss decreased. Saved checkpoint for step 53: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-31
Time:  1.28s, ---- Loss: 0.8221, Acc.: 0.6695, Val. Loss: 0.8891, Val. Acc.: 0.6705

Epoch 53
Validation loss decreased. Saved checkpoint for step 54: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-32
Time:  1.30s, ---- Loss: 0.8220, Acc.: 0.6700, Val. Loss: 0.8885, Val. Acc.: 0.6698

Epoch 54
Validation loss decreased. Saved checkpoint for step 55: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-33
Time:  1.25s, ---- Loss: 0.8209, Acc.: 0.6704, Val. Loss: 0.8879, Val. Acc.: 0.6701

Epoch 55
Validation loss decreased. Saved checkpoint for step 56: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-34
Time:  1.24s, ---- Loss: 0.8224, Acc.: 0.6701, Val. Loss: 0.8875, Val. Acc.: 0.6710

Epoch 56
Validation loss decreased. Saved checkpoint for step 57: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-35
Time:  1.25s, ---- Loss: 0.8204, Acc.: 0.6705, Val. Loss: 0.8858, Val. Acc.: 0.6710

Epoch 57
Validation loss decreased. Saved checkpoint for step 58: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-36
Time:  1.25s, ---- Loss: 0.8190, Acc.: 0.6707, Val. Loss: 0.8853, Val. Acc.: 0.6713

Epoch 58
Validation loss decreased. Saved checkpoint for step 59: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-37
Time:  1.25s, ---- Loss: 0.8174, Acc.: 0.6705, Val. Loss: 0.8849, Val. Acc.: 0.6710

Epoch 59
Validation loss decreased. Saved checkpoint for step 60: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-38
Time:  1.26s, ---- Loss: 0.8174, Acc.: 0.6708, Val. Loss: 0.8848, Val. Acc.: 0.6711

Epoch 60
Validation loss decreased. Saved checkpoint for step 61: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-39
Time:  1.25s, ---- Loss: 0.8171, Acc.: 0.6710, Val. Loss: 0.8844, Val. Acc.: 0.6713

Epoch 61
Validation loss decreased. Saved checkpoint for step 62: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-40
Time:  1.24s, ---- Loss: 0.8180, Acc.: 0.6713, Val. Loss: 0.8843, Val. Acc.: 0.6715

Epoch 62
Loss did not decrease. Count = 1
Time:  1.14s, ---- Loss: 0.8172, Acc.: 0.6714, Val. Loss: 0.8846, Val. Acc.: 0.6714

Epoch 63
Loss did not decrease. Count = 2
Time:  1.13s, ---- Loss: 0.8167, Acc.: 0.6716, Val. Loss: 0.8846, Val. Acc.: 0.6716

Epoch 64
Validation loss decreased. Saved checkpoint for step 65: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-41
Time:  1.24s, ---- Loss: 0.8171, Acc.: 0.6717, Val. Loss: 0.8834, Val. Acc.: 0.6721

Epoch 65
Validation loss decreased. Saved checkpoint for step 66: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-42
Time:  1.26s, ---- Loss: 0.8184, Acc.: 0.6717, Val. Loss: 0.8827, Val. Acc.: 0.6718

Epoch 66
Loss did not decrease. Count = 1
Time:  1.13s, ---- Loss: 0.8166, Acc.: 0.6718, Val. Loss: 0.8831, Val. Acc.: 0.6725

Epoch 67
Validation loss decreased. Saved checkpoint for step 68: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-43
Time:  1.26s, ---- Loss: 0.8147, Acc.: 0.6719, Val. Loss: 0.8823, Val. Acc.: 0.6729

Epoch 68
Validation loss decreased. Saved checkpoint for step 69: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-44
Time:  1.24s, ---- Loss: 0.8160, Acc.: 0.6721, Val. Loss: 0.8820, Val. Acc.: 0.6725

Epoch 69
Validation loss decreased. Saved checkpoint for step 70: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-45
Time:  1.25s, ---- Loss: 0.8150, Acc.: 0.6723, Val. Loss: 0.8818, Val. Acc.: 0.6734

Epoch 70
Loss did not decrease. Count = 1
Time:  1.12s, ---- Loss: 0.8142, Acc.: 0.6722, Val. Loss: 0.8822, Val. Acc.: 0.6725

Epoch 71
Validation loss decreased. Saved checkpoint for step 72: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-46
Time:  1.25s, ---- Loss: 0.8136, Acc.: 0.6724, Val. Loss: 0.8816, Val. Acc.: 0.6726

Epoch 72
Validation loss decreased. Saved checkpoint for step 73: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-47
Time:  1.28s, ---- Loss: 0.8139, Acc.: 0.6727, Val. Loss: 0.8807, Val. Acc.: 0.6728

Epoch 73
Loss did not decrease. Count = 1
Time:  1.12s, ---- Loss: 0.8145, Acc.: 0.6726, Val. Loss: 0.8810, Val. Acc.: 0.6729

Epoch 74
Validation loss decreased. Saved checkpoint for step 75: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-48
Time:  1.25s, ---- Loss: 0.8142, Acc.: 0.6724, Val. Loss: 0.8806, Val. Acc.: 0.6737

Epoch 75
Validation loss decreased. Saved checkpoint for step 76: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-49
Time:  1.25s, ---- Loss: 0.8120, Acc.: 0.6727, Val. Loss: 0.8797, Val. Acc.: 0.6736

Epoch 76
Loss did not decrease. Count = 1
Time:  1.11s, ---- Loss: 0.8139, Acc.: 0.6729, Val. Loss: 0.8797, Val. Acc.: 0.6735

Epoch 77
Validation loss decreased. Saved checkpoint for step 78: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-50
Time:  1.27s, ---- Loss: 0.8128, Acc.: 0.6732, Val. Loss: 0.8793, Val. Acc.: 0.6737

Epoch 78
Loss did not decrease. Count = 1
Time:  1.11s, ---- Loss: 0.8142, Acc.: 0.6731, Val. Loss: 0.8798, Val. Acc.: 0.6736

Epoch 79
Loss did not decrease. Count = 2
Time:  1.14s, ---- Loss: 0.8111, Acc.: 0.6732, Val. Loss: 0.8795, Val. Acc.: 0.6738

Epoch 80
Loss did not decrease. Count = 3
Time:  1.12s, ---- Loss: 0.8133, Acc.: 0.6732, Val. Loss: 0.8795, Val. Acc.: 0.6737

Epoch 81
Validation loss decreased. Saved checkpoint for step 82: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-51
Time:  1.27s, ---- Loss: 0.8114, Acc.: 0.6730, Val. Loss: 0.8788, Val. Acc.: 0.6743

Epoch 82
Loss did not decrease. Count = 1
Time:  1.16s, ---- Loss: 0.8112, Acc.: 0.6732, Val. Loss: 0.8797, Val. Acc.: 0.6731

Epoch 83
Loss did not decrease. Count = 2
Time:  1.13s, ---- Loss: 0.8119, Acc.: 0.6733, Val. Loss: 0.8794, Val. Acc.: 0.6744

Epoch 84
Validation loss decreased. Saved checkpoint for step 85: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-52
Time:  1.25s, ---- Loss: 0.8128, Acc.: 0.6732, Val. Loss: 0.8786, Val. Acc.: 0.6737

Epoch 85
Loss did not decrease. Count = 1
Time:  1.12s, ---- Loss: 0.8107, Acc.: 0.6733, Val. Loss: 0.8793, Val. Acc.: 0.6737

Epoch 86
Loss did not decrease. Count = 2
Time:  1.13s, ---- Loss: 0.8113, Acc.: 0.6734, Val. Loss: 0.8794, Val. Acc.: 0.6733

Epoch 87
Loss did not decrease. Count = 3
Time:  1.12s, ---- Loss: 0.8115, Acc.: 0.6735, Val. Loss: 0.8788, Val. Acc.: 0.6739

Epoch 88
Loss did not decrease. Count = 4
Time:  1.12s, ---- Loss: 0.8118, Acc.: 0.6736, Val. Loss: 0.8788, Val. Acc.: 0.6742

Epoch 89
Loss did not decrease. Count = 5
Time:  1.13s, ---- Loss: 0.8115, Acc.: 0.6735, Val. Loss: 0.8787, Val. Acc.: 0.6738

Epoch 90
Validation loss decreased. Saved checkpoint for step 91: models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/tf_ckpts/ckpt-53
Time:  1.24s, ---- Loss: 0.8120, Acc.: 0.6734, Val. Loss: 0.8781, Val. Acc.: 0.6744

Epoch 91
Loss did not decrease. Count = 1
Time:  1.14s, ---- Loss: 0.8120, Acc.: 0.6733, Val. Loss: 0.8787, Val. Acc.: 0.6741

Epoch 92
Loss did not decrease. Count = 2
Time:  1.13s, ---- Loss: 0.8111, Acc.: 0.6734, Val. Loss: 0.8783, Val. Acc.: 0.6746

Epoch 93
Loss did not decrease. Count = 3
Time:  1.12s, ---- Loss: 0.8114, Acc.: 0.6736, Val. Loss: 0.8782, Val. Acc.: 0.6739

Epoch 94
Loss did not decrease. Count = 4
Time:  1.12s, ---- Loss: 0.8103, Acc.: 0.6736, Val. Loss: 0.8786, Val. Acc.: 0.6744

Epoch 95
Loss did not decrease. Count = 5
Time:  1.12s, ---- Loss: 0.8099, Acc.: 0.6737, Val. Loss: 0.8784, Val. Acc.: 0.6741

Epoch 96
Loss did not decrease. Count = 6
Time:  1.13s, ---- Loss: 0.8120, Acc.: 0.6736, Val. Loss: 0.8783, Val. Acc.: 0.6743

Epoch 97
Loss did not decrease. Count = 7
Time:  1.12s, ---- Loss: 0.8110, Acc.: 0.6738, Val. Loss: 0.8783, Val. Acc.: 0.6748

Epoch 98
Loss did not decrease. Count = 8
Time:  1.13s, ---- Loss: 0.8118, Acc.: 0.6735, Val. Loss: 0.8787, Val. Acc.: 0.6740

Epoch 99
Loss did not decrease. Count = 9
Time:  1.12s, ---- Loss: 0.8112, Acc.: 0.6736, Val. Loss: 0.8785, Val. Acc.: 0.6741

Saving at models/sixlabel_20k_EE2_equalexamples-randoms_kmin-0.4_kmax-2.5_/hist.png
Done in 3986.27s
